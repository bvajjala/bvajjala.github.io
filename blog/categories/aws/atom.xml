<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: AWS | Balaji Vajjala's Blog]]></title>
  <link href="http://bvajjala.github.io/blog/categories/aws/atom.xml" rel="self"/>
  <link href="http://bvajjala.github.io/"/>
  <updated>2014-04-16T09:48:34-04:00</updated>
  <id>http://bvajjala.github.io/</id>
  <author>
    <name><![CDATA[Balaji Vajjala]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Continuous Delivery Implementation : Getting started with AWS]]></title>
    <link href="http://bvajjala.github.io/blog/2014/03/25/continuous-delivery-implementation-getting-started-with-aws/"/>
    <updated>2014-03-25T14:57:15-04:00</updated>
    <id>http://bvajjala.github.io/blog/2014/03/25/continuous-delivery-implementation-getting-started-with-aws</id>
    <content type="html"><![CDATA[<ul>
<li>Blog</li>
<li>This article is part of the Continuous Delivery Blueprints series.
It discusses how to go from no cloud infrastructure and no
continuous integration set up to having a functioning Continuous
Delivery Pipeline in Amazon Web Services. It discusses high level
topics while also providing a reference implementation so it’s easy
to follow along with.

<ul>
<li>Turn on CloudTrail</li>
<li>Turn on Programmatic Billing</li>
<li>If CloudTrail and Programmatic Billing are so important, why
aren’t they turned on by default?</li>
<li>Create IAM Users</li>
<li>Comments</li>
<li>Trackbacks</li>
<li>Post a comment</li>
<li>Categories</li>
</ul>
</li>
</ul>


<h1>This article is part of the Continuous Delivery Blueprints series. It discusses how to go from no cloud infrastructure and no continuous integration set up to having a functioning Continuous Delivery Pipeline in Amazon Web Services. It discusses high level topics while also providing a reference implementation so it’s easy to follow along with.</h1>

<p>Everyone is talking about migrating to the cloud these days, and getting
started with Amazon Web Services is super simple to do. However, most
people just rush in, creating headaches for themselves down the road.
There are some best practices you should take at the beginning of your
cloud migration that will make things easier, more secure, and allow you
to scale up and out better.</p>

<p>What we’re going to do today:</p>

<ul>
<li>• Create an AWS Account</li>
<li>• Turn On AWS CloudTrail</li>
<li>• Turn On Programmatic Billing</li>
<li>• Create IAM Users and Groups</li>
<li>• Add MFA for New Users</li>
</ul>


<p><strong>Create your AWS Account</strong></p>

<p>It all starts here: <a href="http://aws.amazon.com/">aws.amazon.com</a>. Find the
big sign up button and just follow the prompts. A couple of things to
note before getting started:</p>

<ol>
<li><ol>
<li>It’ll prompt you for your information (name, email, address, etc)
and credit card info, so you should get that figured out first.</li>
</ol>
</li>
<li><ol>
<li>You’ll need to verify your account via a phone call, so have your
phone handy.</li>
</ol>
</li>
<li><ol>
<li>You don’t need to sign up for support just yet.</li>
</ol>
</li>
</ol>


<p>Once you’re signed up, just login into the AWS console. The console
allows you to interact with most AWS services. Most people will start
building their servers in the sky right away, but there’s a bit of
information you should probably know up front, and some account set up
we recommend before getting started. Let’s go over that first.</p>

<p><strong>What You Need To Know About AWS Before Setting Stuff Up</strong></p>

<p>Amazon Web Services offers a lot of different services, from virtual
computing instances and storage to transcoding and streaming. Going over
each service would take a whole series of blog posts, but an
understanding of how AWS is laid out will be helpful when getting
started.</p>

<p>AWS has data centers all over the world, and has two ways of grouping
them. At global scale there are <strong>regions</strong>, representing parts of or
entire continents. Inside each region are <strong>availability zones</strong>.
Regions are completely distinct entities, and you can only work in one
at a time. Availability zones are designed to talk to each other, and
AWS will automatically spread your resources across availability zones.
Availability zones, however, can only speak to other zones within the
same region.</p>

<p>Choosing a region is important, though these directions are the same
more-or-less in every region. However, be aware that not all services
are available in all regions, and pricing does vary by region. In
addition to that, US-East-1 is the “default” zone when you start with
AWS, and has been around the longest. For that reason, it’s also the
most popular, and sometimes you won’t be able to allocate resources in
certain Availability Zones in the US-East-1 region due to those zones
being at capacity.</p>

<p>AWS provides <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html">lots of
documentation</a>
on how to choose a region, so definitely look through that to decide the
best place to host your infrastructure. If you’re just doing initial
investigation into AWS and aren’t sure what region to use, just pick one
close to you.</p>

<p><strong>Making a Name For Yourself</strong></p>

<p>We’ll be talking about several AWS services in this section, and many of
them make use of AWS Simple Storage Service, or <strong>S3</strong>. S3 allows you to
store objects in the cloud with a high degree of durability. Where S3
objects are stored are called “buckets”. S3 bucket names have to be
unique, not just across you account, but across the entire world. A
bucket name is globally unique. By the time we’re done, we’ll have
created a couple buckets, as well globally unique login URL. For that
reason, you should come up with a unique identifier now. For example,
when we tested this documentation, we used the identifier
“stelligent-cdblueprints.” Just note it down now and we’ll refer to it
as we go on.</p>

<h4>Turn on CloudTrail</h4>

<p>First thing is to turn on CloudTrail. CloudTrail is basically logging
for your AWS account. It will generate JSON files and store them in an
S3 bucket (Amazon’s cloud storage solution) every time an action is
performed on the account. While we won’t be doing a lot with CloudTrail
right away, we’re turning it on now because it’s not retroactive — you
can only see logs after you’ve turned it on. So let’s turn it on first.</p>

<p>(Quick note: CloudTrail is a relatively new service, and at the time of
this writing is only available in two regions: US-East-1 and US-West-2.
If you’re using a different region, you might not be able to turn
CloudTrail on. If that’s the case, just skip on to the next step.)</p>

<ol>
<li>Find CloudTrail panel from the main AWS Console,</li>
<li>Click Get Started and just punch in an S3 Bucket name. (As was
mentioned above, the S3 bucket name has to be globally unique. One
approach is to take the unique identifier you came up with before,
and just append -cloudtrail to it. We’ve named our bucket
“stelligent-cdblueprints-cloudtrail”.)</li>
<li>Click OK and you’re done.</li>
</ol>


<p>That was easy.</p>

<h4>Turn on Programmatic Billing</h4>

<p>Next, we’ll want to turn on Programmatic Billing. This will store your
AWS billing in JSON files in another S3 bucket, so that other services
can analyze your spending and plot trends over time. We’ll be visiting
those kind of tools later on, but we want to enable programmatic billing
now because (just like CloudTrail) it only generates data from the
present — there’s no way to go back and generate historical data. By
turning it on now, when we do start parsing that data for trends, you’ll
have a good amount of data to go back through.</p>

<p>Unlike CloudTrail, you’ll need to create and permission the bucket for
this yourself.</p>

<ol>
<li>Go to the S3 console so we can create a new bucket. (Taking your
previous unique identifier and just appending -billing to it isn’t a
bad idea. We’ve named ours “stelligent-cdblueprints-billing” to keep
with the theme.)</li>
<li>Click Create Bucket and punch that name in.</li>
<li>We’ll need to get a bucket permissions policy. Luckily, AWS will
generate that for us at this page (we’ll need to flip back to the S3
page in a second, so open this in a new
tab): <a href="https://portal.aws.amazon.com/gp/aws/developer/account?ie=UTF8&amp;action=billing-preferences">https://portal.aws.amazon.com/gp/aws/developer/account?ie=UTF8&amp;action=billing-preferences</a></li>
<li>Go down the list and turn everything on one and a time.</li>
<li>When you get to to Programmatic billing, punch in the name of
your bucket, and click “sample policy.” Just copy that policy, then
flip back to your S3 bucket.</li>
<li>Click on the bucket, then properties, then Permissions, and
you’ll see an option for setting an access policy.</li>
<li>Click into that, paste the policy you just copied, and save.</li>
<li>Now, flip back to the Billing Preferences page, click save there</li>
<li>Continue to enable everything else on this page.</li>
</ol>


<h4>If CloudTrail and Programmatic Billing are so important, why aren’t they turned on by default?</h4>

<p>One thing to be aware of with these two services is that they will put
data into your S3 buckets. S3 storage is very cheap, and while it is
pretty close, it is not free. You’ll be paying between nine and fifteen
cents a gig for storage, depending on region. For more details, <a href="https://aws.amazon.com/s3/pricing/">check
out the S3 pricing page</a>. The
services themselves don’t cost anything, though; you only pay for
storing the data they generate.</p>

<h4>Create IAM Users</h4>

<p>Now that the bookkeeping is taken care of, let’s set up some users. A
lot of new AWS users will start doing everything as the root account,
which besides being a bit of a security risk, also poses some issues
when you try to have multiple developers building solutions in your
cloud. That’s why we strongly recommend setting up IAM users and roles
from the beginning.</p>

<p>We’re going to use the AWS Identity and Access Management (IAM) console.
IAM allows you to create users, groups, and roles so that you can manage
users and access to your AWS account. For the first section, we’ll only
be creating one user (for you) and one group (admins) but as your usage
of the cloud increases and you need to add more users, you’ll be able to
control that from here.</p>

<p>To create a new admins group, head to the IAM console</p>

<ol>
<li>Click Create Group, and follow the prompts.</li>
<li>We’ll name the group “admins” and give it Administrator access.</li>
</ol>


<p>Now that we have an admins group, go to the Users panel and create a new
user for yourself to log in as. It’s pretty straightforward, and if you
hit any bumps in the road, <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/Using_SettingUpUser.html">AWS has some pretty good documentation about
it</a>.</p>

<p>After you create the user, add it to the admins group. Then, for each
user we want to set up two types of authentication. The first is a
simple password. Under each users’ Security Credentials tab, click the
“Manage Passwords” button and you’ll be able to assign a password.</p>

<p>After each user logs in, you’ll want to require them to add a
multi-factor authentication (MFA) device to their account. To add an MFA
device</p>

<ol>
<li>the user will need to login and go to the IAM console</li>
<li>find their username</li>
<li>under the security credentials tab, select “Manage MFA device.”</li>
<li>Then follow the steps to add your virtual MFA device to the account.</li>
</ol>


<p>Having MFAs set up for all accounts helps ensure that AWS accounts won’t
be compromised, keeping your data safe. Also, it helps ensure that your
account won’t be used for malicious purposes (DDOS attacks, spam emails,
etc) which would at best would increase your AWS bill and worst case
have your entire account disabled. We strongly recommend enabling MFAs
for all user accounts.</p>

<p>Now that users are able to log in, we’ll need to give them a URL to do
so. If you go to the main IAM console, you’ll find a IAM User Sign-In
URL section. Remember the unique identifier you came up with your
CloudTrail and Programatic Billing buckets? That’s probably a good
option for your sign in URL. Changing it is optional, though highly
recommended.</p>

<p><strong>Wrapping Up</strong></p>

<p>Using AWS is easy; using it well takes some thought. By setting up
logging of your usage and billing information, you’ll be able to
identify trends as time goes on. By setting up groups and users, your
account is prepared to scale as you bring on more developers. And by
giving those users multi-factor authentication, you’ve helped ensure the
security of the account. You’re in a great place to start using the
cloud. In our next post, we’ll lay the foundations for building a
continuous delivery pipeline.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Autoscaling for LAMP on AWS |Creating a LAMP Stack AMI : Part 4]]></title>
    <link href="http://bvajjala.github.io/blog/2014/03/25/autoscaling-for-lamp-on-aws-creating-a-lamp-stack-ami-part-4/"/>
    <updated>2014-03-25T11:23:17-04:00</updated>
    <id>http://bvajjala.github.io/blog/2014/03/25/autoscaling-for-lamp-on-aws-creating-a-lamp-stack-ami-part-4</id>
    <content type="html"><![CDATA[<h3>Autoscaling for LAMP on AWS | Choosing an instance type: Part 4</h3>

<p>As mentioned in <a href="../autoscaling-for-lamp-on-aws-creating-a-lamp-stack-ami-part-1/index.html" title="Autoscaling for LAMP on AWS |Creating a LAMP Stack AMI : Part 1">part 1 of this
series</a> (Creating
a LAMP Stack AMI), a common concern among most customers is to choose
the right instance type.</p>

<p>It is important to do the capacity planning. Before you choose instance
type ask yourself the following three questions:</p>

<ol>
<li><p>Is the application Memory intensive CPU intensive or Network
intensive? For this question to be meaningful put a monitoring
system in place and collect the data for a few weeks of real usage.</p></li>
<li><p>What is the expected request count at peak hours?</p></li>
<li><p>What is the minimum number of instances you want to run in
non-business hours?</p></li>
</ol>


<p><a href="https://docs.google.com/a/flux7.com/spreadsheet/ccc?key=0AkmUqlScRGp8dGJTNndjY0VjTURid3FTV2dNMEljOUE#gid=0">https://docs.google.com/a/flux7.com/spreadsheet/ccc?key=0AkmUqlScRGp8dGJTNndjY0VjTURid3FTV2dNMEljOUE#gid=0</a></p>

<p>Make sure to run at least 2 servers for high availability.  During times
of fewer loads, choose two m1.small instances for non-business hours
like weekends. This would optimize cost instead of using 2 large
instances for the same request.</p>

<p>Different instance types have different capacity levels. If the
application is memory intensive choose and use m1. class. If the
application is CPU intensive then choose and use c1. class.</p>

<p>Network bandwidth varies between different instance types. If the
application requires more bandwidth (ex: video streaming applications)
choose higher instance types irrespective of Memory or CPU to get better
bandwidth.</p>

<p>To know more about each instance types visit the following link.</p>

<p><a href="http://aws.amazon.com/ec2/instance-types/">http://aws.amazon.com/ec2/instance-types/</a></p>

<p>Start with micro/small instance for any workload. Do the Load run
starting with the minimum number of users and increase the load
gradually. Also scale the servers vertically or horizontally gradually
until it reaches the maximum capacity. This would give a clearer picture
of the number of instances required to serve the maximum or minimum
load. Closely watch the CloudWatch graphs to understand usage statistics
better.</p>

<p>An interesting question at this juncture could be as follows: Can 4
m1.medium instances be preferred to 2 large instances? Yes of course.
However, network bandwidth varies from one instance type to other. Given
that, it is wise to choose 2 large instances instead of 4 m1.medium
instances as it is easier to handle lesser number of instances.</p>

<p>(Note: DB server health needs to be checked when a load test is run.
Increasing the app servers count may not improve the performance all the
time. If DB queries are the bottleneck, chances are high for a bad
performance. Consider scaling up the DB server capacity as well.)</p>

<p>Based on the instance type identified from the load run, tune the PHP
memory settings and Apache prefork MPM client connections.</p>

<p>Check out the following links to know more about fine tuning Apache and
PHP</p>

<p><a href="http://www.hosting.com/support/linux/tuning-the-apache-prefork-mpm/">http://www.hosting.com/support/linux/tuning-the-apache-prefork-mpm/</a></p>

<p><a href="http://icreatestuff.co.uk/blog/article/apache-performance-tuning">http://icreatestuff.co.uk/blog/article/apache-performance-tuning</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Autoscaling for LAMP on AWS |Creating a LAMP Stack AMI : Part 3]]></title>
    <link href="http://bvajjala.github.io/blog/2014/03/25/autoscaling-for-lamp-on-aws-creating-a-lamp-stack-ami-part-3/"/>
    <updated>2014-03-25T11:23:14-04:00</updated>
    <id>http://bvajjala.github.io/blog/2014/03/25/autoscaling-for-lamp-on-aws-creating-a-lamp-stack-ami-part-3</id>
    <content type="html"><![CDATA[<h3>Autoscaling for LAMP on AWS | Load Test the Environment: Part 3</h3>

<p>In part 3 of the Autoscaling for LAMP on AWS series,</p>

<p>After setting up your application autoscaling, it’s important to load
run the application in order to understand the minimum and maximum
number of instances required for each application.</p>

<p><a href="../autoscaling-for-lamp-on-aws-setting-up-austoscaling-groups-part-2/index.html" title="Autoscaling for LAMP on AWS | Setting Up Austoscaling Groups : Part 2">Read Part 2 to learn more about setting up autoscaling
groups.</a></p>

<p>First, fire the load run. For this article we’ve used HP LoadRunner
because it provides more detailed results than others, but there are
also other load runner tools to choose from. Be sure to run the load
from multiple IP addresses or else the ELB may not distribute it equally
across all instances. HP LoadRunner helps you use multiple nodes in
order to generate the load.</p>

<p>Update the Auto Scaling Group’s minimum and maximum instance counts.\</p>

<p><img src="https://lh5.googleusercontent.com/nXhTs4kEqjzxfAy8aGdgqLvC_yKninSiyM3pClGWhemLXPWFjr_6Y5NU8xnf2j7twuJgVx2TO4tvs8fjm2K1c8y6C23NN8lacgef-JEH4621AXZITbYAAKRF4w" alt="" /></p>

<p>For the this article, we’ve set the minimum and maximum instance counts
at 2 and 8 respectively.</p>

<p>Now change your Auto Scaling Policies. A scaling policy specifies
whether to scale the auto scaling group up or down, and by how much.
Here we’ve chosen 2 instances for Scale Up and Scale Down policies.
These policies automatically increase or decrease the instances
according to your defined conditions in order to maintain performance
and minimize cost.</p>

<p><img src="https://lh3.googleusercontent.com/3G9JdQa1GNjF_2fWOrZ10y-cpc3m8_6gtTH2Y046OK3LoiaMYGx0Nm_N4LsBcBhhRhA3cxr7D1sMlCv90ewW9rZ8QCr8amOHqivVcZZmML7Bx-XMIeM7wdN1Nw" alt="" /></p>

<p>Next, <strong>increase the load</strong> gradually with LoadRunner. Once the CPU
reaches 75% of the instances, Autoscaling will trigger the scale up
policy to launch 2 more instances.</p>

<p>Now <strong>decrease the load</strong> gradually and the CPU instances load should
come down to less than 45%. Autoscaling will then trigger the scale down
policy and delete the additional instances that were launched.</p>

<p>Consider a scenario in which a 2,000-concurrent-request count is reached
during peak hours and 500 users are reached during non-peak hours. For
best load run results, try the following.</p>

<p>Capture load test results and CloudWatch metrics for each of the
following scenarios:</p>

<p>​1. Start the load test with 500 users. Set the minimum instance count
to 2 if you choose large or medium types, and set the maximum instance
count to 4.</p>

<p>​2. Increase the load to 1,000 users. Set the minimum and maximum
instance counts to 2 and 6 respectively.</p>

<p>​3. Increase the load to 2,000 users. Set the minimum and maximum
instance counts to 4 and 10 respectively.</p>

<p>​4. Increase the load to 3,000 users. Set the minimum and maximum
instance counts to 6 and 12 respectively.</p>

<p>Analyze the results for each scenario and note which gives better
throughput and response times. Also check the DB metrics.</p>

<p>Now it will be easy to choose the best instance type and max/min
instance counts..</p>

<p><strong>Shutdown Autoscaling</strong></p>

<p>Update the autoscale group to resize the instance count to 0. This will
terminate all instances launched within the lamp-asg autoscale group.</p>

<p><em>Watch out for the final part of this series tomorrow on how to choose
an instance type. </em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Autoscaling for LAMP on AWS |Creating a LAMP Stack AMI : Part 2]]></title>
    <link href="http://bvajjala.github.io/blog/2014/03/25/autoscaling-for-lamp-on-aws-creating-a-lamp-stack-ami-part-2/"/>
    <updated>2014-03-25T11:23:10-04:00</updated>
    <id>http://bvajjala.github.io/blog/2014/03/25/autoscaling-for-lamp-on-aws-creating-a-lamp-stack-ami-part-2</id>
    <content type="html"><![CDATA[<h3>Autoscaling for LAMP on AWS | Setting Up Austoscaling Groups : Part 2</h3>

<p>In part 2 of the Autoscaling LAMP in AWS series, let’s discuss how to
create autoscaling launch configuration, autoscaling groups and how to
verify the setup autoscaling.</p>

<h2><strong>Autoscale Implementation</strong> </h2>

<p>Autoscale configuration is now available in console. AWS command lines
are no longer needed for implementation.</p>

<p>Complete the following steps as detailed in <a href="../autoscaling-for-lamp-on-aws-creating-a-lamp-stack-ami-part-1/index.html" title="Autoscaling for LAMP on AWS |Creating a LAMP Stack AMI : Part 1">Part
1</a>of
this series in order to set up autoscaling :</p>

<ul>
<li><p>Configure AMI to launch the Instances.</p></li>
<li><p>Configure Instance type to launch the instances. (Example:
m1.small,m1.large).</p></li>
<li><p>Configure KeyPair Name to access the machines.</p></li>
<li><p>Configure Security Group to allow the Instances to communicate with
other components.</p></li>
<li><p>Keep the ELB name readily available.</p></li>
<li><p>Keep your availability zones ready. (Example: us-east-1a,
us-east-1b).</p></li>
<li><p>Set the minimum number of instances for Maximum and Desired
Capacity. (Start with zero).</p></li>
<li><p>Set Health Check Type. (ELB).</p></li>
<li><p>Set Region.</p></li>
<li><p>Change Capacity Cooldown time.</p></li>
<li><p>Adjust for scale up and scale down.</p></li>
</ul>


<h2><strong>1. Create the Autoscaling Launch Config</strong> </h2>

<p>Log in to the AWS console and navigate to Services-> EC2-> Launch
Configuration.</p>

<p><img src="https://lh5.googleusercontent.com/-E7LhgP_GnMeKXQHtHPieeiqZBbrD3TauY5FHvA90y2hvnWMoncO5gEJASGmYd_v1HjDIzIr949-gjX7N2DlCtzCyO5iwZnUd481qEyiHKVkxhH40xDL3xiTzQ" alt="" /></p>

<p>Click on “Create Autoscaling Group”.\</p>

<p><img src="https://lh6.googleusercontent.com/8MJM4YJXpOnamUnIZdfPkHZDJJ_iyVXg1qj373NTmPKZbihu4C2nqYcm2zvCacxycBN1OjzxbpANVSI7W4t7a8LYo15FbooKxx0UlXXkpJwuWxSNX7ZfSYm-PA" alt="" /></p>

<p>On the next screen, click on “Create Launch Configuration”.\</p>

<p><img src="https://lh6.googleusercontent.com/8h6Tn5ncvwmpG6qqI5vqulA_qoG6ijs4wtOOWA6nDwuCUCF1_OpD1VSWhlJDimgNNyhp_dmEsVx4DNJkls043s_CbBJ3HK0VUsSUphYjNeM3Qnlx1clgXZ5jAA" alt="" /></p>

<p>Create a new launch configuration. The name of the launch configuration
must be unique within the scope of the client’s AWS account.</p>

<p><strong>Choose AMI:</strong> Go to My AMIs and select the LAMP AMI created.\</p>

<p><img src="https://lh4.googleusercontent.com/SJXQcn4aWSm83eKHuKKZHJomaUvLwJShg8w5M1Q6wEXXNiUv61JNoiaKMYlaacP4TYT8kTvJju2vDKK23RReWFLgLxRGb68xaSuMbHzjQ0H74evkNtINH_T_xQ" alt="" /></p>

<p><strong>Choose Instance Type:</strong> We’ve selected a micro instance for our
example.\</p>

<p><img src="https://lh3.googleusercontent.com/e7lh5P4VR8i9qJ5QgxUK1PBN6in9HQNpU0cjznY6Giemq8RZrF2wBEfmlL_cCS_cDUBKKUHkmU__YC6YPiNncXXhbXMq9BRE3tLSbDewJR8MZ8upoWi0OwIp2w" alt="" /></p>

<p><strong>Configure Details:</strong> Give a name for the Launch Configuration\</p>

<p><img src="https://lh4.googleusercontent.com/kP646CGpnJLDO-44macZIU6A4FMSeLpu8kSq6hpFIstb_heGHWMCRwtn5EpOw8YZdvCANbd-5Pur5SNw_OaWg7432_WdQ1Rbi9QUsR6FMUIo71Y6REwKA5wJ2w" alt="" /></p>

<p><strong>Add Storage:</strong> Keep the values on default.</p>

<p><strong>Configure the Security Group:</strong>Select the Security group to launch the
autoscaling instances. Review the details and create the Launch
Configuration.\</p>

<p><img src="https://lh5.googleusercontent.com/rd0tjYvJyMzG0irkmsj9LZSXrxigf93tfOhOLUtcrQ-c1Pk2XXsOF7ksRbu4BY_6PvPfMWqC9bF4NZcy1aNLBOfUd91vjV9shjfA9IRAA5MNSJXb6sPuVa8gHA" alt="" /></p>

<p>In the next window, select “KeyPair” to access the instances.</p>

<h2><strong>2. Create the Auto Scaling Group</strong> </h2>

<p>Create a new Auto Scaling group with a specified name and other
attributes. When you make the creation request, the Auto Scaling group
is ready for use in other calls.</p>

<p>Navigate to EC2-> Auto Scaling Groups-> Create Autoscaling Group.</p>

<p>Select the existing Launch Configuration (lamp-launch-1) and go to “Next
Step”.\</p>

<p><img src="https://lh4.googleusercontent.com/N9-2P0wrXtd1IKWO58H1i7s6MRx0w_toDG5wjmtvsw0v5wUamXz6oIC88g-YYqnP5H9OTobjDc_X9Hf1shLrn_5tTO4HLuHHUomu8qE8OYv3oLEDp02urv0U4g" alt="" /></p>

<p><strong>Configure Autoscaling Group Details:</strong></p>

<p>Give a name to the Auto Scaling Group.</p>

<p>Group Size: Start with zero instances in order to avoid the immediate
creation of instances. The exact number of required instances can be set
after these steps are completed, but just set cost optimization values
to 0 for now.</p>

<p><strong>Availability Zones:</strong></p>

<p>Choose 2 availability zones in order to maintain high availability.</p>

<p>In “Advanced Details” choose the values as shown below.\</p>

<p><img src="https://lh3.googleusercontent.com/YL14QA7srKzFlnQLXuXtIxo0wrB51aDQuOj8fR5YXDYErg2usKCEaKJ57fKN6UahjFP0KFOTkr_y8odlPVWqDh2z3OMwy_iUCRJ5ubiQ4EsOTTNSLKbz8IU2UQ" alt="" /></p>

<p><strong>Configure Scaling Policies:</strong> Keep minimum and maximum instances count
to zero.</p>

<p><strong>Increase Group Size:</strong> Keep the name at default.</p>

<p><strong>Execute Policy:</strong> Click on “Add new alarm”.\</p>

<p><img src="https://lh3.googleusercontent.com/ysaxf1OR2wazrUt1lvdkYI-YRoVdijKoJD4m6DDlGOHld-LO_mtz24-kOmvyTHybJPIEK_VOKV_UC5ybIwwt9jKtJhZ_3N3J1B_4e5P1iAyIsynEpODx6S4gKQ" alt="" /></p>

<p>A popup window will appear for creating a “Cloud Watch Alarm”.\</p>

<p><img src="https://lh3.googleusercontent.com/eqvhUKlpyNKv7vWQiAI95g5oUQxp9KpqQJ0WCEJjFNfCfn-PIBtaYEPf7k8T2BrlCxN8EoF6utdR5c67tMMk-K0CW-upVZIKR1jOTumOoiwic5fEvZndn8_aEA" alt="" /></p>

<p>For this example, we chose CPU Load average as the autoscaling trigger.
Whenever the average CPU load of app servers goes beyond 75% for 5
minutes, autoscaling will trigger the auto-scale-up-policy to launch the
1 instance and attach to load balancer. The application here is CPU
intensive and requires more computing power, so we chose the CPU Load
Average as the autoscale triggering event.</p>

<p>You can choose any Cloudwatch metric to trigger the autoscaling policy.
For example, Disk read/writes, Network In/Out, ELB request count, ELB
latency, etc.</p>

<p><strong>Decrease Group size:</strong>\</p>

<p><img src="https://lh3.googleusercontent.com/wxwMuiWm-72K4zGTx-oT56LdXvjhQXNQZPLg_HXPMb89ey5CEtmOV76euYKqLwbYKm88kOAlmSrW6xfRImjIefcQ7LVFOcUIRoyZ5t3xF_JffVy7R96Ypk8lMg" alt="" /></p>

<p><strong>Configure Notifications:</strong> If you’ve already created notifications,
select one to receive the notifications of Autoscaling events, else skip
this step for now.</p>

<p>Review the details and click on “Create Autoscaling Group”.</p>

<p>Auto Scaling evaluates the health of each Amazon EC2 instance in the
Auto Scaling Group and automatically replaces unhealthy instances in
order to keep the Auto Scaling Group size fixed. That ensures that the
application is getting the expected compute capacity.</p>

<p>In this example, we’ve chosen to scale down the environment when the
average CPU load lowers to 40% for 5 minutes.</p>

<h2><strong>Verify Autoscaling</strong> </h2>

<p>After completing the previous steps, it’s time to test autoscaling.</p>

<p>​1. Update the Autoscaling group minimum and maximum instances count to
2 and 4. You can change these later to fit your specific requirements.</p>

<p>Navigate to EC2-> Auto Scaling Group- > lamp-asg-1.</p>

<p>Right click on “lamp-asg-1” and select “Edit”.</p>

<p>In the “Details” tab, update Desired Min and Max values to 1, and then
save.\</p>

<p><img src="https://lh5.googleusercontent.com/hxxgnuVeJGgoMHPJvsr5oTeghIkuhJv4_hX0U1YtdjpO57N84IN4KmuSk4cO9cYeTH7JiSD9EMVAXCwS8z5v0-lZ3Gf4jW67oGNflBhgr10tiUVHbn9lpjE8oQ" alt="" /></p>

<p>Now, navigate to Services->EC2->Instances.</p>

<p>You can see that a new instance has been launched and attached to ELB.\</p>

<p><img src="https://lh3.googleusercontent.com/GPJHyEzUrO4LtbxCSzT6rHiz_RLPIIkmeIS--__XDuzFiW2dLSZwZhSwkvHG2KvW5CJ6Kx8DpvjEXo8Xgbw7Q8HBa6cfNUu2Mf6XAM6jpx-8LVKxEUMNeXCVHA" alt="" /></p>

<p>\</p>

<p><img src="https://lh3.googleusercontent.com/9_cNWARusMs6T9rypbPZWakid_pmJpMwBWLXuPhwaRlpiXLU5XFjQDGzBAYbPTtjSiupY8tELI5s8ROwgZtKCvfKhxVsagLXYoKCl_MnWqvnqrOGAoqj-wHGOg" alt="" /></p>

<p>If your health check is configured properly, the instance status will
turn into “In Service” rather quickly. Always have a minimum of 2
instances running in order to maintain high availability.</p>

<p>​2. How to Update Launch Configuration: It’s not possible to update the
existing Launch configuration, so you’ll have to create a new Launch
configuration and edit the Autoscaling Group to use that new
configuration.</p>

<p><img src="https://lh5.googleusercontent.com/_bDZv08DtcohHQkG5s0e2_0rd3VnkzImL-87T5wfku5cmvL69tgMhMwKc71Vo-zgVbVImT-HaD0f_fo7dcv5F0JmkbXZGpllnhldKILcPVdgYR7nKZ0qaRniwQ" alt="" /></p>

<p>Now, start the application load run and find out the minimum and maximum
instances required for your application to handle the load. Then update
the AutoScaling Group to meet your needs.</p>

<p>Watch out for  Part 3 of this series to understand <a href="../autoscaling-for-lamp-on-aws-load-test-the-environment-part-3/index.html" title="Autoscaling for LAMP on AWS | Load Test the Environment: Part 3">how to load run an
application</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Autoscaling for LAMP on AWS : Creating a LAMP Stack AMI : Part 1]]></title>
    <link href="http://bvajjala.github.io/blog/2014/03/25/autoscaling-for-lamp-on-aws-creating-a-lamp-stack-ami-part-1/"/>
    <updated>2014-03-25T11:23:04-04:00</updated>
    <id>http://bvajjala.github.io/blog/2014/03/25/autoscaling-for-lamp-on-aws-creating-a-lamp-stack-ami-part-1</id>
    <content type="html"><![CDATA[<h3>Autoscaling for LAMP on AWS |Creating a LAMP Stack AMI : Part 1</h3>

<p>This is part 1 of the Autoscaling for LAMP in AWS series. The
step-by-step guide would walk you through</p>

<p><a href="index.html" title="Autoscaling for LAMP on AWS |Creating a LAMP Stack AMI : Part 1">Part 1: Creating a LAMP Stack
AMI</a></p>

<p><a href="../autoscaling-for-lamp-on-aws-setting-up-austoscaling-groups-part-2/index.html" title="Autoscaling for LAMP on AWS | Setting Up Austoscaling Groups : Part 2">Part 2: Setting up Autoscaling
Groups. </a></p>

<p><a href="../autoscaling-for-lamp-on-aws-load-test-the-environment-part-3/index.html" title="Autoscaling for LAMP on AWS | Load Test the Environment: Part 3">Part 3: Load Test the
environment</a></p>

<p><a href="../autoscaling-for-lamp-on-aws-choosing-an-instance-type-part-4/index.html" title="Autoscaling for LAMP on AWS | Choosing an instance type: Part 4">Part 4: Choose instance
type</a></p>

<p>First, let’s discuss how to prepare the AMI, create an ELB and RDS,
verify the application and terminate the instance.</p>

<h2><strong>Prepare AMI</strong> </h2>

<p>In Autoscaling, create an AMI with all required packages installed. This
AMI will be used as a template to launch instances in autoscaling. For
LAMP Stack, you should install and fine tune the latest versions of
Apache and PHP.</p>

<p>​1. Log in to AWS console.</p>

<p>​2. Navigate to EC2 services. Make sure to switch to the desired region
before launching instances.</p>

<p>​3. Click on “Launch instance”.</p>

<p><img src="https://lh4.googleusercontent.com/hRoQeC1-aimLHiAt0ptacAxdMqlX8w0N19bEmMo8vm31e0n3-PRzWJLd6gg5TUn2FgokMj6n9y72S6gE_XKS0jNx9tHGv5kqD9TKz5qM0vYhu9TIF5FBAG6C-Q" alt="" /></p>

<p>​4. Select your favorite <strong>Linux AMI</strong> in Classic Wizard.</p>

<p><img src="https://lh6.googleusercontent.com/aWfL4g9PfAqaFTg3uI0Ntv52hSxUyPCNKN5Sf8Y4R5zYyjGOmHeA2zi6pGk59F9NiNJa16n27rSk111xlUJUt24oCLPdQfBZMr0k5yhCZpQ6B_ibxzU9hQRKeA" alt="" /></p>

<p>For this article we used CentOS 6.3 from the community AMIs, but
OpenSuse and Ubuntu are also good choices.</p>

<p>​5. Launch a <strong>micro</strong> instance from the selected AMI with the desired
<strong>Security group</strong> and <strong>Key pair</strong>. Remember, this instance is only for
creating an AMI and will be terminated once <strong>LAMP Stack</strong> is installed
on it.</p>

<p><img src="https://lh3.googleusercontent.com/_U5YNCpt3CelshRRvlBG8CLKp8tYd64u1lwFWqqZcN48v3UjL9GBOfHoxL3EXJ9pXOk3tNz0Ig049xbwJa4gIsNvr4Z869PFqwkSfBDkJ8GK1PU9olC7ktBn7w" alt="" /></p>

<p>​6. Now log in to the instance and perform the <strong>PHP</strong> and Apache
installation steps. For this article, we used <strong>Cygwin</strong> to connect the
<strong>Linux</strong> servers. Make sure you open port 22 to allow <strong>SSH</strong> access
using security groups.</p>

<p><img src="https://lh4.googleusercontent.com/Al62wHOtPAxqNRUh_kr47FmQqMSycjLKMJ9zSz47OfIWUVDENcSi6ypdoBaiABQ9Rlr33kid0Be8a-1KuyLDYhFbea4Fw4rdJKxGSoDfbQZP6iClUbDTnUmFGA" alt="" /></p>

<p>We modified the “default” security group to open the SSH port. We
recommend that you not completely open port 22 for SSH, but rather allow
incoming requests to SSH from your specific IP address. In our case the
IP address was 49.206.166.12.</p>

<p><code>
$ ssh –I LAMP_AMI.pem root@ec2-54-254-37-17.ap-southeast-1.compute.amazonaws.commailto:root@ec2-54-254-37-17.ap-southeast-1.compute.amazonaws.com
mailto:root@ec2-54-254-37-17.ap-southeast-1.compute.amazonaws.com
$ yum install httpd.x86_64 httpd-devel.x86_64 mod_ssl.x86_64 php.x86_64 php-common.x86_64 php-devel.x86_64 php-gd.x86_64 php-mbstring.x86_64 php-mysql.x86_64 php-pdo.x86_64 php-soap.x86_64 php-xml.x86_64 php-xmlrpc.x86_64 php-pecl-apc-devel.x86_64 php-pecl-memcache.x86_64 -y
</code></p>

<p>Once you’ve successfully executed these commands, Apache and PHP will
install. Note that the commands we’ve used are specific to CentOS 6.3.
Choosing a different OS or a different CentOS may cause these commands
to fail to execute. T<strong>he php modules listed above are required for
WordPress setup and they may vary depending upon your requirements.</strong></p>

<p>Now update the PHP and Apache configurations for your Instance types and
for the expected load on application. We used t1.Micro for this article.
Keep in mind that a production system’s instance types need to be chosen
very carefully, and that the software must be tuned to those particular
types.</p>

<p><strong><em>Read more on selecting instance types in <a href="../autoscaling-for-lamp-on-aws-choosing-an-instance-type-part-4/index.html" title="Autoscaling for LAMP on AWS | Choosing an instance type: Part 4">Part 4 of this
series.</a></em></strong></p>

<p>Install Postfix to send email notification for the script used in the
next step.</p>

<p><code>
$ yum install postfix  
$ chkconfig –level 2345 postfix on
$ chkconfig –level 2345 httpd off
</code></p>

<p>​7. Now all of the required packages are installed and fine-tuned.</p>

<p>So, how does one deploy the code into AMI?</p>

<p>The method described here automates the deployment. One cron job will be
included in AMI, and it will download and deploy the latest available S3
code. That means that code updates will deploy to S3 every time, but not
to instances. Every time a new instance is up, the instance will
automatically download updates from the S3 bucket and deploy them.</p>

<p>What follows is a script scheduled for machine boot-up. It requires
updating based on specific user configurations and file paths.</p>

<p>```</p>

<h1>!/bin/bash</h1>

<p>S3_URL= “<a href="http://s3-ap-southeast-1.amazonaws.com/lamp-deploy/wordpress.zip%E2%80%9D">http://s3-ap-southeast-1.amazonaws.com/lamp-deploy/wordpress.zip%E2%80%9D</a> #Change the following paths as per your requirement.
DOCUMENT_ROOT=</var/www/html>
TEMP_LOC=</tmp>
APACHE_RESTART=<code>/etc/init.d/httpd restart</code></p>

<h1>Get the instance ID from AWS metadata.</h1>

<p>INSTANCE_ID=<code>curl http://169.254.169.254/latest/meta-data/instance-id</code></p>

<h3>download the latest code from s3 and deploy</h3>

<p>cd /tmp
wget $S3_URL
if [ $? –ne 0 ]
then
pkill -9 httpd
mail –s “Code Download Failed from S3##$INSTANCE_ID”  <a href="&#x6d;&#x61;&#x69;&#108;&#116;&#x6f;&#58;&#116;&#x65;&#x73;&#x74;&#64;&#116;&#x65;&#x73;&#116;&#x2e;&#x63;&#x6f;&#109;">&#116;&#101;&#x73;&#x74;&#x40;&#x74;&#101;&#x73;&#x74;&#x2e;&#x63;&#111;&#x6d;</a> #Provide valid email ID here”
exit 1
fi
unzip wordpress.zip
rm –rf  &lt;/var/www/html/<em>>
cp –r wordpress/</em> $DOCUMENT_ROOT
chmod 775 –R $DOCUMENT_ROOT
chown –R apache.root $DOCUMENT_ROOT
$APACHE_RESTART
if [ $? –ne 0 ]
then
pkill -9 httpd
mail –s “Apache startup Failed- $INSTANCE_ID”  <a href="&#109;&#97;&#x69;&#x6c;&#x74;&#x6f;&#x3a;&#116;&#101;&#x73;&#116;&#x40;&#x74;&#x65;&#x73;&#116;&#46;&#x63;&#111;&#109;">&#x74;&#101;&#115;&#116;&#64;&#x74;&#x65;&#x73;&#116;&#x2e;&#99;&#111;&#109;</a> #Provide valid email ID here”
exit 1
fi</p>

<h2>script ends here</h2>

<p>```</p>

<p>Put this bash script into a file in /opt/ directory:</p>

<p><code>
$vim /opt/auto-deploy.sh
$chmod +x /opt/auto-deploy.sh
</code></p>

<p>Open the Crontab and add this script to start at machine boot up:</p>

<p><code>
$ crontab –e
</code></p>

<p>Add the following script:</p>

<p><img src="https://lh4.googleusercontent.com/ZiqV0hI1ocrhmDqqLubt01OQdBcmJZqWhNciW6sbPfEz2Iwr99cxoNK4U5actZ6Vqdqat8asF-IwxjJQrVKiutlBZq6A74t9sp1wA0ezqCDbSR09YOjTQrJblX_8VShJfMA" alt="" /></p>

<p>Save your changes and deploy the code by running the script to test
whether or not the application is working as expected. This step is
mandatory before creating an AMI. If you find any issues with the code
or PHP/Apache settings, be sure to fix them before creating an AMI.</p>

<p>Bundle and Upload the Code to S3</p>

<ol>
<li><p>Update the code with RDS DB configuration parameters.</p></li>
<li><p>Now zip the working copy of the code and upload it to the S3
location. The S3 location should match the location in the script,
and also match the zip file name.</p></li>
<li><p>Upload the zip file to the S3 bucket that matches the script. You
can upload the zip file by using the console or any third party tool
like Cloudberry.</p></li>
<li><p>Grant read permissions to download the code from S3 to app servers.</p></li>
</ol>


<h2><strong>Create the ELB</strong> </h2>

<p>Go to Services-> EC2 &ndash;> Load Balancers and select “<strong>Create Load
Balancer</strong>”.</p>

<p><img src="https://lh5.googleusercontent.com/w-ZRahemXgWVTJcIwpwJYfdXgp7kcmUs23IYzjgdEpwUuYiCkoLJg2dnLs0-5fe8U0UFG1_3qyaNggPesGGHGUq1PwQH5MMo-QowBXfuhGSNthk65DDg5Oc1OA" alt="" /></p>

<p><img src="https://lh5.googleusercontent.com/JU0AmjRaIgFbWa8mdGz2qTlbYTU7wKWiOa93uUVuu-RDO5PPfEVhV1ggUBZ95rr5_z637SffLdwYgHb5srqZlj9GfcL-or3aG3xWsqb9Sd4kJ24LKZ8_84d_YA" alt="" /></p>

<p>Keep Healthy/Unhealthy threshold limits to 4 because that’s proven to be
an ideal value. Also make sure index.html is available in the Document
root. ELB looks for the index.html as a health check and removes the
instance from the load balancer if it doesn’t get the 200 response.
Create the required security groups and key pair for the autoscaling
instances.</p>

<h2><strong>Create RDS</strong> </h2>

<p>​1. Go to Services &ndash;> RDS and select the <strong>MySQL</strong> engine.</p>

<p><img src="https://lh5.googleusercontent.com/dgMcoX4gkePTWwEYT8soz9RdvW3iMPmmlVlnkgczHmwIDpfmh39BhRUmWRBEdbR0f6FMJi3LtaSW6z_sRhBmk_WYLfls0bv8VQ8r9PFPl52WOX0B12-vCLKBEQ" alt="" /></p>

<p>​2. Select instance types, provide the details for all required fields
and launch the instance. The RDS configuration details chosen for this
article can be seen below.</p>

<p>How should you select the DB instance type? There are many monitoring
tools available for monitoring MySQL performance. If AWS RDS is used for
MySQL, then it’s important to consider CloudWatch metrics. Since it’s
not possible to install agents in RDS, you can rely upon CloudWatch
metrics.</p>

<p>By default, CloudWatch contains all required RDS monitoring metrics. Be
sure to monitor the memory, CPU, DB connections and network I/O before
you scale up the server.</p>

<p>Ideally, m1.small RDS can handle up to 75 concurrent connections easily.
but that depends upon the DB queries and the code.</p>

<p>​3. After launching RDS, open the 3306 port to the app servers group.</p>

<p>​4. Import the DB and try connecting to the application. Then use
standard MySQL commands to import the dump.</p>

<p><strong>Example:</strong> mysql –h rds-endpoint –u user –ppasswwd databasename &lt;
dump.sql</p>

<h2><strong>Verify the Application</strong> </h2>

<p>At this point, it’s mandatory that you thoroughly verify the
application. Make sure to check Login/logout, upload/download and any
other relevant verifications. Create an AMI only after making sure that
the application is working as expected. Fix any issues before proceeding
to the next step.</p>

<h3><strong>Create an AMI</strong></h3>

<p>​1. Delete the command history:</p>

<p><code>
$ history -c
</code></p>

<p>Delete the deployed code and logs files and make things as clean as
possible.</p>

<p>​2. Create an AMI using the micro instance that you’ve configured.</p>

<p>Go to AWS Console->Services->EC2, right click on the instance, and
select “Create Image” (EBS AMI).</p>

<p><img src="https://lh4.googleusercontent.com/pR5iFmQYgO6FygwUB1SNh52dtHhrTr4TDk_G9fd6wlh1ds3V5gnbvhqYdn4yPOPRuQ7JZXwO54xuguOEoczq9yhVx1gsuHuZbVmCRgVFbida6ciJxv0EhNhwdQ" alt="" /></p>

<p>Name the AMI using a date as the naming convention. <strong>Do not</strong> select
“<strong>No reboot</strong>”. Instead, allow it to reboot while creating the AMI. The
reboot will give you a consistent snapshot of EBS.</p>

<p><img src="https://lh5.googleusercontent.com/5vWSfAF_enz-JCR8PlW-hDts2pvtUSI8yRFYkx8H27K0UdRCntJjTgcHGODGJpiGkXfFpe-XGva-EZUFF5gEDRcPcw5o8xc_8n1ueqYQaK8hpY9WolFLUdrHRw" alt="" /></p>

<p>In a few minutes an AMI will be created and made available.</p>

<p>Keep the root partition as minimal as possible because that helps to
prevent bugs. You don’t need large space for root partition in autoscale
because these instances keep rotating.</p>

<h2><strong>Terminate the Instance</strong> </h2>

<p>Finally, terminate the instance by right clicking on the instance and
selecting “Terminate”. Keep the ELB and RDS running.</p>

<p><strong><em>Watch out for Part 2, same time tomorrow, on how to setup autoscaling
groups!</em></strong></p>

<p><strong>Update</strong>: Check part 2 on how to setup autoscaling groups
<a href="../autoscaling-for-lamp-on-aws-setting-up-austoscaling-groups-part-2/index.html" title="Autoscaling for LAMP on AWS | Setting Up Austoscaling Groups : Part 2">here</a>.</p>
]]></content>
  </entry>
  
</feed>
