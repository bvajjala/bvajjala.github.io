
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Balaji Vajjala's Blog</title>
  <meta name="author" content="Balaji Vajjala">

  
  <meta name="description" content="A Case Study on using 100% Cloud-based Resources with Automated Software Delivery We
help – typically large – organizations create one-click software &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://bvajjala.github.io">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Balaji Vajjala's Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
<link href='http://fonts.googleapis.com/css?family=Fjalla+One' rel='stylesheet' type='text/css'>
  

</head>

<body   class="collapse-sidebar sidebar-footer" >
  <header role="banner">
	<div class="header-title"><a href="/">Balaji Vajjala's Blog</a></div>


	<br><div class="header-subtitle">A DevOps Blog from Trenches</div>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:bvajjala.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/home/">Home</a></li> 
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
  
    
      <h1 class="entry-title"><a href="/blog/2014/04/04/a-case-study-on-using-100-percent-cloud-based-resources-with-automated-software-delivery/">A Case Study on Using 100% Cloud Based Resources With Automated Software Delivery</a></h1>
      
      
    
      <p class="meta">
        








  


<time datetime="2014-04-04T14:08:01-04:00" pubdate data-updated="true">Apr 4<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>A Case Study on using 100% Cloud-based Resources with Automated Software Delivery</h1>

<p><a href="http://stelligent.com" title="Stelligent Continuous Delivery in the Cloud">We</a>
help – typically large – organizations create one-click software
delivery systems so that they can deliver software in a more rapid,
reliable and repeatable manner (AKA <a href="http://www.amazon.com/Continuous-Delivery-Deployment-Automation-Addison-Wesley/dp/0321601912" title="Continuous Delivery book">Continuous
Delivery</a>).
The only way this works is when Development works with Operations. As
has been written elsewhere in this series, this means changing the
hearts and minds of people because most organizations are used to
working in ‘siloed’ environments. In this entry, I focus on
implementation, by describing a real-world case study in which we have
brought Continuous Delivery Operations to the Cloud consisting of a team
of Systems and Software Engineers.  </p>

<p>For years, we’ve helped customers in <a href="http://www.amazon.com/gp/product/0321336380/?tag=integratecom-20" title="Continuous Integration">Continuous
Integration</a>
and Testing so more of our work was with Developers and Testers. Several
years ago, we hired a Sys Admin/Engineer/DBA who was passionate about
automation. As a result of this, we began assembling multiple two-person
“<a href="http://en.wikipedia.org/wiki/DevOps" title="DevOps on Wikipedia">DevOps</a>”
teams consisting of a Software Engineer and a Systems Engineer both of
whom being big-picture thinkers and not just “Developers” or “Sys
Admins”. These days, we put together these targeted teams of Continuous
Delivery and Cloud experts with hands-on experience as Software
Engineers and Systems Engineers so that organizations can deliver
software as quickly and as often as the business requires.</p>

<p>A couple of years ago we already had a few people in the company who
were experimenting with using Cloud infrastructures so we thought this
would be a great opportunity in providing cloud-based delivery
solutions. In this case study, I cover a project we are currently
working on for a large organization. It is a new Java-based web services
project so we’ve been able to implement solutions using our recommended
software delivery patterns rather than being constrained by legacy tools
or decisions. However, as I note, we aren’t without constraints on this
project. If I were you, I’d call “BS!” on any “case study” in which
everything went flawlessly and assume it was an extremely small or a
theoretical project in the author’s mind. This is the real deal. Enough
said, on to the case study.      </p>

<p><img src="https://s3.amazonaws.com/stelligent_img/aws_tools.jpg" alt="AWS Tools" /></p>

<p><strong>Fast Facts</strong></p>

<p><strong>Industry</strong>: Healthcare, Public Sector\
<strong>Profile</strong>: The customer is making available to all, free of charge, a
series of software specifications and open source software modules that
together make up an oncology-extended Electronic Health Record
capability.\
<strong>Key Business Issues</strong>: The customer was seeking that all team members
are provided “unencumbered” access to infrastructure resources without
the usual “request and wait” queued-based procedures present in most
organizations \
<strong>Stakeholders</strong>: Over 100 people consisting of Developers, Testers,
Analysts, Architects, and Project Management.\
<strong>Solution:</strong> Continuous Delivery Operations in the Cloud\
<strong>Key Tools/Technologies</strong>: Amazon Web Services  - AWS (Elastic Computer
Cloud (EC2), (Simple Storage Service (S3), Elastic Block Storage (EBS),
etc.), Jenkins, JIRA Studio, Ant, Ivy, Tomcat and PostgreSQL</p>

<p><strong>The Business Problem</strong>\
The customer was used to dealing with long drawn-out processes with
Operations teams that lacked agility. They were accustomed to submitting
Word documents via email to an Operations teams, attending multiple
meetings and getting their environments setup weeks or months later. We
were compelled to develop a solution that reduced or eliminated these
problems that are all too common in many large organizations (Note: each
problem is identified as a letter and number, for example: P1, and
referred to later):</p>

<ol>
<li>Unable to deliver software to users on demand (P1)</li>
<li>Queued requests for provisioned instances (P2)</li>
<li>Unable to reprovision precise target environment configuration on
demand (P3)</li>
<li>Unable to provision instances on demand (P4)</li>
<li>Configuration errors in target environments presenting deployment
bottlenecks while Operations and Development teams troubleshoot
errors (P5)</li>
<li>Underutilized instances (P6)</li>
<li>No visibility into purpose of instance (P7)</li>
<li>No visibility into the costs of instance (P8)</li>
<li>Users cannot terminate instances (P9)</li>
<li>Increased Systems Operations personnel costs (P10)</li>
</ol>


<p><strong>Our Team</strong>\
We put together a four-person team to create a solution for delivering
software and managing the internal Systems Operations for this 100+
person project. We also hired a part-time Security expert. The team
consists of two Systems Engineers and two Software Engineers focused on
Continuous Delivery and the Cloud. One of the Software Engineers is the
Solutions Architect/PM for our team.</p>

<p><strong>Our Solution</strong>\
We began with the end in mind based on the customer’s desire for
unencumbered access to resources. To us, “unencumbered” did not mean
without controls; it meant providing automated services over queued
“request and wait for the Ops guy to fulfill the request” processes. Our
approach is that every resource is in the cloud: Software as a Service
(SaaS), Platform as a Service (PaaS) or Infrastructure as a Service
(IaaS) to reduce operations costs (P10) and increase efficiency. In
doing this, effectively all project resources are available on demand in
the cloud. We have also automated the software delivery process to
Development and Test environments and working on the process of
one-click delivery to production. I’ve identified the problem we’re
solving – from above – in parentheses (P1, P8, etc.). The solution
includes:</p>

<ul>
<li><strong>On-Demand Provisioning</strong> – All hardware is provided via EC2’s
virtual instances in the cloud, on demand (P2). We’ve developed a
“Provisioner” (PaaS) that provides any authorized team member the
capability to click a button and get their project-specific target
environment (P3) in the AWS’ cloud – thus, providing unencumbered
access to hardware resources. (P4) The Provisioner provides all
authorized team members the capability to monitor instance usage
(P6) and adjust accordingly. Users can terminate their own virtual
instances (P9).</li>
<li><strong>Continuous Delivery</strong> Solution so that the team can deliver
software to users on demand (P1):

<ul>
<li>Automated build script using Ant – used to drive most of the
other automation tools</li>
<li>Dependency Management using Ivy. We will be adding Sonatype
Nexus</li>
<li>Database Integration/Change using Ant and Liquibase</li>
<li>Automated Static Analysis using Sonar (with CheckStyle,
FindBugs, JDepend, and Cobertura)</li>
<li>Test framework hooks for running JUnit, etc.</li>
<li>Reusing remote Deployment custom Ant scripts that use Java
Secure Channel and Web container configuration. However, we will
be starting a process of using a more robust tool such as
ControlTier to perform deployment</li>
<li>Automated document generation using Grand, SchemaSpy (ERDs) and
UMLGraph</li>
<li>Continuous Integration server using Hudson</li>
<li>Continuous Delivery pipeline system – we are customizing Hudson
to emulate a Deployment Pipeline</li>
</ul>
</li>
<li><strong>Issue Tracking</strong> – We’re using the JIRA Studio SaaS product from
Atlassian (P10), which provides issue tracking, version-control
repository, online code review and a Wiki. We also manage the
relationship with the vendor and perform the user administration
including workflow management and reporting.</li>
<li><strong>Development Infrastructure</strong>&ndash; There were numerous tools selected
by the customer for Requirements Management and Test Management and
Execution including HP QC, LoadRunner, SoapUI, Jama Contour. Many of
these tools were installed and managed by our team onto the EC2
instances</li>
<li><strong>Instance Management</strong>&ndash; Any authorized team member is able to
monitor virtual instance usage by viewing a web-based dashboard (P6,
P7, P8) we developed. This helps to determine instances that should
no longer be in use or may be eating up too much money. There is a
policy that test instances (e.g. Sprint Testing) are terminated no
less than every two weeks. This promotes ephemeral environments and
test automation.</li>
<li><strong>Deployment to Production</strong> – Much of the pre-production
infrastructure is in place, but we will be adding some additional
automation features to make it available to users in production
(P1). The deployment sites are unique in that we aren’t hosting a
single instance used by all users and it’s likely the software will
be installed at each site. One plan is to deploy separate instances
to the cloud or to virtual instances that are shipped to the user
centers</li>
<li><p><strong>System Monitoring and Disaster Recovery</strong> – Using
<a href="https://www.cloudkick.com/" title="CloudKick AWS Monitoring">CloudKick</a>
to notify us of instance errors or anomalies. EC2 provides us with
some monitoring as well. We will be implementing a more robust
monitoring solution using Nagios or something similar in the coming
months. Through automation and supporting process, we’ve implemented
a disaster recovery solution.</p></li>
</ul>


<p><strong>Benefits</strong>\
The benefits are primarily around removing the common bottlenecks from
processes so that software can be delivered to users and team members
more often. Also, we think our approach to providing on-demand services
over queued-based requests increases agility and significantly reduces
costs. Here are some of the benefits:</p>

<ul>
<li><strong>Deliver software more often</strong> – to users and internally (testers,
managers, demos)</li>
<li><strong>Deliver software more quickly</strong> – since the software delivery
process is automated, we identify the SVN tag and click a button to
deliver the software to any environment</li>
<li><strong>Software delivery is rapid, reliable and repeatable</strong>. All
resources can be reproduced with a single click – source code,
configuration, environment configuration, database and network
configuration is all checked in and versioned and part of a single
delivery system.</li>
<li><strong>Increased visibility</strong> to environments and other resources – All
preconfigured virtual hardware instances are available for any
project member to provision without needing to submit forms or
attend countless meetings</li>
</ul>


<p><strong>Tools</strong>\
Here are some of the tools we are using to deliver this solution. Some
of the tools were chosen by our team exclusively and some by other
stakeholders on the project.</p>

<ul>
<li><a href="http://aws.amazon.com/ec2/" title="AWS EC2"><strong>AWS EC2</strong></a>&ndash; Cloud-based
virtual hardware instances</li>
<li><a href="http://aws.amazon.com/s3/" title="AWS S3"><strong>AWS S3</strong></a> – Cloud-based
storage. We use S3 to store temporary software binaries and backups</li>
<li><a href="http://aws.amazon.com/ebs/" title="AWS EBS"><strong>AWS EBS</strong></a> – Elastic Block
Storage. We use EBS to attach PostgreSQL data volumes</li>
<li><a href="http://ant.apache.org/" title="Ant"><strong>Ant</strong></a> – Build Automation</li>
<li><a href="https://www.cloudkick.com/" title="CloudKick"><strong>CloudKick</strong></a> – Real-time
Cloud instance monitoring</li>
<li><a href="http://controltier.com/" title="ControlTier"><strong>ControlTier</strong></a> –
Deployment Automation. Not implemented yet.</li>
<li><strong>HP LoadRunner</strong> – Load Testing</li>
<li><strong>HP Quality Center (QC)</strong> – Test Management and Orchestration</li>
<li><strong>Ivy</strong> – Dependency Management</li>
<li><strong>Jama Contor</strong>&ndash; Requirements Management</li>
<li><a href="http://jenkins-ci.org/" title="Jenkins"><strong>Jenkins</strong></a> – Continuous
Integration Server</li>
<li><a href="http://www.atlassian.com/hosted/studio/" title="JIRA Studio"><strong>JIRA
Studio</strong></a>&ndash;
Issue Tracking, Code Review, Version-Control, Wiki</li>
<li><strong>JUnit</strong> – Unit and Component Testing</li>
<li><a href="http://www.liquibase.org/" title="Liquibase"><strong>Liquibase</strong></a> – Automated
database change management</li>
<li><strong>Nagios</strong> – or Zenoss. Not implemented yet</li>
<li><strong>Nexus</strong> – Dependency Management Repository Manager (not
implemented yet)</li>
<li><strong>PostgreSQL</strong> – Database used by Development team. We’ve written
script that automate database change management</li>
<li><strong>Provisioner</strong> (Custom Web-based) – Target Environment Provisioning
and Virtual Instance Monitoring</li>
<li><a href="http://www.puppetlabs.com/" title="Puppet"><strong>Puppet</strong></a> – Systems
Configuration Management</li>
<li><strong>QTP</strong> – Test Automation</li>
<li><strong>SoapUI</strong> – Web Services Test Automation</li>
<li><a href="http://www.sonarsource.org/" title="Sonar"><strong>Sonar</strong></a> – code quality
analysis (Includes CheckStyle, PMD, Cobertura, etc.)</li>
<li><strong>Tomcat/JBoss</strong> – Web container used by Development. We’ve written
script to automate the deployment and container configuration</li>
</ul>


<p><strong>Solutions we’re in the process of Implementing</strong>\
We’re less than a year into the project and have much more work to do.
Here are a few projects we’re in the process or will be starting to
implement soon:</p>

<ul>
<li>System Configuration Management – We’ve started using Puppet, but we
are expanding how it’s being used in the future</li>
<li>Deployment Automation – The move to a more robust Deployment
automation tool such as ControlTier</li>
<li>Development Infrastructure Automation – Automating the provisioning
and configuration of tools such as HP QC in a cloud environment.
etc.</li>
</ul>


<p><strong>What we would do Differently</strong>\
Typically, if we were start a Java-based project and recommend tools
around testing, we might choose the following tools for testing,
requirements and test management based on the particular need:</p>

<ul>
<li>Selenium with
<a href="http://saucelabs.com/" title="SauceLabs Selenium">SauceLabs</a></li>
<li>JIRA Studio for Test Management</li>
<li>JIRA Studio for Requirements Management</li>
<li>JMeter – or other open source tool – for Load Testing</li>
</ul>


<p>However, like most projects there are many stakeholders who have their
preferred approach and tools they are familiar in using, the same way
our team does. Overall, we are pleased with how things are going so far
and the customer is happy with the infrastructure and approach that is
in place at this time. I could probably do another case study on dealing
with multiple SaaS vendors, but I will leave that for another post.</p>

<p><strong>Summary</strong>\
There’s much more I could have written about what we’re doing, but I
hope this gives you a decent perspective of how we’ve implemented a
DevOps philosophy with Continuous Delivery and the Cloud and how this
has led our customer to more a service-based, unencumbered and agile
environment. </p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
  
    
      <h1 class="entry-title"><a href="/blog/2014/04/04/tutotial-continuous-delivery-in-the-cloud-part-6-of-6/">Tutotial : Continuous Delivery in the Cloud Part 6 of 6</a></h1>
      
      
    
      <p class="meta">
        








  


<time datetime="2014-04-04T14:00:06-04:00" pubdate data-updated="true">Apr 4<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In<a href="http://www.stelligent.com/wp-admin/continuous-delivery-in-the-cloud-case-study-for-the-sea-to-shore-alliance-introduction-part-1-of-6">part 1 of this series</a>, I introduced the<a href="http://refcardz.dzone.com/refcardz/continuous-delivery-patterns">Continuous Delivery</a> (CD) pipeline for the<a href="http://manatees.mapntracker.com/wildtracks/">Manatee Tracking application</a>.
In<a href="../continuous-delivery-in-the-cloud-cd-pipeline-part-2-of-6/index.html">part 2</a>,I went over how we use this CD pipeline to deliver software from checkin to production.
In<a href="../continuous-delivery-in-the-cloud-cloudformation-part-3-of-6/index.html">part 3</a>,we focused on how CloudFormation is used to script the virtual AWS components that create the Manatee infrastructure.
Then in<a href="../continuous-delivery-in-the-cloud-dynamic-configuration-part-4-of-6/index.html">part 4</a>, we focused on a “property file less” environment by dynamically setting and retrieving properties.
<a href="../continuous-delivery-in-the-cloud-deployment-automation-part-5-of-6/index.html">Part 5</a> explained how we use Capistrano for scripting our deployment. A list of topics for each of the articles is summarized below:</p>

<p><a href="../continuous-delivery-in-the-cloud-case-study-for-the-sea-to-shore-alliance-introduction-part-1-of-6/index.html">Part 1: Introduction</a>
– Introduction to continuous delivery in the cloud and the rest of the articles;
 <a href="../continuous-delivery-in-the-cloud-cd-pipeline-part-2-of-6/index.html">Part 2: CD Pipeline</a>
– In-depth look at the CD Pipeline;
 <a href="../continuous-delivery-in-the-cloud-cloudformation-part-3-of-6/index.html">Part 3: CloudFormation</a>
– Scripted virtual resource provisioning;
 <a href="../continuous-delivery-in-the-cloud-dynamic-configuration-part-4-of-6/index.html">Part 4: Dynamic Configuration</a>
– “Property file less” infrastructure;
 <a href="../continuous-delivery-in-the-cloud-deployment-automation-part-5-of-6/index.html">Part 5: Deployment Automation</a>
– Scripted deployment orchestration;
 Part 6: Infrastructure Automation – What you’re reading now;</p>

<p>In this part of the series, I am going to show how we use <a href="http://puppetlabs.com/">Puppet</a> in combination with <a href="http://aws.amazon.com/cloudformation/">CloudFormation</a> to script our target environment infrastructure, preparing it for a Manatee application deployment.</p>

<p><strong>What is Puppet?</strong></p>

<p>Puppet is a Ruby based infrastructure automation tool. Puppet is primarily used for provisioning environments and managing configuration. Puppet is made to support multiple operating systems, making your infrastructure automation cross-platform.</p>

<p><strong>How does Puppet work?</strong></p>

<p>Puppet uses a library called <a href="http://www.puppetlabs.com/puppet/related-projects/facter/">Facter</a> which collects facts about your system. Facter returns details such as the operating system, architecture, IP address, etc. Puppet uses these facts to make decisions for provisioning your environment. Below is an example of the facts returned by Facter.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># Facter architecture =&gt; i386 
</span><span class='line'>... 
</span><span class='line'>ipaddress =&gt; 172.16.182.129 
</span><span class='line'>is_virtual =&gt; true 
</span><span class='line'>kernel =&gt; Linux 
</span><span class='line'>kernelmajversion =&gt; 2.6 
</span><span class='line'>... 
</span><span class='line'>operatingsystem =&gt; CentOS 
</span><span class='line'>operatingsystemrelease =&gt; 5.5 
</span><span class='line'>physicalprocessorcount =&gt; 0 
</span><span class='line'>processor0 =&gt; Intel(R) Core(TM)2 Duo CPU     P8800  @ 2.66GHz 
</span><span class='line'>processorcount =&gt; 1 productname =&gt; VMware Virtual Platform</span></code></pre></td></tr></table></div></figure>


<p>Puppet uses the operating system <em>fact</em> to decide the service name as show below:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>case $operatingsystem {
</span><span class='line'>   centos, redhat: {
</span><span class='line'>     $service_name = 'ntpd'
</span><span class='line'>     $conf_file    = 'ntp.conf.el'
</span><span class='line'>   }
</span><span class='line'> }`</span></code></pre></td></tr></table></div></figure>


<p>With this case statement, if the operating environment is either <code>centos</code> or <code>redhat</code> the service name <code>ntpd</code> and the configuration file <code>ntp.conf.el</code> are used.</p>

<p>Puppet is declarative by nature. Inside a Puppet <em>module</em> you define the end state the environment end state after the Puppet run. Puppet enforces this state during the run. If at any point the environment does not conform to the desired state, the Puppet run fails.</p>

<p><strong>Anatomy of a Puppet Module</strong></p>

<p>To script the infrastructure Puppet uses <em>modules</em> for organizing related code to perform a specific task. A Puppet <em>module</em> has multiple sub directories that contain resources for performing the intended task. Below are these resources:</p>

<p><code>manifests/</code>: Contains the manifest class files for defining how to perform the intended task
 <code>files/</code>: Contains static files that the node can download during the installation
 <code>lib/</code>: Contains plugins
 <code>templates/</code>: Contains templates which can be used by the <em>module</em>’s manifests
 <code>tests/</code>: Contains tests for the <em>module</em></p>

<p>Puppet also uses <em>manifests</em> to manage multiple <em>modules</em> together <code>site.pp</code>. Puppet also uses another manifest to define what to install on each node, <code>default.pp</code>.</p>

<p><strong>How to run Puppet</strong></p>

<p>Puppet can be run using either a master agent configuration or a solo installation (puppet apply).</p>

<p><strong>Master Agent:</strong> With a master agent installation, you configure one main master puppet node which manages and configure all of your agent nodes (target environments). The master initiates the installation of the agent and manages it throughout its lifecycle. This model enables infrastructure changes to your agents in parallel by controlling the master node.</p>

<p><strong>Solo:</strong> In a solo Puppet run, it’s up to the user to place the desired Puppet <em>module</em> on the target environment. Once the <em>module</em> is on the target environment, the user needs run
<code>puppet apply --modulepath=/path/to/modules/ /path/to/site.pp</code>. Puppet will then provision the server with the provided <em>modules</em> and <code>site.pp</code> without relying on another node.</p>

<p><strong>Why do we use Puppet?</strong></p>

<p>We use Puppet to script and automate our infrastructure — making our environment provisioning repeatable, fully automated, and less error prone. Furthermore, scripting our environments gives us complete control over our infrastructure and the ability to terminate and recreate environments as often as they choose.</p>

<p><strong>Puppet for Manatees</strong></p>

<p>In the Manatee infrastructure, we use Puppet for provisioning our target environments. I am going to go through our manifests and <em>modules</em> while explaining their use and purpose. In our Manatee infrastructure, we create a new target environment as part of the CD pipeline – discussed in part 2 of the series,<a href="../continuous-delivery-in-the-cloud-cd-pipeline-part-2-of-6/index.html">CD Pipeline</a>.
Below I provide a high-level summary of the environment provisioning process:</p>

<p>​1. CloudFormation dynamically creates a params.pp manifest with AWS variables
2. CloudFormation runs puppet apply as part of UserData
3. Puppet runs the <em>modules</em> defined in hosts/default.pp.
4. Cucumber acceptance tests are run to verify the infrastructure was provisioned correctly.</p>

<p>Now that we know at a high-level what’s being done during the environment provisioning, let’s take a deeper look at the scripts in more detail. The actual scripts can be found here: <a href="http://code.google.com/p/sea2shore/source/browse/trunk/src/infrastructure/puppet/">Puppet</a></p>

<p>First we will start off with the manifests.</p>

<p>The <a href="http://code.google.com/p/sea2shore/source/browse/trunk/src/infrastructure/puppet/manifests/site.pp">site.pp</a> (shown below) serves two purposes. It loads the other manifests <code>default.pp</code>, <code>params.pp</code> and also sets stages <code>pre</code>, <code>main</code> and <code>post</code>.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>import "hosts/*" import "classes/*"
</span><span class='line'>
</span><span class='line'>stage { [pre, post]: }
</span><span class='line'> Stage[pre] -&gt; Stage[main] -&gt; Stage[post]</span></code></pre></td></tr></table></div></figure>


<p>These stages are used to define the order in which Puppet <em>modules</em> should be run. If the Puppet <em>module</em> is defined as <code>pre</code>,it will run before Puppet <em>modules</em> defined as <code>main</code> or <code>post</code>. Moreover if stages aren’t defined,  Puppet will determine the order of execution. The <code>default.pp</code> (referenced below) shows how staging defined for executing puppet <em>modules</em>.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>node default {
</span><span class='line'>   class { "params": stage =&gt; pre }
</span><span class='line'>   class { "java": stage =&gt; pre }
</span><span class='line'>   class { "system": stage =&gt; pre }
</span><span class='line'>   class { "tomcat6": stage =&gt; main }
</span><span class='line'>   class { "postgresql": stage =&gt; main }
</span><span class='line'>   class { "subversion": stage =&gt; main }
</span><span class='line'>   class { "httpd": stage =&gt; main }
</span><span class='line'>   class { "groovy": stage =&gt; main } 
</span><span class='line'> }</span></code></pre></td></tr></table></div></figure>


<p>The <a href="http://code.google.com/p/sea2shore/source/browse/trunk/src/infrastructure/puppet/manifests/hosts/default.pp">default.pp</a> manifest also defines which Puppet <em>modules</em> to use for provisioning the target environment.</p>

<p><a href="http://code.google.com/p/sea2shore/source/browse/trunk/src/infrastructure/puppet/manifests/classes/params.pp">params.pp</a> (shown below), loaded from site.pp, is dynamically created using CloudFormation. <code>params.pp</code> is used for setting AWS property values that are used later in the Puppet <em>modules</em>.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> class params {
</span><span class='line'>   $s3_bucket = ''   
</span><span class='line'>   $application_name = ''
</span><span class='line'>   $hosted_zone = ''
</span><span class='line'>   $access_key = ''
</span><span class='line'>   $secret_access_key = ''
</span><span class='line'>   $jenkins_internal_ip = '' 
</span><span class='line'> }</span></code></pre></td></tr></table></div></figure>


<p>Now that we have an overview of the manifests used, lets take a look at the Puppet <em>modules</em> themselves.</p>

<p>In our <a href="http://code.google.com/p/sea2shore/source/browse/trunk/src/infrastructure/puppet/modules/java/manifests/init.pp">java</a> <em>module</em>, which is run in the <code>pre</code> stage, we are running a simple installation using packages. This is easily dealt with in Puppet by using the <code>package</code> resource. This relies on Puppet’s knowledge of the <em>operating system</em> and the <em>package manager</em>. Puppet simply installs the package that is declared.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>class java {
</span><span class='line'>   package {  "java-1.6.0-openjdk": ensure =&gt; "installed" } 
</span><span class='line'> }</span></code></pre></td></tr></table></div></figure>


<p>The next <em>module</em> we’ll discuss is <a href="http://code.google.com/p/sea2shore/source/browse/trunk/src/infrastructure/puppet/modules/system/manifests/init.pp">system</a>. System is also run during the <code>pre</code> stage and is used for the setup of all the extra operations that don’t necessarily need their own <em>module</em>. These actions include setting up general packages (gcc, make, etc.), installing ruby gems (AWS sdk, bundler, etc.), and downloading custom scripts used on the target environment.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> class system {
</span><span class='line'>
</span><span class='line'>  include params
</span><span class='line'>
</span><span class='line'>  $access_key = $params::access_key
</span><span class='line'>  $secret_access_key = $params::secret_access_key
</span><span class='line'>
</span><span class='line'>  Exec { path =&gt; ‘/usr/bin:/bin:/usr/sbin:/sbin’ }
</span><span class='line'>
</span><span class='line'>  package { “gcc”: ensure =&gt; “installed” }
</span><span class='line'>   package { “mod_proxy_html”: ensure =&gt; “installed” }
</span><span class='line'>   package { “perl”: ensure =&gt; “installed” }
</span><span class='line'>   package { “libxslt-devel”: ensure =&gt; “installed” }
</span><span class='line'>   package { “libxml2-devel”: ensure =&gt; “installed” }
</span><span class='line'>   package { “make”: ensure =&gt; “installed” }
</span><span class='line'>
</span><span class='line'>  package {“bundler”:
</span><span class='line'>     ensure =&gt; “1.1.4”,
</span><span class='line'>     provider =&gt; gem
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  package {“trollop”:
</span><span class='line'>     ensure =&gt; “2.0”,
</span><span class='line'>     provider =&gt; gem
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  package {“aws-sdk”:
</span><span class='line'>     ensure =&gt; “1.5.6”,
</span><span class='line'>     provider =&gt; gem,
</span><span class='line'>     require =&gt; [
</span><span class='line'>       Package[“gcc”],
</span><span class='line'>       Package[“make”]
</span><span class='line'>     ]
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  file { “/home/ec2-user/aws.config”:
</span><span class='line'>     content =&gt; template(“system/aws.config.erb”),
</span><span class='line'>     owner =&gt; ‘ec2-user’,
</span><span class='line'>     group =&gt; ‘ec2-user’,
</span><span class='line'>     mode =&gt; ‘500’,
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  define download_file($site=“”,$cwd=“”,$creates=“”){
</span><span class='line'>     exec { $name:
</span><span class='line'>       command =&gt; “wget ${site}/${name}”,
</span><span class='line'>       cwd =&gt; $cwd,
</span><span class='line'>       creates =&gt; “${cwd}/${name}”
</span><span class='line'>     }
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  download_file {“database_update.rb”:
</span><span class='line'>     site =&gt; “https://s3.amazonaws.com/sea2shore”,
</span><span class='line'>     cwd =&gt; “/home/ec2-user”,
</span><span class='line'>     creates =&gt; “/home/ec2-user/database_update.rb”,
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  download_file {“id_rsa.pub”:
</span><span class='line'>     site =&gt; “https://s3.amazonaws.com/sea2shore/private”,
</span><span class='line'>     cwd =&gt; “/tmp”,
</span><span class='line'>     creates =&gt; “/tmp/id_rsa.pub”
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  exec {“authorized_keys”:
</span><span class='line'>     command =&gt; “cat /tmp/id_rsa.pub &gt;&gt; /home/ec2-user/.ssh/authorized_keys”,
</span><span class='line'>     require =&gt; Download_file[“id_rsa.pub”]
</span><span class='line'>     }
</span><span class='line'>   }</span></code></pre></td></tr></table></div></figure>


<p>First I want to point out that at the top we are specifying to <code>include params</code>. This enables the system <em>module</em> to access the <code>params.pp</code> file. This way we can use the properties defined in <code>params.pp.</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> include params
</span><span class='line'>
</span><span class='line'> $access_key = $params::access_key
</span><span class='line'> $secret_access_key = $params::secret_access_key</span></code></pre></td></tr></table></div></figure>


<p>This enables us to define the parameters in one central location and then reference that location with other <em>module</em>.</p>

<p>As we move through the script we are using the package resource similar to previous <em>modules</em>. For each rubygem we use the package resource and explicitly tell Puppet to use the <code>gem</code> provider. You can specify other providers like <code>rpm</code> and <code>yum</code>.</p>

<p>We use the <code>file</code> resource to create files from templates.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> AWS.config(
</span><span class='line'>   :access_key_id =&gt; "&lt;%= "#{access_key}" %&gt;",
</span><span class='line'>   :secret_access_key =&gt; "&lt;%= "#{secret_access_key}" %&gt;" 
</span><span class='line'> )</span></code></pre></td></tr></table></div></figure>


<p>In the <code>aws.config.erb</code> template (referenced above) we are using the properties defined in <code>params.pp</code> for dynamically creating an <code>aws.config</code> credential file. This file is then used by our <code>database_update.rb</code> script for connecting to <a href="http://aws.amazon.com/s3/">S3</a>.</p>

<p>Speaking of the <code>database_update.rb</code> script, we need to get it on the target environment. To do this, we define a <code>download_file</code> resource.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> define download_file($site="",$cwd="",$creates=""){
</span><span class='line'>   exec { $name:
</span><span class='line'>     command =&gt; "wget ${site}/${name}",
</span><span class='line'>     cwd =&gt; $cwd,
</span><span class='line'>     creates =&gt; "${cwd}/${name}"
</span><span class='line'>   }
</span><span class='line'> }</span></code></pre></td></tr></table></div></figure>


<p>This creates a new resource for Puppet to use. Using this we are able to download both the <code>database_update.rb</code> and <code>id_rsa.pub</code> public SSH key.</p>

<p>As a final step for setting up the system, we execute a bash line for copying the <code>id_rsa.pub</code> contents into the <code>authorized_keys</code> file for the <code>ec2-user</code>. This enables clients with the connected <code>id_rsa</code> key to ssh into the target environment as <code>ec2-user</code>.</p>

<p>The Manatee infrastructure uses <a href="http://httpd.apache.org/">Apache</a> for the webserver, <a href="http://tomcat.apache.org/">Tomcat</a> for the app server, and <a href="http://www.postgresql.org/">PostgreSQL</a> for its database. Puppet these up as part of the <code>main</code> stage, meaning they run in order after the <code>pre</code> stage <em>modules</em> are run.</p>

<p>In our <code>httpd</code> <em>module</em>, we are performing several steps discussed previously. The <code>httpd</code> package is installed and creating a new file from a template.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> class httpd {   include params
</span><span class='line'>
</span><span class='line'>  $application_name = $params::application_name
</span><span class='line'>   $hosted_zone = $params::hosted_zone
</span><span class='line'>
</span><span class='line'>  package { ‘httpd’:
</span><span class='line'>     ensure =&gt; installed,
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  file { “/etc/httpd/conf/httpd.conf”:
</span><span class='line'>     content =&gt; template(“httpd/httpd.conf.erb”),
</span><span class='line'>     require =&gt; Package[“httpd”],
</span><span class='line'>     owner =&gt; ‘ec2-user’,
</span><span class='line'>     group =&gt; ‘ec2-user’,
</span><span class='line'>     mode =&gt; ‘664’,
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  service { ‘httpd’:
</span><span class='line'>     ensure =&gt; running,
</span><span class='line'>     enable =&gt; true,
</span><span class='line'>     require =&gt; [
</span><span class='line'>       Package[“httpd”],
</span><span class='line'>       File[“/etc/httpd/conf/httpd.conf”]],
</span><span class='line'>       subscribe =&gt; Package[’httpd’],
</span><span class='line'>     }
</span><span class='line'>   }</span></code></pre></td></tr></table></div></figure>


<p>The new piece of functionality used in our <code>httpd</code> <em>module</em> is <code>service</code>. <code>service</code> allows us define the state the <code>httpd</code> service should be in at the end of our run. In this case, we are declaring that it should be running.</p>

<p>The Tomcat <em>module</em> again uses package to define what to install and service to declare the end state of the tomcat service.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> class tomcat6 {
</span><span class='line'>
</span><span class='line'>  Exec { path =&gt; ‘/usr/bin:/bin:/usr/sbin:/sbin’ }
</span><span class='line'>
</span><span class='line'>  package { “tomcat6”:
</span><span class='line'>     ensure =&gt; “installed”
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  $backup_directories = [
</span><span class='line'>     “/usr/share/tomcat6/.sarvatix/”,
</span><span class='line'>     “/usr/share/tomcat6/.sarvatix/manatees/”,
</span><span class='line'>     “/usr/share/tomcat6/.sarvatix/manatees/wildtracks/”,
</span><span class='line'>
</span><span class='line'>    “/usr/share/tomcat6/.sarvatix/manatees/wildtracks/database_backups/”,
</span><span class='line'>
</span><span class='line'>    “/usr/share/tomcat6/.sarvatix/manatees/wildtracks/database_backups/backup_archive”,
</span><span class='line'>   ]
</span><span class='line'>
</span><span class='line'>  file { $backup_directories:
</span><span class='line'>     ensure =&gt; “directory”,
</span><span class='line'>     owner =&gt; “tomcat”,
</span><span class='line'>     group =&gt; “tomcat”,
</span><span class='line'>     mode =&gt; 777,
</span><span class='line'>     require =&gt; Package[“tomcat6”],
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  service { “tomcat6”:
</span><span class='line'>     enable =&gt; true,
</span><span class='line'>     require =&gt; [
</span><span class='line'>       File[$backup_directories],
</span><span class='line'>       Package[“tomcat6”]],
</span><span class='line'>     ensure =&gt; running,
</span><span class='line'>   }
</span><span class='line'> }</span></code></pre></td></tr></table></div></figure>


<p>Tomcat uses the <code>file</code> resource differently then previous <em>modules</em>. <code>tomcat</code> uses <code>file</code> for creating directories. This is defined using <code>ensure =&gt; “directory”</code>.</p>

<p>We are using the <code>package</code> resource for installing PostgreSQL, building files from templates using the <code>file</code> resource, performing bash executions with <code>exec</code>, and declaring the intended state of the PostgreSQL using the <code>service</code> resource.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> class postgresql {
</span><span class='line'>
</span><span class='line'>  include params
</span><span class='line'>
</span><span class='line'>  $jenkins_internal_ip = $params::jenkins_internal_ip
</span><span class='line'>
</span><span class='line'>  Exec { path =&gt; ‘/usr/bin:/bin:/usr/sbin:/sbin’ }
</span><span class='line'>
</span><span class='line'>  define download_file($site=“”,$cwd=“”,$creates=“”){
</span><span class='line'>     exec { $name:
</span><span class='line'>       command =&gt; “wget ${site}/${name}”,
</span><span class='line'>       cwd =&gt; $cwd,
</span><span class='line'>       creates =&gt; “${cwd}/${name}”
</span><span class='line'>     }
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  download_file {“wildtracks.sql”:
</span><span class='line'>     site =&gt; “https://s3.amazonaws.com/sea2shore”,
</span><span class='line'>     cwd =&gt; “/tmp”,
</span><span class='line'>     creates =&gt; “/tmp/wildtracks.sql”
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  download_file {“createDbAndOwner.sql”:
</span><span class='line'>     site =&gt; “https://s3.amazonaws.com/sea2shore”,
</span><span class='line'>     cwd =&gt; “/tmp”,
</span><span class='line'>     creates =&gt; “/tmp/createDbAndOwner.sql”
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  package { “postgresql8-server”:
</span><span class='line'>     ensure =&gt; installed,
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  exec { “initdb”:
</span><span class='line'>     command =&gt; “service postgresql initdb”,
</span><span class='line'>     require =&gt; Package[“postgresql8-server”]
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  file { “/var/lib/pgsql/data/pg_hba.conf”:
</span><span class='line'>     content =&gt; template(“postgresql/pg_hba.conf.erb”),
</span><span class='line'>     require =&gt; Exec[“initdb”],
</span><span class='line'>     owner =&gt; ‘postgres’,
</span><span class='line'>     group =&gt; ‘postgres’,
</span><span class='line'>     mode =&gt; ‘600’,
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  file { “/var/lib/pgsql/data/postgresql.conf”:
</span><span class='line'>     content =&gt; template(“postgresql/postgresql.conf.erb”),
</span><span class='line'>     require =&gt; Exec[“initdb”],
</span><span class='line'>     owner =&gt; ‘postgres’,
</span><span class='line'>     group =&gt; ‘postgres’,
</span><span class='line'>     mode =&gt; ‘600’,
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  service { “postgresql”:
</span><span class='line'>     enable =&gt; true,
</span><span class='line'>     require =&gt; [
</span><span class='line'>       Exec[“initdb”],
</span><span class='line'>       File[“/var/lib/pgsql/data/postgresql.conf”],
</span><span class='line'>       File[“/var/lib/pgsql/data/pg_hba.conf”]],
</span><span class='line'>     ensure =&gt; running,
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  exec { “create-user”:
</span><span class='line'>     command =&gt; “echo CREATE USER root | psql -U postgres”,
</span><span class='line'>     require =&gt; Service[“postgresql”]
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  exec { “create-db-owner”:
</span><span class='line'>     require =&gt; [
</span><span class='line'>       Download_file[“createDbAndOwner.sql”],
</span><span class='line'>       Exec[“create-user”],
</span><span class='line'>       Service[“postgresql”]],
</span><span class='line'>     command =&gt; “psql &lt; /tmp/createDbAndOwner.sql -U postgres”
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  exec { “load-database”:
</span><span class='line'>     require =&gt; [
</span><span class='line'>       Download_file[“wildtracks.sql”],
</span><span class='line'>       Exec[“create-user”],
</span><span class='line'>       Service[“postgresql”],
</span><span class='line'>       Exec[“create-db-owner”]],
</span><span class='line'>     command =&gt; “psql -U manatee_user -d manatees_wildtrack -f /tmp/wildtracks.sql”
</span><span class='line'>   }
</span><span class='line'> }</span></code></pre></td></tr></table></div></figure>


<p>In this module we are creating a new user on the PostgreSQL database:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>exec {  "create-user":
</span><span class='line'>   command =&gt; "echo CREATE USER root | psql -U postgres",
</span><span class='line'>   require =&gt; Service["postgresql"]
</span><span class='line'> }</span></code></pre></td></tr></table></div></figure>


<p>In this next section we download the latest Manatee database SQL dump.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>download_file {"wildtracks.sql":
</span><span class='line'>   site =&gt; "https://s3.amazonaws.com/sea2shore",
</span><span class='line'>   cwd =&gt; "/tmp",   creates =&gt; "/tmp/wildtracks.sql" 
</span><span class='line'> }</span></code></pre></td></tr></table></div></figure>


<p>In the section below, we load the database with the SQL file. This builds our target environments with the production database content giving developers an exact replica sandbox to work in.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>
</span><span class='line'>exec { “load-database”:
</span><span class='line'>   require =&gt; [
</span><span class='line'>     Download_file[“wildtracks.sql”],
</span><span class='line'>     Exec[“create-user”],
</span><span class='line'>     Service[“postgresql”],
</span><span class='line'>     Exec[“create-db-owner”]],
</span><span class='line'>   command =&gt; “psql -U manatee_user -d manatees_wildtrack -f /tmp/wildtracks.sql”
</span><span class='line'>   }
</span><span class='line'> }</span></code></pre></td></tr></table></div></figure>


<p>Lastly in our Puppet run, we install <code>subversion</code> and <code>groovy</code> on the target node. We could have just included these in our system module, but they seemed general purpose enough to create individual <em>modules</em>.</p>

<p>Subversion manifest:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> class subversion {
</span><span class='line'>   package { "subversion":
</span><span class='line'>     ensure =&gt; "installed"   
</span><span class='line'>  } 
</span><span class='line'> }</span></code></pre></td></tr></table></div></figure>


<p>Groovy manifest:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> class groovy {   Exec { path =&gt; '/usr/bin:/bin:/usr/sbin:/sbin' }
</span><span class='line'>
</span><span class='line'>  define download_file($site=“”,$cwd=“”,$creates=“”){
</span><span class='line'>     exec { $name:
</span><span class='line'>     command =&gt; “wget ${site}/${name}”,
</span><span class='line'>     cwd =&gt; $cwd,
</span><span class='line'>     creates =&gt; “${cwd}/${name}”
</span><span class='line'>     }
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  download_file {“groovy-1.8.2.tar.gz”:
</span><span class='line'>     site =&gt; “https://s3.amazonaws.com/sea2shore/resources/binaries”,
</span><span class='line'>     cwd =&gt; “/tmp”,
</span><span class='line'>     creates =&gt; “/tmp/groovy-1.8.2.tar.gz”,
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  file { “/usr/bin/groovy-1.8.2/”:
</span><span class='line'>     ensure =&gt; “directory”,
</span><span class='line'>     owner =&gt; “root”,
</span><span class='line'>     group =&gt; “root”,
</span><span class='line'>     mode =&gt; 755,
</span><span class='line'>     require =&gt; Download_file[“groovy-1.8.2.tar.gz”],
</span><span class='line'>   }
</span><span class='line'>
</span><span class='line'>  exec { “extract-groovy”:
</span><span class='line'>     command =&gt; “tar -C /usr/bin/groovy-1.8.2/ -xvf /tmp/groovy-1.8.2.tar.gz”,
</span><span class='line'>     require =&gt; File[“/usr/bin/groovy-1.8.2/”],
</span><span class='line'>   }
</span><span class='line'> }</span></code></pre></td></tr></table></div></figure>


<p>The Subversion manifest is relatively straightforward as we are using the package resource. The Groovy manifest is slightly different, we are downloading the Groovy tar, placing it on the filesystem, and then extracting it.</p>

<p>We’ve gone through how the target environment is provisioned. We do however have one more task, testing. It’s not enough to assume that if Puppet doesn’t error out, that everything got installed successfully. For this reason, we use <a href="http://cukes.info/">Cucumber</a> to do acceptance testing against our environment. Our tests check if services are running, configuration files are present and if the right packages have been installed.</p>

<p>Puppet allows us to completely script and version our target environments. Consequently, this enables us to treat environments as disposable entities. As a practice, we create a new target environment every time our <a href="../continuous-delivery-in-the-cloud-cd-pipeline-part-2-of-6/index.html">CD pipeline</a> is run. This way we are always deploying against a known state.</p>

<p>As our blog series is coming to a close, let’s recap what we’ve gone through. In the Manatee infrastructure we use a combination of <a href="../continuous-delivery-in-the-cloud-cloudformation-part-3-of-6/index.html">CloudFormation</a>
for scripting AWS resources, Puppet for scripting target environments, <a href="../continuous-delivery-in-the-cloud-deployment-automation-part-5-of-6/index.html">Capistrano</a> for deployment automation, <a href="../continuous-delivery-in-the-cloud-dynamic-configuration-part-4-of-6/index.html">Simple DB</a> and CloudFormation for dynamic properties and</p>

<p><a href="../continuous-delivery-in-the-cloud-cd-pipeline-part-2-of-6/index.html">Jenkins</a> for coordinating all the resources into one cohesive unit for moving a Manatee application change from check-in to production in just a single click.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
  
    
      <h1 class="entry-title"><a href="/blog/2014/04/04/tutorial-continuous-delivery-in-the-cloud-part-5-of-6/">Tutorial : Continuous Delivery in the Cloud Part 5 of 6</a></h1>
      
      
    
      <p class="meta">
        








  


<time datetime="2014-04-04T13:59:59-04:00" pubdate data-updated="true">Apr 4<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In<a href="http://www.stelligent.com/wp-admin/continuous-delivery-in-the-cloud-case-study-for-the-sea-to-shore-alliance-introduction-part-1-of-6">part 1 of this series</a>, I introduced the<a href="http://refcardz.dzone.com/refcardz/continuous-delivery-patterns">Continuous Delivery</a> (CD) pipeline for the<a href="http://manatees.mapntracker.com/wildtracks/">Manatee Tracking application</a>. In<a href="../continuous-delivery-in-the-cloud-cd-pipeline-part-2-of-6/index.html">part 2</a> I went over how we use this CD pipeline to deliver software from checkin to production. In <a href="../continuous-delivery-in-the-cloud-cloudformation-part-3-of-6/index.html">part 3</a>, we focused on how CloudFormation is used to script the virtual AWS components that create the Manatee infrastructure. A list of topics for each of the articles is summarized below:</p>

<p><a href="../continuous-delivery-in-the-cloud-case-study-for-the-sea-to-shore-alliance-introduction-part-1-of-6/index.html">Part 1: Introduction</a>
– Introduction to continuous delivery in the cloud and the rest of the articles;
 <a href="../continuous-delivery-in-the-cloud-cd-pipeline-part-2-of-6/index.html">Part 2: CD Pipeline</a>
– In-depth look at the CD Pipeline;
 <a href="../continuous-delivery-in-the-cloud-cloudformation-part-3-of-6/index.html">Part 3: CloudFormation</a>
– Scripted virtual resource provisioning;
 Part 4: Dynamic Configuration –  What you’re reading now;
 <a href="../continuous-delivery-in-the-cloud-deployment-automation-part-5-of-6/index.html">Part 5: Deployment Automation</a>
– Scripted deployment orchestration;
 <a href="../continuous-delivery-in-the-cloud-infrastructure-automation-part-6-of-6/index.html">Part 6: Infrastructure Automation</a>
– Scripted environment provisioning (Infrastructure Automation)</p>

<p>In this part of the series, I am going to explain how we dynamically generate our configuration and avoid property files whenever possible. Instead of using property files, we store and retrieve configuration on the fly – as part of the CD pipeline – without predefining these values in a static file (i.e. a properties file) ahead of time. We do this using two methods: AWS <a href="http://aws.amazon.com/simpledb/">SimpleDB</a> and <a href="http://aws.amazon.com/cloudformation/">CloudFormation</a>.</p>

<p>SimpleDB is a highly available non-relational data storage service that only stores strings in key value pairs. CloudFormation, as discussed in <a href="../continuous-delivery-in-the-cloud-cloudformation-part-3-of-6/index.html">Part 3</a>
of the series, is a scripting language for allocating and configuring AWS virtual resources.</p>

<p><strong>Using SimpleDB</strong></p>

<p>Throughout the CD pipeline, we often need to manage state across multiple Jenkins jobs. To do this, we use SimpleDB. As the pipeline executes, values that will be needed by subsequent jobs get stored in SimpleDB as properties. When the properties are needed we use a simple Ruby script script to return the key/value pair from SimpleDB and then use it as part of the job. The values being stored and retrieved range from IP addresses and domain names to AMI (Machine Images) IDs.</p>

<p>So what makes this dynamic? As Jenkins jobs or CloudFormation templates are run, we often end up with properties that need to be used elsewhere. Instead of hard coding all of the values to be used in a property file, we create, store and retrieve them as the pipeline executes.</p>

<p>Below is the <strong>CreateTargetEnvironment</strong> Jenkins job script that creates a new target environment from a CloudFormation script <code>production.template</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>if [ $deployToProduction ] == true 
</span><span class='line'>then 
</span><span class='line'>SSH_KEY=production 
</span><span class='line'>else SSH_KEY=development 
</span><span class='line'>fi
</span></code></pre></td></tr></table></div></figure>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># Create Cloudformaton Stack
</span><span class='line'> ruby /usr/share/tomcat6/scripts/aws/create_stack.rb ${STACK_NAME} ${WORKSPACE}/production.template ${HOST} ${JENKINSIP} ${SSH_KEY} ${SGID} ${SNS_TOPIC}
</span><span class='line'>
</span><span class='line'># Load SimpleDB Domain with Key/Value Pairs
</span><span class='line'> ruby /usr/share/tomcat6/scripts/aws/load_domain.rb ${STACK_NAME}
</span><span class='line'>
</span><span class='line'># Pull and store variables from SimpleDB
</span><span class='line'> host=`ruby /usr/share/tomcat6/scripts/aws/showback_domain.rb ${STACK_NAME} InstanceIPAddress`
</span><span class='line'>
</span><span class='line'># Run Acceptance Tests
</span><span class='line'> cucumber features/production.feature host=${host} user=ec2-user key=/usr/share/tomcat6/.ssh/id_rsa</span></code></pre></td></tr></table></div></figure>


<p>Referenced above in the <strong>CreateTargetEnvironment</strong> code snippet. This is the <strong>load_domain.rb</strong> script that iterates over a file and sends key/value pairs to SimpleDB.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> require 'rubygems' 
</span><span class='line'> require 'aws-sdk' 
</span><span class='line'> load File.expand_path('../../config/aws.config', __FILE__)
</span><span class='line'> 
</span><span class='line'>
</span><span class='line'>stackname=ARGV[0]
</span><span class='line'>
</span><span class='line'>file = File.open(“/tmp/properties”, “r”)
</span><span class='line'>
</span><span class='line'>sdb = AWS::SimpleDB.new
</span><span class='line'>
</span><span class='line'>AWS::SimpleDB.consistent_reads do
</span><span class='line'>   domain = sdb.domains[“stacks”]
</span><span class='line'>   item = domain.items[“#{stackname}”]
</span><span class='line'>
</span><span class='line'>  file.each_line do|line|
</span><span class='line'>     key,value = line.split ‘=’
</span><span class='line'>     item.attributes.set(
</span><span class='line'>       “#{key}” =&gt; “#{value}”)
</span><span class='line'>   end
</span><span class='line'> end</span></code></pre></td></tr></table></div></figure>


<p>Referenced above in the <strong>CreateTargetEnvironment</strong> code snippet. This is the <strong>showback_domain.rb</strong> script which connects to SimpleDB and returns a key/value pair.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> load File.expand_path('../../config/aws.config', __FILE__)
</span><span class='line'>
</span><span class='line'>item_name=ARGV[0]
</span><span class='line'> key=ARGV[1]
</span><span class='line'>
</span><span class='line'>sdb = AWS::SimpleDB.new
</span><span class='line'>
</span><span class='line'>AWS::SimpleDB.consistent_reads do
</span><span class='line'>   domain = sdb.domains[“stacks”]
</span><span class='line'>   item = domain.items[“#{item_name}”]
</span><span class='line'>
</span><span class='line'>  item.attributes.each_value do |name, value|
</span><span class='line'>     if name == “#{key}”
</span><span class='line'>       puts “#{value}”.chomp
</span><span class='line'>     end
</span><span class='line'>   end
</span><span class='line'> end</span></code></pre></td></tr></table></div></figure>


<p>In the above in the <strong>CreateTargetEnvironment</strong> code snippet, we store the outputs of the CloudFormation stack in a temporary file. We then iterate over the file with the <strong>load_domain.rb</strong> script and store the key/value pairs in SimpleDB.</p>

<p>Following this, we make a call to SimpleDB with the <strong>showback_domain.rb</strong> script and return the instance IP address (created in the CloudFormation template) and store it in the <code>host</code> variable. <code>host</code> is then used by cucumber to ssh into the target instance and run the acceptance tests.</p>

<p><strong>Using CloudFormation</strong></p>

<p>In our CloudFormation templates we allocate multiple AWS resources. Every time we run the template, a different resource is being used. For example, in our <code>jenkins.template</code> we create a new <a href="http://aws.amazon.com/iam/">IAM</a> user. Every time we run the template a different IAM user with different credentials is created. We need a way to reference these resources. This is where CloudFormation comes in. You can reference resources within other resources throughout the script. You can define a reference to another resource using the <a href="http://www.stelligent.com/docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-ref.html">Ref</a>
function in CloudFormation. Using Ref, you can dynamically refer to values of other resources such as an IP Address, domain name, etc.</p>

<p>In the script we are creating an IAM user, referencing the IAM user to create <a href="https://portal.aws.amazon.com/gp/aws/securityCredentials">AWS Access keys</a> and then storing them in an environment variable.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> "CfnUser" : {
</span><span class='line'>   "Type" : "AWS::IAM::User",
</span><span class='line'>   "Properties" : {
</span><span class='line'>     "Path": "/",
</span><span class='line'>     "Policies": [{
</span><span class='line'>       "PolicyName": "root",
</span><span class='line'>       "PolicyDocument": {
</span><span class='line'>         "Statement":[{
</span><span class='line'>           "Effect":"Allow",
</span><span class='line'>           "Action":"*",
</span><span class='line'>           "Resource":"*"
</span><span class='line'>         }
</span><span class='line'>       ]}
</span><span class='line'>     }]
</span><span class='line'>   }
</span><span class='line'> },`
</span><span class='line'>
</span><span class='line'>“HostKeys” : {
</span><span class='line'>   “Type” : “AWS::IAM::AccessKey”,
</span><span class='line'>   “Properties” : {
</span><span class='line'>     “UserName” : { “Ref”: “CfnUser” }
</span><span class='line'>   }
</span><span class='line'> },
</span><span class='line'>
</span><span class='line'>“# Add AWS Credentials to Tomcatn”,
</span><span class='line'> “echo ”AWS_ACCESS_KEY=“, {”Ref" : “HostKeys” }, “” &gt;&gt; /etc/sysconfig/tomcat6n",
</span><span class='line'> “echo ”AWS_SECRET_ACCESS_KEY=“, {”Fn::GetAtt“:
</span><span class='line'>[”HostKeys“,”SecretAccessKey“]},”" &gt;&gt; /etc/sysconfig/tomcat6n",</span></code></pre></td></tr></table></div></figure>


<p>We can then use these access keys in other scripts by referencing the <code>$AWS_ACCESS_KEY</code> and <code>$AWS_SECRET_ACCESS_KEY</code> environment variables.</p>

<p><strong>How is this different from typical configuration management?</strong></p>

<p>Typically in many organizations, there’s a big property with hard coded key/value pairs that gets passed into the pipeline. The pipeline executes using the given parameters and cannot scale or change without a user modifying the property file. They are unable to scale or adapt because all of the properties are hard coded, if the property file hard codes the IP to an EC2 instance and it goes down for whatever reason, their pipeline doesn’t work until someone fixes the property file. There are more effective ways of doing this when using the cloud. The cloud is provides on-demand resources that will constantly be changing. These resources will have different IP addresses, domain names, etc associated with them every time.</p>

<p>With dynamic configuration, there are no property files, every property is generated as part of the pipeline.</p>

<p>With this dynamic approach, the pipeline values change with every run. As new cloud resources are allocated, the pipeline is able to adjust itself and automatically without the need for users to constantly modify property files. This leads to less time spent debugging those cumbersome property file management issues that plague most companies.</p>

<p>In the next part of our series – which is all about Deployment Automation – we’ll go through scripting and testing your deployment using industry-standard tools. In this next article, you’ll see how to orchestrate deployment sequences and configuration using Capistrano.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
  
    
      <h1 class="entry-title"><a href="/blog/2014/04/04/tutorial-continuous-delivery-in-the-cloud-part-4-of-6/">Tutotial : Continuous Delivery in the Cloud Part 4 of 6</a></h1>
      
      
    
      <p class="meta">
        








  


<time datetime="2014-04-04T13:59:52-04:00" pubdate data-updated="true">Apr 4<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In<a href="http://www.stelligent.com/wp-admin/continuous-delivery-in-the-cloud-case-study-for-the-sea-to-shore-alliance-introduction-part-1-of-6">part 1 of this series</a>, I introduced the<a href="http://refcardz.dzone.com/refcardz/continuous-delivery-patterns">Continuous Delivery</a> (CD) pipeline for the<a href="http://manatees.mapntracker.com/wildtracks/">Manatee Tracking application</a>. In<a href="../continuous-delivery-in-the-cloud-cd-pipeline-part-2-of-6/index.html">part 2</a> I went over how we use this CD pipeline to deliver software from checkin to production. In <a href="../continuous-delivery-in-the-cloud-cloudformation-part-3-of-6/index.html">part 3</a>, we focused on how CloudFormation is used to script the virtual AWS components that create the Manatee infrastructure. A list of topics for each of the articles is summarized below:</p>

<p><a href="../continuous-delivery-in-the-cloud-case-study-for-the-sea-to-shore-alliance-introduction-part-1-of-6/index.html">Part 1:
Introduction</a> – Introduction to continuous delivery in the cloud and the rest of the articles;
 <a href="../continuous-delivery-in-the-cloud-cd-pipeline-part-2-of-6/index.html">Part 2: CD Pipeline</a>
– In-depth look at the CD Pipeline;
 <a href="../continuous-delivery-in-the-cloud-cloudformation-part-3-of-6/index.html">Part 3: CloudFormation</a>
– Scripted virtual resource provisioning;
 Part 4: Dynamic Configuration –  What you’re reading now;
 <a href="../continuous-delivery-in-the-cloud-deployment-automation-part-5-of-6/index.html">Part 5: Deployment Automation</a>
– Scripted deployment orchestration;
 <a href="../continuous-delivery-in-the-cloud-infrastructure-automation-part-6-of-6/index.html">Part 6: Infrastructure Automation</a>
– Scripted environment provisioning (Infrastructure Automation)</p>

<p>In this part of the series, I am going to explain how we dynamically generate our configuration and avoid property files whenever possible. Instead of using property files, we store and retrieve configuration on the fly – as part of the CD pipeline – without predefining these values in a static file (i.e. a properties file) ahead of time. We do this using two methods: AWS <a href="http://aws.amazon.com/simpledb/">SimpleDB</a> and <a href="http://aws.amazon.com/cloudformation/">CloudFormation</a>.</p>

<p>SimpleDB is a highly available non-relational data storage service that only stores strings in key value pairs. CloudFormation, as discussed in <a href="../continuous-delivery-in-the-cloud-cloudformation-part-3-of-6/index.html">Part 3</a>
of the series, is a scripting language for allocating and configuring AWS virtual resources.</p>

<p><strong>Using SimpleDB</strong></p>

<p>Throughout the CD pipeline, we often need to manage state across multiple Jenkins jobs. To do this, we use SimpleDB. As the pipeline executes, values that will be needed by subsequent jobs get stored in SimpleDB as properties. When the properties are needed we use a simple Ruby script script to return the key/value pair from SimpleDB and then use it as part of the job. The values being stored and retrieved range from IP addresses and domain names to AMI (Machine Images) IDs.</p>

<p>So what makes this dynamic? As Jenkins jobs or CloudFormation templates are run, we often end up with properties that need to be used elsewhere. Instead of hard coding all of the values to be used in a property file, we create, store and retrieve them as the pipeline executes.</p>

<p>Below is the <strong>CreateTargetEnvironment</strong> Jenkins job script that creates a new target environment from a CloudFormation script <code>production.template</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> if [ $deployToProduction ] == true 
</span><span class='line'> then
</span><span class='line'> SSH_KEY=production
</span><span class='line'> else
</span><span class='line'> SSH_KEY=development
</span><span class='line'> fi
</span><span class='line'>
</span><span class='line'># Create Cloudformaton Stack
</span><span class='line'> ruby /usr/share/tomcat6/scripts/aws/create_stack.rb ${STACK_NAME}
</span><span class='line'>${WORKSPACE}/production.template ${HOST} ${JENKINSIP} ${SSH_KEY}
</span><span class='line'>${SGID} ${SNS_TOPIC}
</span><span class='line'>
</span><span class='line'># Load SimpleDB Domain with Key/Value Pairs
</span><span class='line'> ruby /usr/share/tomcat6/scripts/aws/load_domain.rb ${STACK_NAME}
</span><span class='line'>
</span><span class='line'># Pull and store variables from SimpleDB
</span><span class='line'> host=`ruby /usr/share/tomcat6/scripts/aws/showback_domain.rb ${STACK_NAME} InstanceIPAddress`
</span><span class='line'>
</span><span class='line'># Run Acceptance Tests
</span><span class='line'> cucumber features/production.feature host=${host} user=ec2-user key=/usr/share/tomcat6/.ssh/id_rsa</span></code></pre></td></tr></table></div></figure>


<p>Referenced above in the <strong>CreateTargetEnvironment</strong> code snippet. This is the <strong>load_domain.rb</strong> script that iterates over a file and sends key/value pairs to SimpleDB.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> require 'rubygems'
</span><span class='line'> require 'aws-sdk'
</span><span class='line'> load File.expand_path('../../config/aws.config', __FILE__)
</span><span class='line'>
</span><span class='line'>stackname=ARGV[0]
</span><span class='line'>
</span><span class='line'>file = File.open(“/tmp/properties”, “r”)
</span><span class='line'>
</span><span class='line'>sdb = AWS::SimpleDB.new
</span><span class='line'>
</span><span class='line'>AWS::SimpleDB.consistent_reads do
</span><span class='line'>   domain = sdb.domains[“stacks”]
</span><span class='line'>   item = domain.items[“#{stackname}”]
</span><span class='line'>
</span><span class='line'>  file.each_line do|line|
</span><span class='line'>     key,value = line.split ‘=’
</span><span class='line'>     item.attributes.set(
</span><span class='line'>       “#{key}” =&gt; “#{value}”)
</span><span class='line'>   end
</span><span class='line'> end</span></code></pre></td></tr></table></div></figure>


<p>Referenced above in the <strong>CreateTargetEnvironment</strong> code snippet. This is the <strong>showback_domain.rb</strong> script which connects to SimpleDB and returns a key/value pair.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> load File.expand_path('../../config/aws.config', __FILE__)
</span><span class='line'>
</span><span class='line'>item_name=ARGV[0]
</span><span class='line'> key=ARGV[1]
</span><span class='line'>
</span><span class='line'>sdb = AWS::SimpleDB.new
</span><span class='line'>
</span><span class='line'>AWS::SimpleDB.consistent_reads do
</span><span class='line'>   domain = sdb.domains[“stacks”]
</span><span class='line'>   item = domain.items[“#{item_name}”]
</span><span class='line'>
</span><span class='line'>  item.attributes.each_value do |name, value|
</span><span class='line'>     if name == “#{key}”
</span><span class='line'>       puts “#{value}”.chomp
</span><span class='line'>     end
</span><span class='line'>   end
</span><span class='line'> end</span></code></pre></td></tr></table></div></figure>


<p>In the above in the <strong>CreateTargetEnvironment</strong> code snippet, we store the outputs of the CloudFormation stack in a temporary file. We then iterate over the file with the <strong>load_domain.rb</strong> script and store the key/value pairs in SimpleDB.</p>

<p>Following this, we make a call to SimpleDB with the <strong>showback_domain.rb</strong> script and return the instance IP address (created in the CloudFormation template) and store it in the <code>host</code> variable. <code>host</code> is then used by cucumber to ssh into the target instance and run the acceptance tests.</p>

<p><strong>Using CloudFormation</strong></p>

<p>In our CloudFormation templates we allocate multiple AWS resources. Every time we run the template, a different resource is being used. For example, in our <code>jenkins.template</code> we create a new <a href="http://aws.amazon.com/iam/">IAM</a> user. Every time we run the template a different IAM user with different credentials is created. We need a way to reference these resources. This is where CloudFormation comes in. You can reference resources within other resources throughout the script. You can define a reference to another resource using the <a href="http://www.stelligent.com/docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-ref.html">Ref</a> function in CloudFormation. Using Ref, you can dynamically refer to values of other resources such as an IP Address, domain name, etc.</p>

<p>In the script we are creating an IAM user, referencing the IAM user to create <a href="https://portal.aws.amazon.com/gp/aws/securityCredentials">AWS Access keys</a> and then storing them in an environment variable.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> "CfnUser" : {
</span><span class='line'>   "Type" : "AWS::IAM::User",
</span><span class='line'>   "Properties" : {
</span><span class='line'>     "Path": "/",
</span><span class='line'>     "Policies": [{
</span><span class='line'>       "PolicyName": "root",
</span><span class='line'>       "PolicyDocument": {
</span><span class='line'>         "Statement":[{
</span><span class='line'>           "Effect":"Allow",
</span><span class='line'>           "Action":"*",
</span><span class='line'>           "Resource":"*"
</span><span class='line'>         }
</span><span class='line'>       ]}
</span><span class='line'>     }]
</span><span class='line'>   }
</span><span class='line'> },
</span><span class='line'>
</span><span class='line'>“HostKeys” : {
</span><span class='line'>   “Type” : “AWS::IAM::AccessKey”,
</span><span class='line'>   “Properties” : {
</span><span class='line'>     “UserName” : { “Ref”: “CfnUser” }
</span><span class='line'>   }
</span><span class='line'> },
</span><span class='line'>
</span><span class='line'>“# Add AWS Credentials to Tomcatn”,
</span><span class='line'> “echo ”AWS_ACCESS_KEY=“, {”Ref" : “HostKeys” }, “” &gt;&gt; /etc/sysconfig/tomcat6n",
</span><span class='line'> “echo ”AWS_SECRET_ACCESS_KEY=“, {”Fn::GetAtt“: [”HostKeys“,”SecretAccessKey“]},”" &gt;&gt; /etc/sysconfig/tomcat6n",
</span></code></pre></td></tr></table></div></figure>


<p>We can then use these access keys in other scripts by referencing the <code>$AWS_ACCESS_KEY</code> and <code>$AWS_SECRET_ACCESS_KEY</code> environment variables.</p>

<p><strong>How is this different from typical configuration management?</strong></p>

<p>Typically in many organizations, there’s a big property with hard coded key/value pairs that gets passed into the pipeline. The pipeline executes using the given parameters and cannot scale or change without a user modifying the property file. They are unable to scale or adapt because all of the properties are hard coded, if the property file hard codes the IP to an EC2 instance and it goes down for whatever reason, their pipeline doesn’t work until someone fixes the property file. There are more effective ways of doing this when using the cloud. The cloud is provides on-demand resources that will constantly be changing. These resources will have different IP addresses, domain names, etc associated with them every time.</p>

<p>With dynamic configuration, there are no property files, every property is generated as part of the pipeline.</p>

<p>With this dynamic approach, the pipeline values change with every run. As new cloud resources are allocated, the pipeline is able to adjust itself and automatically without the need for users to constantly modify property files. This leads to less time spent debugging those cumbersome property file management issues that plague most companies.</p>

<p>In the next part of our series – which is all about Deployment Automation – we’ll go through scripting and testing your deployment using industry-standard tools. In this next article, you’ll see how to orchestrate deployment sequences and configuration using Capistrano.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
  
    
      <h1 class="entry-title"><a href="/blog/2014/04/04/tutorial-continuous-delivery-in-the-cloud-part-3-of-6/">Tutorial : Continuous Delivery in the Cloud Part 3 of 6</a></h1>
      
      
    
      <p class="meta">
        








  


<time datetime="2014-04-04T13:59:46-04:00" pubdate data-updated="true">Apr 4<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In <a href="http://www.stelligent.com/wp-admin/continuous-delivery-in-the-cloud-case-study-for-the-sea-to-shore-alliance-introduction-part-1-of-6">part 1 of this series</a>, I introduced the<a href="http://refcardz.dzone.com/refcardz/continuous-delivery-patterns">Continuous Delivery</a>
(CD) pipeline for the<a href="http://manatees.mapntracker.com/wildtracks/">Manatee Tracking application</a>.
In <a href="../continuous-delivery-in-the-cloud-cd-pipeline-part-2-of-6/index.html" title="Continuous Delivery pipeline">part 2</a> I went over how we use this CD pipeline to deliver software from checkin to production. A list of topics for each of the articles is summarized below.</p>

<p><a href="../continuous-delivery-in-the-cloud-case-study-for-the-sea-to-shore-alliance-introduction-part-1-of-6/index.html">Part 1: Introduction</a>
– introduction to continuous delivery in the cloud and the rest of the articles;
 <a href="../continuous-delivery-in-the-cloud-cd-pipeline-part-2-of-6/index.html">Part 2: CD Pipeline</a>
– In-depth look at the CD Pipeline
 Part 3: CloudFormation – What you’re reading now<br/>
 <a href="../continuous-delivery-in-the-cloud-dynamic-configuration-part-4-of-6/index.html">Part 4: Dynamic Configuration</a>
– “Property file less” infrastructure;
 <a href="../continuous-delivery-in-the-cloud-deployment-automation-part-5-of-6/index.html">Part 5: Deployment Automation</a>
– Scripted deployment orchestration;
 <a href="../continuous-delivery-in-the-cloud-infrastructure-automation-part-6-of-6/index.html">Part 6: Infrastructure Automation</a>
– Scripted environment provisioning (Infrastructure Automation)</p>

<p>In this part of the series, I am going to explain how we use CloudFormation to script our AWS infrastructure and provision our Jenkins environment.</p>

<p><strong>What is CloudFormation?</strong>
 <a href="http://aws.amazon.com/cloudformation/">CloudFormation</a> is an AWS offering for scripting AWS virtual resource allocation. A CloudFormation template is a JSON script which references various AWS resources that you want to use. When the template runs, it will allocate the AWS resources accordingly.</p>

<p>A CloudFormation template is split up into four sections:</p>

<ol>
<li><strong>Parameters</strong>: <a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/concept-parameters.html">Parameters</a>     are values that you define in the template. When creating the stack    through the AWS console, you will be prompted to enter in values for     the Parameters. If the value for the parameter generally stays the     same, you can set a default value. Default values can be overridden     when creating the stack. The parameter can be used throughout the     template by using the     “<a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-ref.html">Ref</a>”     function.</li>
<li><strong>Mappings</strong>:     <a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/concept-mappings.html">Mappings</a>     are for specifying conditional parameter values in your template.     For instance you might want to use a different AMI depending on the     region your instance is running on. Mappings will enable you to     switch AMIs depending on the region the instance is being created     in.</li>
<li><strong>Resources</strong>:     <a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/concept-resources.html">Resources</a>     are the most vital part of the CloudFormation template. Inside the     resource section, you define and configure your AWS components.</li>
<li><strong>Outputs</strong>: After the stack resources are created successfully, you    may want to have it return values such as the IP address or the     domain of the created instance. You use Outputs for this.     <a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/concept-outputs.html">Outputs</a>     will return the values to the AWS console or command line depending     on which medium you use for creating a stack.</li>
</ol>


<p>CloudFormation parameters, and resources can be <a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/concept-property-references.html">referenced</a> throughout the template. You do this using intrinsic functions,
<a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-ref.html">Ref</a>, <a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-base64.html">Fn::Base64</a>,<a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-findinmap.html">Fn::FindInMap</a>, <a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-getatt.html">Fn::GetAtt</a>,<a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-getavailabilityzones.html">Fn::GetAZs</a> and <a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-join.html">Fn::Join</a>.</p>

<p>These functions enable you to pass properties and resource outputs throughout your template – reducing the need for most hardcoded properties (something I will discuss in part 4 of this series, <em>Dynamic Configuration</em>).</p>

<p><strong>How do you run a CloudFormation template?</strong>
 You can create a CloudFormation stack using either the <a href="https://console.aws.amazon.com/cloudformation/home?" title="AWS Console">AWS Console</a>, <a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/cfn-using-cli.html" title="CloudFormation CLI tools">CloudFormation CLI tools</a> or the <a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/APIReference" title="CloudFormation API">CloudFormation API</a>.</p>

<p><strong>Why do we use CloudFormation?</strong>
 We use CloudFormation in order to have a fully scripted, versioned infrastructure. From the application to the virtual resources, everything is created from a script and is checked into version control. This gives us complete control over our AWS infrastructure which can be recreated whenever necessary.</p>

<p><strong>CloudFormation for Manatees</strong>
 In the Manatee Infrastructure, we use CloudFormation for setting up the Jenkins CD environment. I am going to go through each part of the jenkins template and explain its use and purpose. In template’s lifecycle, the user launches the stack using the jenkins.template and enters in the Parameters. The template then starts to work:</p>

<p>​1. <a href="http://aws.amazon.com/iam/">IAM</a> User with <a href="https://portal.aws.amazon.com/gp/aws/securityCredentials">AWS Access keys</a> is created
 2. SNS Topic is created
 3. CloudWatch Alarm is created and SNS topic is used for sending alarm notifications
 4. Security Group is created
 5. Wait Condition created
 6. Jenkins EC2 Instance is created with the Security Group from step #4. This security group is used for port configuration. It also uses AWSInstanceType2Arch and AWSRegionArch2AMI to decide what AMI and OS type to use
 7. Jenkins EC2 Instance runs <code>UserData</code> script and executes <code>cfn_init</code>.
 8. Wait Condition waits for Jenkins EC2 instance to finish <code>UserData</code> script
 9. Elastic IP is allocated and associated with Jenkins EC2 instance
 10. Route53 domain name created and associated with Jenkins Elastic IP
 11. If everything creates successfully, the stack signals complete and outputs are displayed</p>

<p>Now that we know at a high level what is being done, lets take a deeper look at what’s going on inside the <code>jenkins.template</code>.</p>

<h2>Parameters</h2>

<ul>
<li><strong>Email:</strong> Email address that SNS notifications will be sent. When     we create or deploy to target environments, we use SNS to notify us     of their status.</li>
<li><strong>ApplicationName:</strong> Name of A Record created by Route53. Inside the     template, we dynamically create a domain with A record for easy     access to the instance after creation. Example:     jenkins.integratebutton.com, jenkins is the ApplicationName</li>
<li><strong>HostedZone:</strong> Name of Domain used Route53. Inside the template, we     dynamically create a domain with A record for easy access to the     instance after creation. Example: jenkins.integratebutton.com,     integratebutton.com is the HostedZone.</li>
<li><strong>KeyName</strong>: EC2 SSH Keypair to create the Instance with. This is     the key you use to ssh into the Jenkins instance after creation.</li>
<li><strong>InstanceType:</strong> Size of the EC2 instance. Example: t1.micro,     c1.medium</li>
<li><strong>S3Bucket:</strong> We use a S3 bucket for containing the resources for     the Jenkins template to use, this parameter specifies the name of     the bucket to use for this.</li>
</ul>


<p> </p>

<h2>Mappings</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> "Mappings" : {
</span><span class='line'>   "AWSInstanceType2Arch" : {
</span><span class='line'>     "t1.micro" : { "Arch" : "64" },
</span><span class='line'>     "m1.small" : { "Arch" : "32" },
</span><span class='line'>     "m1.large" : { "Arch" : "64" },
</span><span class='line'>     "m1.xlarge" : { "Arch" : "64" },
</span><span class='line'>     "m2.xlarge" : { "Arch" : "64" },
</span><span class='line'>     "m2.2xlarge" : { "Arch" : "64" },
</span><span class='line'>     "m2.4xlarge" : { "Arch" : "64" },
</span><span class='line'>     "c1.medium" : { "Arch" : "64" },
</span><span class='line'>     "c1.xlarge" : { "Arch" : "64" },
</span><span class='line'>     "cc1.4xlarge" : { "Arch" : "64" }
</span><span class='line'>   },
</span><span class='line'>     "AWSRegionArch2AMI" : {
</span><span class='line'>     "us-east-1" : { "32" : "ami-ed65ba84", "64" : "ami-e565ba8c" }   
</span><span class='line'> } 
</span><span class='line'> },</span></code></pre></td></tr></table></div></figure>


<p>These Mappings are used to define what type of operating system architecture and AWS AMI (Amazon Machine Image) ID to use to use based upon the Instance size. The instance size is specified using the Parameter <strong>InstanceType</strong></p>

<p>The conditional logic to interact with the Mappings is done inside the EC2 instance.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> "ImageId" : {
</span><span class='line'>  "Fn::FindInMap" : [
</span><span class='line'>   "AWSRegionArch2AMI", 
</span><span class='line'>    {"Ref" : "AWS::Region" },
</span><span class='line'>    { "Fn::FindInMap" : [ 
</span><span class='line'>     "AWSInstanceType2Arch", { 
</span><span class='line'>       "Ref" : "InstanceType" 
</span><span class='line'>       },
</span><span class='line'>        "Arch" 
</span><span class='line'>        ] }
</span><span class='line'>         ]
</span><span class='line'>    },</span></code></pre></td></tr></table></div></figure>


<h2>Resources</h2>

<p><strong><a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/aws-properties-iam-user.html">AWS::IAM::User</a></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> "CfnUser" : {
</span><span class='line'>   "Type" : "AWS::IAM::User",
</span><span class='line'>   "Properties" : {
</span><span class='line'>     "Path": "/",
</span><span class='line'>     "Policies": [{
</span><span class='line'>       "PolicyName": "root",
</span><span class='line'>       "PolicyDocument": { "Statement":[{
</span><span class='line'>         "Effect":"Allow",
</span><span class='line'>         "Action":"*",
</span><span class='line'>         "Resource":"*"
</span><span class='line'>         }
</span><span class='line'>       ]}
</span><span class='line'>     }]
</span><span class='line'>   }
</span><span class='line'> },
</span><span class='line'>
</span><span class='line'>  "Type" : "AWS::IAM::AccessKey",
</span><span class='line'>  "Properties" : {
</span><span class='line'>    "UserName" : { "Ref": "CfnUser" } 
</span><span class='line'>  }
</span><span class='line'>  </span></code></pre></td></tr></table></div></figure>


<p> We create the AWS IAM user and then create the <a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/aws-properties-iam-accesskey.html">AWS Access and Secret access keys</a> for the IAM user which are used throughout the rest of the template. Access and Secret access keys are authentication keys used to authenticate to the AWS account.</p>

<p><strong><a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/aws-properties-sns-topic.html">AWS::SNS::Topic</a></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> "MySNSTopic" : {
</span><span class='line'>   "Type" : "AWS::SNS::Topic",
</span><span class='line'>   "Properties" : {
</span><span class='line'>     "Subscription" : [ {
</span><span class='line'>       "Endpoint" : { "Ref": "Email" },
</span><span class='line'>       "Protocol" : "email"
</span><span class='line'>     } ]
</span><span class='line'>   } },</span></code></pre></td></tr></table></div></figure>


<p>SNS is a highly available solution for sending notifications. In the Manatee infrastructure it is used for sending notifications to the development team.</p>

<p><strong><a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/aws-properties-route53-recordsetgroup.html">AWS::Route53::RecordSetGroup</a></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> "JenkinsDNS" : {
</span><span class='line'>   "Type" : "AWS::Route53::RecordSetGroup",
</span><span class='line'>   "Properties" : {
</span><span class='line'>     "HostedZoneName" : { "Fn::Join" : [ "", [ {"Ref" : "HostedZone"}, "." ]]},
</span><span class='line'>     "RecordSets" : [{       "Name" : { "Fn::Join" : ["", [ { "Ref" : "ApplicationName" }, ".", { "Ref" : "HostedZone" }, "." ]]},
</span><span class='line'>       "Type" : "A",
</span><span class='line'>       "TTL" : "900",
</span><span class='line'>       "ResourceRecords" : [ { "Ref" : "IPAddress" } ]
</span><span class='line'>     }]
</span><span class='line'>   }
</span><span class='line'> },</span></code></pre></td></tr></table></div></figure>


<p>Route53 is a highly available DNS service. We use Route53 to create domains dynamically using the given HostedZone and ApplicationName parameters. If the parameters are not overriden, the domain jenkins.integratebutton.com will be created. We then reference the Elastic IP and associate it with the created domain. This way the jenkins.integratebutton.com domain will route to the created instance</p>

<p><strong><a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-instance.html">AWS::EC2::Instance</a></strong></p>

<p>EC2 gives access to on-demand compute resources. In this template, we allocate a new EC2 instance and configure it with a Keypair, Security Group, and Image ID (AMI). Then for provisioning the EC2 instance we use the <code>UserData</code> property. Inside <code>UserData</code> we run a set of bash commands along with <code>cfn_init</code>. The <code>UserData</code> script is run during instance creation.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
<span class='line-number'>202</span>
<span class='line-number'>203</span>
<span class='line-number'>204</span>
<span class='line-number'>205</span>
<span class='line-number'>206</span>
<span class='line-number'>207</span>
<span class='line-number'>208</span>
<span class='line-number'>209</span>
<span class='line-number'>210</span>
<span class='line-number'>211</span>
<span class='line-number'>212</span>
<span class='line-number'>213</span>
<span class='line-number'>214</span>
<span class='line-number'>215</span>
<span class='line-number'>216</span>
<span class='line-number'>217</span>
<span class='line-number'>218</span>
<span class='line-number'>219</span>
<span class='line-number'>220</span>
<span class='line-number'>221</span>
<span class='line-number'>222</span>
<span class='line-number'>223</span>
<span class='line-number'>224</span>
<span class='line-number'>225</span>
<span class='line-number'>226</span>
<span class='line-number'>227</span>
<span class='line-number'>228</span>
<span class='line-number'>229</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> "WebServer": {
</span><span class='line'>   "Type": "AWS::EC2::Instance",
</span><span class='line'>   "Metadata" : {
</span><span class='line'>     "AWS::CloudFormation::Init" : {
</span><span class='line'>       "config" : {
</span><span class='line'>         "packages" : {
</span><span class='line'>           "yum" : {
</span><span class='line'>             "tomcat6" : [],
</span><span class='line'>             "subversion" : [],
</span><span class='line'>             "git" : [],
</span><span class='line'>             "gcc" : [],
</span><span class='line'>             "libxslt-devel" : [],
</span><span class='line'>             "ruby-devel" : [],
</span><span class='line'>             "httpd" : []
</span><span class='line'>           }
</span><span class='line'>         },
</span><span class='line'>
</span><span class='line'>        “sources” : {
</span><span class='line'>           “/opt/aws/apitools/cfn” : { “Fn::Join” : [“”,[“https://s3.amazonaws.com/”, { “Ref” : “S3Bucket” }, “/resources/aws_tools/cfn-cli.tar.gz”]]},
</span><span class='line'>           “/opt/aws/apitools/sns” : { “Fn::Join” : [“”, [“https://s3.amazonaws.com/”, { “Ref” : “S3Bucket” }, “/resources/aws_tools/sns-cli.tar.gz”]]}
</span><span class='line'>         },
</span><span class='line'>
</span><span class='line'>        “files” : {
</span><span class='line'>           “/usr/share/tomcat6/webapps/jenkins.war” : {
</span><span class='line'>             “source” : “http://mirrors.jenkins-ci.org/war/1.480/jenkins.war”,
</span><span class='line'>             “mode” : “000700”,
</span><span class='line'>             “owner” : “tomcat”,
</span><span class='line'>             “group” : “tomcat”,
</span><span class='line'>             “authentication” : “S3AccessCreds”
</span><span class='line'>           },
</span><span class='line'>
</span><span class='line'>          “/usr/share/tomcat6/webapps/nexus.war” : {
</span><span class='line'>             “source” : “http://www.sonatype.org/downloads/nexus-2.0.3.war”,
</span><span class='line'>             “mode” : “000700”,
</span><span class='line'>             “owner” : “tomcat”,
</span><span class='line'>             “group” : “tomcat”,
</span><span class='line'>             “authentication” : “S3AccessCreds”
</span><span class='line'>           },
</span><span class='line'>
</span><span class='line'>          “/usr/share/tomcat6/.ssh/id_rsa” : {
</span><span class='line'>             “source” : { “Fn::Join” : [“”, [“https://s3.amazonaws.com/”, { “Ref” : “S3Bucket” }, “/private/id_rsa”]]},
</span><span class='line'>             “mode” : “000600”,
</span><span class='line'>             “owner” : “tomcat”,
</span><span class='line'>             “group” : “tomcat”,
</span><span class='line'>             “authentication” : “S3AccessCreds”
</span><span class='line'>           },
</span><span class='line'>
</span><span class='line'>          “/home/ec2-user/common-step-definitions-1.0.0.gem” : {
</span><span class='line'>             “source” : { “Fn::Join” : [“”,[“https://s3.amazonaws.com/”, { “Ref” : “S3Bucket” }, “/gems/common-step-definitions-1.0.0.gem”]]},
</span><span class='line'>             “mode” : “000700”,
</span><span class='line'>             “owner” : “root”,
</span><span class='line'>             “group” : “root”,
</span><span class='line'>             “authentication” : “S3AccessCreds”
</span><span class='line'>           },
</span><span class='line'>
</span><span class='line'>          “/etc/cron.hourly/jenkins_backup.sh” : {
</span><span class='line'>             “source” : { “Fn::Join” : [“”, [“https://s3.amazonaws.com/”, { “Ref” : “S3Bucket” }, “/jenkins_backup.sh”]]},
</span><span class='line'>             “mode” : “000500”,
</span><span class='line'>             “owner” : “root”,
</span><span class='line'>             “group” : “root”,
</span><span class='line'>             “authentication” : “S3AccessCreds”
</span><span class='line'>           },
</span><span class='line'>
</span><span class='line'>          “/etc/tomcat6/server.xml” : {
</span><span class='line'>             “source” : { “Fn::Join” : [“”, [“https://s3.amazonaws.com/”, { “Ref” : “S3Bucket” }, “/server.xml”]]},
</span><span class='line'>             “mode” : “000554”,
</span><span class='line'>             “owner” : “root”,
</span><span class='line'>             “group” : “root”,
</span><span class='line'>             “authentication” : “S3AccessCreds”
</span><span class='line'>           },
</span><span class='line'>
</span><span class='line'>          “/usr/share/tomcat6/aws_access” : {
</span><span class='line'>             “content” : { “Fn::Join” : [“”, [
</span><span class='line'>               “AWSAccessKeyId=”, { “Ref” : “HostKeys” }, “n”,
</span><span class='line'>               “AWSSecretKey=”, {“Fn::GetAtt”: [“HostKeys”, “SecretAccessKey”]}
</span><span class='line'>             ]]},
</span><span class='line'>             “mode” : “000400”,
</span><span class='line'>             “owner” : “tomcat”,
</span><span class='line'>             “group” : “tomcat”,
</span><span class='line'>             “authentication” : “S3AccessCreds”
</span><span class='line'>           },
</span><span class='line'>
</span><span class='line'>          “/opt/aws/aws.config” : {
</span><span class='line'>             “content” : { “Fn::Join” : [“”, [
</span><span class='line'>               “AWS.config(n”,
</span><span class='line'>               “:access_key_id =&gt; ”“, {”Ref" : “HostKeys” }, “”,n",
</span><span class='line'>               “:secret_access_key =&gt; ”“, {”Fn::GetAtt“: [”HostKeys“,”SecretAccessKey“]},”“)n”
</span><span class='line'>             ]]},
</span><span class='line'>             “mode” : “000500”,
</span><span class='line'>             “owner” : “tomcat”,
</span><span class='line'>             “group” : “tomcat”
</span><span class='line'>           },
</span><span class='line'>
</span><span class='line'>          “/etc/httpd/conf/httpd.conf2” : {
</span><span class='line'>             “content” : { “Fn::Join” : [“”, [
</span><span class='line'>               “NameVirtualHost *:80n”,
</span><span class='line'>               “n”,
</span><span class='line'>               “ProxyPass /jenkins http://”, { “Fn::Join” : [“”, [{ “Ref” : “ApplicationName” }, “.”, { “Ref” : “HostedZone” }]] }, “:8080/jenkinsn”,
</span><span class='line'>               “ProxyPassReverse /jenkins http://”, { “Fn::Join” : [“”,[{ “Ref” : “ApplicationName” }, “.”, { “Ref” : “HostedZone” }]] },“:8080/jenkinsn”,
</span><span class='line'>               “ProxyRequests Offn”,
</span><span class='line'>              “n”,
</span><span class='line'>               “Order deny,allown”,
</span><span class='line'>               “Allow from alln”,
</span><span class='line'>               “n”,
</span><span class='line'>               “RewriteEngine Onn”,
</span><span class='line'>               “RewriteRule ^/$ http://”, { “Fn::Join” : [“”, [{ “Ref” : “ApplicationName” }, “.”, { “Ref” : “HostedZone” }]] },“:8080/jenkins$1 [NC,P]n”, “”
</span><span class='line'>             ]]},
</span><span class='line'>             “mode” : “000544”,
</span><span class='line'>             “owner” : “root”,
</span><span class='line'>             “group” : “root”
</span><span class='line'>           },
</span><span class='line'>
</span><span class='line'>          “/root/.ssh/config” : {
</span><span class='line'>             “content” : { “Fn::Join” : [“”, [
</span><span class='line'>               “Host github.comn”,
</span><span class='line'>               “StrictHostKeyChecking non”
</span><span class='line'>             ]]},
</span><span class='line'>             “mode” : “000600”,
</span><span class='line'>             “owner” : “root”,
</span><span class='line'>             “group” : “root”
</span><span class='line'>           },
</span><span class='line'>
</span><span class='line'>          “/usr/share/tomcat6/.route53” : {
</span><span class='line'>             “content” : { “Fn::Join” : [“”, [
</span><span class='line'>               “access_key:”, { “Ref” : “HostKeys” }, “n”,
</span><span class='line'>               “secret_key:”, {“Fn::GetAtt”: [“HostKeys”,“SecretAccessKey”]}, “n”,
</span><span class='line'>               “api: ‘2012-02-29’n”,
</span><span class='line'>               “endpoint: https://route53.amazonaws.com/n”,
</span><span class='line'>               “default_ttl: ‘3600’”
</span><span class='line'>             ]]},
</span><span class='line'>             “mode” : “000700”,
</span><span class='line'>             “owner” : “tomcat”,
</span><span class='line'>             “group” : “tomcat”
</span><span class='line'>           }
</span><span class='line'>         }
</span><span class='line'>       }
</span><span class='line'>     },
</span><span class='line'>
</span><span class='line'>     “AWS::CloudFormation::Authentication” : {
</span><span class='line'>       “S3AccessCreds” : {
</span><span class='line'>         “type” : “S3”,
</span><span class='line'>         “accessKeyId” : { “Ref” : “HostKeys” },
</span><span class='line'>         “secretKey” : {“Fn::GetAtt”: [“HostKeys”, “SecretAccessKey”]},
</span><span class='line'>         “buckets” : [ { “Ref” : “S3Bucket”} ]
</span><span class='line'>       }
</span><span class='line'>     }
</span><span class='line'>   },
</span><span class='line'>
</span><span class='line'>   “Properties”: {
</span><span class='line'>     “ImageId” : { “Fn::FindInMap” : [ “AWSRegionArch2AMI”, { “Ref” : “AWS::Region” }, { “Fn::FindInMap” : [ “AWSInstanceType2Arch”, { “Ref” : “InstanceType” }, “Arch” ] } ] },
</span><span class='line'>     “InstanceType” : { “Ref” : “InstanceType” },
</span><span class='line'>     “SecurityGroups” : [ {“Ref” : “FrontendGroup”} ],
</span><span class='line'>     “KeyName” : { “Ref” : “KeyName” },
</span><span class='line'>     “Tags”: [ { “Key”: “Name”, “Value”: “Jenkins” } ],
</span><span class='line'>     “UserData” : { “Fn::Base64” : { “Fn::Join” : [“”, [
</span><span class='line'>       “#!/bin/bash -vn”,
</span><span class='line'>       “yum -y install java-1.6.0-openjdk*n”,
</span><span class='line'>       “yum update -y aws-cfn-bootstrapn”,
</span><span class='line'>
</span><span class='line'>      “# Install packagesn”,
</span><span class='line'>       “/opt/aws/bin/cfn-init -s”, { “Ref” : “AWS::StackName” }, " -r WebServer ",
</span><span class='line'>       " –access-key “, {”Ref" : “HostKeys” },
</span><span class='line'>       " –secret-key “, {”Fn::GetAtt“: [”HostKeys“,”SecretAccessKey"]},
</span><span class='line'>       " –region “, {”Ref" : “AWS::Region” }, " || error_exit ‘Failed to run cfn-init’n",
</span><span class='line'>
</span><span class='line'>      “# Copy Github credentials to root ssh directoryn”,
</span><span class='line'>       “cp /usr/share/tomcat6/.ssh/* /root/.ssh/n”,
</span><span class='line'>
</span><span class='line'>      “# Installing Ruby 1.9.3 from RPMn”,
</span><span class='line'>       “wget -P /home/ec2-user/ https://s3.amazonaws.com/”, { “Ref” : “S3Bucket” }, “/resources/rpm/ruby-1.9.3p0-2.amzn1.x86_64.rpmn”,
</span><span class='line'>       “rpm -Uvh /home/ec2-user/ruby-1.9.3p0-2.amzn1.x86_64.rpmn”,
</span><span class='line'>
</span><span class='line'>      “cat /etc/httpd/conf/httpd.conf2 &gt;&gt; /etc/httpd/conf/httpd.confn”,
</span><span class='line'>
</span><span class='line'>      “# Install S3 Gemsn”,
</span><span class='line'>       “gem install /home/ec2-user/common-step-definitions-1.0.0.gemn”,
</span><span class='line'>
</span><span class='line'>      “# Install Public Gemsn”,
</span><span class='line'>       “gem install bundler –version 1.1.4 –no-rdoc –no-rin”,
</span><span class='line'>       “gem install aws-sdk –version 1.5.6 –no-rdoc –no-rin”,
</span><span class='line'>       “gem install cucumber –version 1.2.1 –no-rdoc –no-rin”,
</span><span class='line'>       “gem install net-ssh –version 2.5.2 –no-rdoc –no-rin”,
</span><span class='line'>       “gem install capistrano –version 2.12.0 –no-rdoc –no-rin”,
</span><span class='line'>       “gem install route53 –version 0.2.1 –no-rdoc –no-rin”,
</span><span class='line'>       “gem install rspec –version 2.10.0 –no-rdoc –no-rin”,
</span><span class='line'>       “gem install trollop –version 2.0 –no-rdoc –no-rin”,
</span><span class='line'>
</span><span class='line'>      “# Update Jenkins with versioned configurationn”,
</span><span class='line'>       “rm -rf /usr/share/tomcat6/.jenkinsn”,
</span><span class='line'>       “git clone git@github.com:stelligent/continuous_delivery_open_platform_jenkins_configuration.git /usr/share/tomcat6/.jenkinsn”,
</span><span class='line'>
</span><span class='line'>      “# Get S3 bucket publisher from S3n”,
</span><span class='line'>       “wget -P /usr/share/tomcat6/.jenkins/ https://s3.amazonaws.com/”, { “Ref” : “S3Bucket” }, “/hudson.plugins.s3.S3BucketPublisher.xmln”,
</span><span class='line'>
</span><span class='line'>      “wget -P /tmp/ https://raw.github.com/stelligent/continuous_delivery_open_platform/master/config/aws/cd_security_group.rbn”,
</span><span class='line'>       “ruby /tmp/cd_security_group –securityGroupName”, { “Ref” : “FrontendGroup” }, " –port 5432n",
</span><span class='line'>
</span><span class='line'>      “# Update main Jenkins confign”,
</span><span class='line'>       “sed -i ’s@.*@”, { “Ref” : “HostKeys” }, “@’ /usr/share/tomcat6/.jenkins/hudson.plugins.s3.S3BucketPublisher.xmln”,
</span><span class='line'>       “sed -i ‘s@.*@“, {”Fn::GetAtt“: [”HostKeys“,”SecretAccessKey“]},”@’ /usr/share/tomcat6/.jenkins/hudson.plugins.s3.S3BucketPublisher.xmln”,
</span><span class='line'>
</span><span class='line'>      “# Add AWS Credentials to Tomcatn”,
</span><span class='line'>       “echo ”AWS_ACCESS_KEY=“, {”Ref" : “HostKeys” }, “” &gt;&gt; /etc/sysconfig/tomcat6n",
</span><span class='line'>       “echo ”AWS_SECRET_ACCESS_KEY=“, {”Fn::GetAtt“: [”HostKeys“,”SecretAccessKey“]},”" &gt;&gt; /etc/sysconfig/tomcat6n",
</span><span class='line'>
</span><span class='line'>      “# Add AWS CLI Toolsn”,
</span><span class='line'>       “echo ”export AWS_CLOUDFORMATION_HOME=/opt/aws/apitools/cfn" &gt;&gt; /etc/sysconfig/tomcat6n",
</span><span class='line'>       “echo ”export AWS_SNS_HOME=/opt/aws/apitools/sns" &gt;&gt; /etc/sysconfig/tomcat6n",
</span><span class='line'>       “echo ”export PATH=$PATH:/opt/aws/apitools/sns/bin:/opt/aws/apitools/cfn/bin" &gt;&gt; /etc/sysconfig/tomcat6n",
</span><span class='line'>
</span><span class='line'>      “# Add Jenkins Environment Variablen”,
</span><span class='line'>       “echo ”export SNS_TOPIC=“, {”Ref" : “MySNSTopic” }, “” &gt;&gt; /etc/sysconfig/tomcat6n",
</span><span class='line'>       “echo ”export JENKINS_DOMAIN=“, {”Fn::Join" : [“”, [“http://”,{ “Ref” : “ApplicationName” }, “.”, { “Ref” : “HostedZone” }]] }, “”&gt;&gt; /etc/sysconfig/tomcat6n",
</span><span class='line'>       “echo ”export JENKINS_ENVIRONMENT=“, {”Ref" : “ApplicationName” }, “” &gt;&gt; /etc/sysconfig/tomcat6n",
</span><span class='line'>
</span><span class='line'>      “wget -P /tmp/ https://raw.github.com/stelligent/continuous_delivery_open_platform/master/config/aws/showback_domain.rbn”,
</span><span class='line'>       “echo ”export SGID=`ruby /tmp/showback_domain.rb –item properties –key SGID`" &gt;&gt; /etc/sysconfig/tomcat6n",
</span><span class='line'>
</span><span class='line'>      “chown -R tomcat:tomcat /usr/share/tomcat6/n”,
</span><span class='line'>       “chmod +x /usr/share/tomcat6/scripts/aws/*n”,
</span><span class='line'>       “chmod +x /opt/aws/apitools/cfn/bin/*n”,
</span><span class='line'>
</span><span class='line'>      “service tomcat6 restartn”,
</span><span class='line'>       “service httpd restartn”,
</span><span class='line'>
</span><span class='line'>      “/opt/aws/bin/cfn-signal”, " -e 0“,” ’“, {”Ref" : “WaitHandle” },“’”
</span><span class='line'>     ]]}}
</span><span class='line'>   }
</span><span class='line'> },</span></code></pre></td></tr></table></div></figure>


<p> Calling <a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/cfn-init.html">cfn init</a> from <code>UserData</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> "# Install packagesn", 
</span><span class='line'>  "/opt/aws/bin/cfn-init -s ", { "Ref" : "AWS::StackName" }, " -r WebServer ",
</span><span class='line'>  " --access-key ", { "Ref" : "HostKeys" },
</span><span class='line'>  " --secret-key ", {"Fn::GetAtt": ["HostKeys", "SecretAccessKey"]},
</span><span class='line'>  " --region ", { "Ref" : "AWS::Region" }, " || error_exit 'Failed to run cfn-init'n", 
</span><span class='line'>  },</span></code></pre></td></tr></table></div></figure>


<p><code>cfn_init</code> is used to retrieve and interpret the resource metadata, installing packages, creating files and starting services. In the Manatee template we use <code>cfn_init</code> for easy access to other AWS resources, such as S3.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> "/etc/tomcat6/server.xml" : {
</span><span class='line'>   "source" : { "Fn::Join" : ["", ["https://s3.amazonaws.com/", { "Ref" : "S3Bucket" }, "/server.xml"]]},
</span><span class='line'>   "mode" : "000554",
</span><span class='line'>   "owner" : "root",
</span><span class='line'>   "group" : "root",
</span><span class='line'>   "authentication" : "S3AccessCreds" },
</span><span class='line'>
</span><span class='line'>   "AWS::CloudFormation::Authentication" : {
</span><span class='line'>     "S3AccessCreds" : {
</span><span class='line'>       "type" : "S3",
</span><span class='line'>       "accessKeyId" : { "Ref" : "HostKeys" },
</span><span class='line'>       "secretKey" : {"Fn::GetAtt": ["HostKeys", "SecretAccessKey"]},
</span><span class='line'>       "buckets" : [ { "Ref" : "S3Bucket"} ]
</span><span class='line'>     }
</span><span class='line'>   }</span></code></pre></td></tr></table></div></figure>


<p>When possible, we try to use <code>cfn_init</code> rather than <code>UserData</code> bash commands because it stores a detailed log of Cfn events on the instance.</p>

<p><strong><a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-security-group.html">AWS::EC2::SecurityGroup</a></strong></p>

<p>When creating a <a href="http://jenkins-ci.org/">Jenkins</a> instance, we only want certain ports to be open and only open to certain users. For this we use Security Groups. Security groups are firewall rules defined at the AWS level. You can use them to set which ports, or range of ports to be opened. In addition to defining which ports are to be open, you can define who they should be open to using CIDR.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> "FrontendGroup" : {
</span><span class='line'>   "Type" : "AWS::EC2::SecurityGroup",   
</span><span class='line'>   "Properties" : {
</span><span class='line'>     "GroupDescription" : "Enable SSH and access to Apache and Tomcat",
</span><span class='line'>     "SecurityGroupIngress" : [
</span><span class='line'>       {"IpProtocol" : "tcp", "FromPort" : "22", "ToPort" : "22", "CidrIp" : "0.0.0.0/0"},
</span><span class='line'>       {"IpProtocol" : "tcp", "FromPort" : "8080", "ToPort" : "8080", "CidrIp" : "0.0.0.0/0"},
</span><span class='line'>       {"IpProtocol" : "tcp", "FromPort" : "80", "ToPort" : "80", "CidrIp" : "0.0.0.0/0"}
</span><span class='line'>     ]
</span><span class='line'>   }
</span><span class='line'> },</span></code></pre></td></tr></table></div></figure>


<p>In this security group we are opening ports 22, 80 and 8080. Since we are opening 8080, we are able to access Jenkins at the completion of the template. By default, ports on an instance are closed, meaning these are necessary to be specified in order to have access to Jenkins.</p>

<p><strong><a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-eip.html">AWS::EC2::EIP</a></strong></p>

<p>When an instance is created, it is given a public DNS name similar to: ec2-107-20-139-148.compute-1.amazonaws.com. By using Elastic IPs, you can associate your instance an IP rather than a DNS.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> "IPAddress" : {   "Type" : "AWS::EC2::EIP" 
</span><span class='line'> },
</span><span class='line'>
</span><span class='line'>“IPAssoc” : {
</span><span class='line'>   “Type” : “AWS::EC2::EIPAssociation”,
</span><span class='line'>   “Properties” : {
</span><span class='line'>     “InstanceId” : { “Ref” : “WebServer” },
</span><span class='line'>     “EIP” : { “Ref” : “IPAddress” }
</span><span class='line'>   }
</span><span class='line'> },</span></code></pre></td></tr></table></div></figure>


<p> In the snippets above, we create a new Elastic IP and then associate it with the EC2 instance created above. We do this so we can reference the Elastic IP when creating the <a href="http://aws.amazon.com/route53/">Route53</a> Domain name.</p>

<p><strong><a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/aws-properties-cw-alarm.html">AWS::CloudWatch::Alarm</a></strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> "CPUAlarmLow": {
</span><span class='line'>   "Type": "AWS::CloudWatch::Alarm",
</span><span class='line'>   "Properties": {
</span><span class='line'>     "AlarmDescription": "Scale-down if CPU &lt; 70% for 10 minutes",
</span><span class='line'>     "MetricName": "CPUUtilization",     "Namespace": "AWS/EC2",
</span><span class='line'>     "Statistic": "Average",     "Period": "300",
</span><span class='line'>     "EvaluationPeriods": "2",
</span><span class='line'>     "Threshold": "70",
</span><span class='line'>     "AlarmActions": [ { "Ref": "SNSTopic" } ],
</span><span class='line'>     "Dimensions": [{
</span><span class='line'>       "Name": "WebServerName",
</span><span class='line'>       "Value": { "Ref": "WebServer" }
</span><span class='line'>     }],
</span><span class='line'>     "ComparisonOperator": "LessThanThreshold"
</span><span class='line'>   }
</span><span class='line'> },</span></code></pre></td></tr></table></div></figure>


<p>There are many reasons an instance can become unavailable. <a href="http://aws.amazon.com/cloudwatch/">CloudWatch</a> is used to monitor instance usage and performance. CloudWatch can be set to notify specified individuals if the instance experiences higher than normal CPU utilization, disk usage, network usage, etc. In the Manatee infrastructure we use CloudWatch to monitor disk utilization and notify team members if it reaches 90 percent.</p>

<p>If the Jenkins instance goes down, our CD pipeline becomes temporarily unavailable. This presents a problem as the development team is temporarily blocked from testing their code. CloudWatch helps notify us if this is an impending problem..</p>

<p><strong><a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/aws-properties-waitconditionhandle.html">AWS::CloudFormation::WaitConditionHandle</a>,
<a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/aws-properties-waitcondition.html">AWS::CloudFormation::WaitCondition</a></strong></p>

<p>Wait Conditions are used to wait for all of the resources in a template to be completed before signally template success.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> "WaitHandle" : {
</span><span class='line'>   "Type" : "AWS::CloudFormation::WaitConditionHandle" 
</span><span class='line'> },
</span><span class='line'>
</span><span class='line'>“WaitCondition” : {
</span><span class='line'>   “Type” : “AWS::CloudFormation::WaitCondition”,
</span><span class='line'>   “DependsOn” : “WebServer”,
</span><span class='line'>   “Properties” : {
</span><span class='line'>     “Handle” : { “Ref” : “WaitHandle” },
</span><span class='line'>     “Timeout” : “990”
</span><span class='line'>   }
</span><span class='line'> }</span></code></pre></td></tr></table></div></figure>


<p>When creating the instance, if a wait condition is not used, CloudFormation won’t wait for the completion of the <code>UserData</code> script. It will signal success if the EC2 instance is allocated successfully rather than waiting for the <code>UserData</code> script to run and signal success.</p>

<h2>Outputs</h2>

<p>Outputs are used to return information from what was created during the CloudFormaiton stack creation to the user. In order to return values, you define the Output name and then the resource you want to reference:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> "Outputs" : {
</span><span class='line'>   "Domain" : {
</span><span class='line'>     "Value" : { "Fn::Join" : ["", ["http://", { "Ref" : "ApplicationName" }, ".", { "Ref" : "HostedZone" }]]
</span><span class='line'> },
</span><span class='line'>     "Description" : "URL for newly created Jenkins app"   
</span><span class='line'> },
</span><span class='line'>   "NexusURL" : {
</span><span class='line'>     "Value" : { "Fn::Join" : ["", ["http://", { "Ref" : "IPAddress" }, ":8080/nexus"]] },
</span><span class='line'>     "Description" : "URL for newly created Nexus repository"
</span><span class='line'>   },
</span><span class='line'>   "InstanceIPAddress" : {
</span><span class='line'>     "Value" : { "Ref" : "IPAddress"  }
</span><span class='line'>  } 
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>For instance with the InstanceIPAddress, we are refernceing the IPAddress resource which happens to be the Elastic IP. This will return the Elastic IP address to the CloudFormation console.</p>

<p>CloudFormation allows us to completely script and version our infrastructure. This enables our infrastructure to be recreated the same way every time by just running the CloudFormation template. Because of this, your environments can be run in a Continuous integration cycle, rebuilding with every change in the script.</p>

<p>In the next part of our series – which is all about Dynamic Configuration – we’ll go through building your infrastructure to only require a minimal amount of hard coded properties if any. In this next article, you’ll see how you can use CloudFormation to build “property file less” infrastructure.</p>

<p>Resources:</p>

<ul>
<li><a href="http://aws.amazon.com/cloudformation/">http://aws.amazon.com/cloudformation/</a></li>
<li><a href="http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/aws-template-resource-type-ref.html">http://docs.amazonwebservices.com/AWSCloudFormation/latest/UserGuide/aws-template-resource-type-ref.html</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
  
    
      <h1 class="entry-title"><a href="/blog/2014/04/04/tutorial-continuous-delivery-in-the-cloud-part-2-of-6/">Tutorial : Continuous Delivery in the Cloud Part 2 of 6</a></h1>
      
      
    
      <p class="meta">
        








  


<time datetime="2014-04-04T13:59:41-04:00" pubdate data-updated="true">Apr 4<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In <a href="../continuous-delivery-in-the-cloud-case-study-for-the-sea-to-shore-alliance-introduction-part-1-of-6/index.html" title="Continuous Delivery in the Cloud: Part 1 of 6">part 1 of this series</a>, I introduced the <a href="http://refcardz.dzone.com/refcardz/continuous-delivery-patterns" title="Continuous Delivery patterns">Continuous Delivery</a> (CD) pipeline for the <a href="http://manatees.mapntracker.com/wildtracks/" title="Manatee Tracking Application">Manatee Tracking application</a> and how we use this pipeline to deliver software from checkin to production. In this article I will take an in-depth look at the CD pipeline. A list of topics for each of the articles is summarized below.</p>

<p><a href="../continuous-delivery-in-the-cloud-case-study-for-the-sea-to-shore-alliance-introduction-part-1-of-6/index.html" title="Continuous Delivery in the Cloud case study">Part 1: Introduction</a> – Introduction to continuous delivery in the cloud and the rest of the articles;
 Part 2: CD Pipeline – What you’re reading now;
 <a href="../continuous-delivery-in-the-cloud-cloudformation-part-3-of-6/index.html">Part 3: CloudFormation</a> – Scripted virtual resource provisioning;
 <a href="../continuous-delivery-in-the-cloud-dynamic-configuration-part-4-of-6/index.html">Part 4: Dynamic Configuration</a> – “Property file less” infrastructure;
 <a href="../continuous-delivery-in-the-cloud-deployment-automation-part-5-of-6/index.html">Part 5: Deployment Automation</a>
– Scripted deployment orchestration;
 <a href="../continuous-delivery-in-the-cloud-infrastructure-automation-part-6-of-6/index.html">Part 6: Infrastructure Automation</a> – Scripted environment provisioning (Infrastructure Automation)</p>

<p>The CD pipeline consists of five <a href="http://jenkins-ci.org/" title="Jenkins Continuous Integration">Jenkins</a> jobs. These jobs are configured to run one after the other. If any one of the jobs fail, the pipeline fails and that release  candidate cannot be released to production. The five Jenkins jobs are listed below (further details of these jobs are provided later in the article).</p>

<ol>
<li>A job that set the variables used throughout the pipeline (<strong>SetupVariables</strong>)</li>
<li>Build job (<strong>Build</strong>)</li>
<li>Production database update job (<strong>StoreLatestProductionData</strong>)</li>
<li>Target environment creation job (<strong>CreateTargetEnvironment</strong>)</li>
<li>A deployment job (<strong>DeployManateeApplication</strong>) which enables a    one-click deployment into production.</li>
</ol>


<p><img src="https://lh6.googleusercontent.com/Cp4ASyJBjWLEz8F6oR_HzllPqDE9FY8mQgiwplHGX9FJflA1lF_WqaVQTxIwXFumUH8PbuQtrkyVy-XxRTS3zDhUOXWntmu1lW1D3YnibpRu51K7pfDW" alt="" /></p>

<p>We used Jenkins plugins to add additional features to the core Jenkins configuration. You can extend the standard Jenkins setup by using <a href="http://www.stelligent.com/continuous-delivery-in-the-cloud-cd-pipeline-part-2-of-6/Jenkins%20plugins" title="Jenkins plugins">Jenkins plugins</a>. A list of the plugins we use for the Sea to Shore Alliance Continuous Delivery configuration are listed below.</p>

<ul>
<li><strong>Grails</strong>: <a href="http://updates.jenkins-ci.org/download/plugins/grails/1.5/grails.hpi">http://updates.jenkins-ci.org/download/plugins/grails/1.5/grails.hpi</a>****</li>
<li><strong>Groovy</strong>: <a href="http://updates.jenkins-ci.org/download/plugins/groovy/1.12/groovy.hpi">http://updates.jenkins-ci.org/download/plugins/groovy/1.12/groovy.hpi</a>****</li>
<li><strong>Subversion</strong>: <a href="http://updates.jenkins-ci.org/download/plugins/subversion/1.40/subversion.hpi">http://updates.jenkins-ci.org/download/plugins/subversion/1.40/subversion.hpi</a>****</li>
<li><strong>Paramterized Trigger</strong>: <a href="http://updates.jenkins-ci.org/download/plugins/parameterized-trigger/2.15/parameterized-trigger.hpi">http://updates.jenkins-ci.org/download/plugins/parameterized-trigger/2.15/parameterized-trigger.hpi</a>****</li>
<li><strong>Copy Artifact</strong>: <a href="http://updates.jenkins-ci.org/download/plugins/copyartifact/1.21/copyartifact.hpi">http://updates.jenkins-ci.org/download/plugins/copyartifact/1.21/copyartifact.hpi</a>****</li>
<li><strong>Build Pipeline</strong>: <a href="http://updates.jenkins-ci.org/download/plugins/build-pipeline-plugin/1.2.3/build-pipeline-plugin.hpi">http://updates.jenkins-ci.org/download/plugins/build-pipeline-plugin/1.2.3/build-pipeline-plugin.hpi</a>****</li>
<li><strong>Ant</strong>: <a href="http://updates.jenkins-ci.org/download/plugins/ant/1.1/ant.hpi">http://updates.jenkins-ci.org/download/plugins/ant/1.1/ant.hpi</a>****</li>
<li><strong>S3</strong>: <a href="http://updates.jenkins-ci.org/download/plugins/s3/0.2.0/s3.hpi">http://updates.jenkins-ci.org/download/plugins/s3/0.2.0/s3.hpi</a></li>
</ul>


<p>The parameterized trigger, build pipeline and <a href="http://aws.amazon.com/s3/" title="Amazon Simple Storage Service">S3</a> plugins are used for moving the application through the pipeline jobs. The Ant, Groovy, and Grails plugins are used for running the build for the application code. Subversion for polling and checking out from version control.</p>

<p>Below, I describe each of the jobs that make up the CD pipeline in greater detail.</p>

<p><strong>SetupVariables</strong>: Jenkins job used for entering in necessary property values which are propagated along the rest of the pipeline.</p>

<p><strong>Parameter</strong>: <strong>STACK_NAME</strong></p>

<p> <strong>Type</strong>: String</p>

<p> <strong>Where</strong>: Used in both <strong>CreateTargetEnvironment</strong> and <strong>DeployManateeApplication</strong> jobs</p>

<p> <strong>Purpose</strong>: Defines the <a href="http://aws.amazon.com/cloudformation/" title="AWS CloudFormation">CloudFormation</a> Stack name and <a href="http://aws.amazon.com/simpledb/" title="SimpleDB NoSQL">SimpleDB</a> property domain associated with the CloudFormation stack.</p>

<p><strong>Parameter</strong>: <strong>HOST</strong></p>

<p> <strong>Type</strong>: String</p>

<p> <strong>Where</strong>: Used in both <strong>CreateTargetEnvironment</strong> and <strong>DeployManateeApplication</strong> jobs</p>

<p> <strong>Purpose</strong>: Defines the CNAME of the domain created in the <strong>CreateTargetEnvironment</strong> job. The <strong>DeployManateeApplication</strong> job uses it when it dynamically creates configuration files. For instance, in test.oneclickdeployment.com, test would be the HOST</p>

<p><strong>Parameter</strong>: <strong>PRODUCTION_IP*
 </strong>Type<strong>: String
 </strong>Where<strong>: Used in the </strong>StoreProductionData<strong> job
 </strong>Purpose**: Sets the production IP for the job so that it can SSH into the existing production environment and run a database script that exports the data and uploads it to S3.</p>

<p><strong>Parameter</strong>: <strong>deployToProduction</strong>
 <strong>Type</strong>: Boolean
 <strong>Where</strong>: Used in both <strong>CreateTargetEnvironment</strong> and
<strong>DeployManateeApplication</strong> jobs
 <strong>Purpose</strong>: Determines whether to use the development or production SSH keypair.</p>

<p>In order for the parameters to propagate through the pipeline, we pass the current build parameters using the parametrized build trigger plugin</p>

<p><strong>Build</strong>: Compiles the Manatee application’s Grails source code and creates a WAR file.</p>

<p>To do this, we utilize a Jenkins grails plugin and run grails targets such as <code>compile</code> and <code>prod war</code>. Next, we archive the grails migrations for use in the <strong>DeployManateeApplication</strong> job and then the job pushes the Manatee WAR up to S3 which is used as an artifact repository.</p>

<p>Lastly, using the trigger parametrized build plugin, we trigger the <strong>StoreProductionData</strong> job with the current build parameters.</p>

<p><strong>StoreProductionData</strong>: This job performs a pg dump (PostgreSQL dump) of the production database and then stores it up in S3 for the environment creation job to use when building up the environment. Below is a snippet from this job.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ssh -i /usr/share/tomcat6/development.pem -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no ec2-user@${PRODUCTION_IP} ruby /home/ec2-user/database_update.rb</span></code></pre></td></tr></table></div></figure>


<p>On the target environments created using the CD pipeline, a database script is stored. The script goes into the PostgreSQL database and runs a pg_dump. It then pushes the pg_dump SQL file to S3 to be used when creating the target environment.</p>

<p>After the SQL file is stored successfully, the <strong>CreateTargetEnvironment</strong> job is triggered.</p>

<p><strong>CreateTargetEnvironment</strong>: Creates a new target environment using a CloudFormation template to create all the <a href="https://aws.amazon.com/" title="Amazon Web Services">AWS</a> resources and calls puppet to provision the environment itself from a base operating system to a fully working target environment ready for deployment. Below is a snippet from this job.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>if [ $deployToProduction ] then SSH_KEY=development else SSH_KEY=production fi
</span><span class='line'>
</span><span class='line'># Create Cloudformaton Stack
</span><span class='line'> ruby ${WORKSPACE}/config/aws/create_stack.rb ${STACK_NAME} ${WORKSPACE}/infrastructure/manatees/production.template ${HOST} ${JENKINSIP} ${SSH_KEY} ${SGID} ${SNS_TOPIC}
</span><span class='line'>
</span><span class='line'># Load SimpleDB Domain with Key/Value Pairs
</span><span class='line'> ruby ${WORKSPACE}/config/aws/load_domain.rb ${STACK_NAME}
</span><span class='line'>
</span><span class='line'># Pull and store variables from SimpleDB
</span><span class='line'> host=`ruby ${WORKSPACE}/config/aws/showback_domain.rb
</span><span class='line'>${STACK_NAME} InstanceIPAddress`
</span><span class='line'>
</span><span class='line'># Run Acceptance Tests
</span><span class='line'> cucumber ${WORKSPACE}/infrastructure/manatees/features/production.feature host=${host} user=ec2-user key=/usr/share/tomcat6/.ssh/id_rsa
</span><span class='line'>
</span><span class='line'># Publish notifications to SNS
</span><span class='line'> sns-publish –topic-arn $SNS_TOPIC –subject “New Environment Ready” –message “Your new environment is ready. IP Address: $host. 
</span><span class='line'> 
</span><span class='line'>An example command to ssh into the box would be: 
</span><span class='line'>
</span><span class='line'>ssh -i development.pem ec2-user@$host This instance was created by $JENKINS_DOMAIN” –aws-credential-file /usr/share/tomcat6/aws_access
</span></code></pre></td></tr></table></div></figure>


<p>Once the environment is created, a set of <a href="http://cukes.info" title="Cucumber Acceptance-Test Driven Development">Cucumber</a> tests is run to ensure it’s in the correct working state. If any test fails, the entire pipeline fails and the developer is notified something went wrong. Otherwise if it passes, the <strong>DeployManateeApplication</strong> job is kicked off and an AWS <a href="http://aws.amazon.com/sns/" title="Amazin Simple Notification Service">SNS</a> email notification with information to access the new instance is sent to the developer.</p>

<p><strong>DeployManateeApplication</strong>: Runs a <a href="https://github.com/capistrano/capistrano" title="Capistrano">Capistrano</a> script which uses steps in order to coordinate the deployment. A snippet from this job is displayed below.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>if [ !$deployToProduction ]
</span><span class='line'> then
</span><span class='line'>   SSH_KEY=/usr/share/tomcat6/development.pem
</span><span class='line'> else
</span><span class='line'>   SSH_KEY=/usr/share/tomcat6/production.pem 
</span><span class='line'> fi
</span><span class='line'>
</span><span class='line'>#/usr/share/tomcat6/.ssh/id_rsa
</span><span class='line'>
</span><span class='line'>cap deploy:setup stack=${STACK_NAME} key=${SSH_KEY}
</span><span class='line'>
</span><span class='line'>sed -i “s@manatee0@${HOST}@”
</span><span class='line'>${WORKSPACE}/deployment/features/deployment.feature
</span><span class='line'>
</span><span class='line'>host=`ruby ${WORKSPACE}/config/aws/showback_domain.rb ${STACK_NAME} InstanceIPAddress`
</span><span class='line'> cucumber deployment/features/deployment.feature host=${host} user=ec2-user key=${SSH_KEY} artifact=
</span><span class='line'>
</span><span class='line'>sns-publish –topic-arn $SNS_TOPIC –subject “Manatee Application Deployed” –message “Your Manatee Application has been deployed successfully. 
</span><span class='line'>You can view it by going to 
</span><span class='line'>http://$host/wildtracks This instance was deployed to by $JENKINS_DOMAIN” –aws-credential-file/usr/share/tomcat6/aws_access</span></code></pre></td></tr></table></div></figure>


<p>This deployment job is the final piece of the delivery pipeline, it pulls together all of the pieces created in the previous jobs to successfully deliver working software.</p>

<p>During the deployment, the Capistrano script SSH’s into the target server, deploys the new war and updated configuration changes and restarts all services. Then the Cucumber tests are run to ensure the application is available and running successfully. Assuming the tests pass, an AWS SNS email gets dispatched to the developer with information on how to access their new development application</p>

<p>We use Jenkins as the orchestrator of the pipeline. Jenkins executes a set of scripts and passes around parameters as it runs each job. Because of the role Jenkins plays, we want to make sure it’s treated the same way as application – meaning versioning and testing all of our changes to the system. For example, if a developer modifies the create environment job configuration, we want to have the ability to revert back if necessary. Due to this requirement we version the Jenkins configuration. The jobs, plugins and main configuration. To do this, a script is executed each hour using <code>cron.hourly</code> that checks for new jobs or updated configuration and commits them up to version control.</p>

<p>The CD pipeline that we have built for the Manatee application enables any change in the application, infrastructure, database or configuration to move through to production seamlessly using automation. This allows any new features, security fixes, etc. to be fully tested as it gets delivered to production at the click of a button.</p>

<p>In the next part of our series – which is all about using <a href="http://aws.amazon.com/cloudformation/" title="AWS CloudFormation">CloudFormation</a> – we’ll go through a CloudFormation template used to automate the creation of a Jenkins environment. In this next article, you’ll see how CloudFormation procures AWS resources and provisions our Jenkins CD Pipeline environment.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
  
    
      <h1 class="entry-title"><a href="/blog/2014/04/04/tutorial-continuous-delivery-in-the-cloud-part-1-of-6/">Tutorial : Continuous Delivery in the Cloud Part 1 of 6</a></h1>
      
      
    
      <p class="meta">
        








  


<time datetime="2014-04-04T13:59:32-04:00" pubdate data-updated="true">Apr 4<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>We help companies deliver software reliably and repeatedly using Continuous Delivery in the Cloud. With <a href="http://refcardz.dzone.com/refcardz/continuous-delivery-patterns" title="Continuous Delivery">Continuous Delivery</a> (CD), teams can deliver new versions of software to production by <a href="http://www.ibm.com/developerworks/agile/library/a-devops1/index.html" title="flattening of the software release process">flattening the software delivery process</a> and decreasing the cycle time between an idea and usable software through the automation of the entire delivery system: build, deployment, test, and release. CD is enabled through a delivery pipeline. With CD,our customers can choose when and how often to release to production. On top of this, we utilize the cloud so that customers can scale their infrastructure up and down and deliver software to users on demand.</p>

<p>We offer a solutions called <a href="../solutions/elastic-operations/index.html" title="Elastic Operations">Elastic Operations</a> which provides a Continuous Delivery platform along with expert engineering support and monitoring of a delivery pipeline that builds, tests, provisions and deploys software to target environments – as often as our customers choose. We’re in the process of open sourcing the platform utilized by <a href="../solutions/elastic-operations/index.html" title="Elastic Operations">Elastic Operations</a>.
In this six-part blog series, I am going to go over how we built out a Continuous Delivery solution for one of our customers <a href="http://public.sea2shore.org/" title="Sea to Shore Alliance">Sea to Shore Alliance</a>:</p>

<p><strong>Part 1: Introduction</strong> – What you’re reading now;
<strong><a href="../continuous-delivery-in-the-cloud-cd-pipeline-part-2-of-6/index.html" title="Continuous Delivery in the Cloud: Part 2 of 6">Part 2: CD Pipeline</a></strong>
– Automated pipeline to build, test, deploy, and release software continuously;
<strong><a href="../continuous-delivery-in-the-cloud-cloudformation-part-3-of-6/index.html">Part 3: CloudFormation</a></strong>
– Scripted virtual resource provisioning;
<strong><a href="../continuous-delivery-in-the-cloud-dynamic-configuration-part-4-of-6/index.html">Part 4: Dynamic Configuration</a></strong>
– “Property file less” infrastructure;
 <strong><a href="../continuous-delivery-in-the-cloud-deployment-automation-part-5-of-6/index.html">Part 5: Deployment Automation</a></strong>
– Scripted deployment orchestration;
 <strong><a href="../continuous-delivery-in-the-cloud-infrastructure-automation-part-6-of-6/index.html">Part 6: Infrastructure Automation</a></strong>
– Scripted environment provisioning (<a href="http://www.ibm.com/developerworks/agile/library/a-devops2/index.html" title="Infrastructure Automation">Infrastructure Automation</a>)</p>

<p>This year, we delivered this Continuous Delivery in the Cloud solution to the Sea to Shore Alliance. The Sea to Shore Alliance is a non-profit organization whose mission is to protect and conserve the world’s fragile coastal ecosystems and its endangered species such as manatees, sea turtles, and right whales. One of their first software systems tracks and monitors manatees. Prior to <a href="http://stelligent.com" title="Stelligent's">Stelligent</a>‘s involvement, the application was running on a single instance that was manually provisioned and deployed. As a result of the manual processes, there were no automated tests for the infrastructure or deployment. This made it impossible to reproduce environments or deployments the same way every time. Moreover, the knowledge to recreate these environments, builds and deployments were locked in the heads of a few key individuals. The <a href="http://manatees.mapntracker.com/wildtracks/" title="Tracking Manatees">production application</a> for tracking these Manatees, developed by <a href="http://www.sarvatix.com/">Sarvatix</a>, is located <a href="http://manatees.mapntracker.com/wildtracks/" title="Manatee Tracker">here</a>.</p>

<p>In this case study, I describe how we went from an untested manual process in which the development team was manually building software artifacts, creating environments and deploying, to a completely automated delivery pipeline that is triggered with every change.</p>

<p><strong>Figure 1</strong> illustrates the AWS architecture of the infrastructure that we designed for this Continuous Delivery solution.</p>

<p><img src="https://lh4.googleusercontent.com/jf8LnXDc6kUDE2gMHSLmkGln-G4VhSzJ2-fDXrv9NCj4ZuL_8feNpe-2EO0RqWTTDfr6aIrUlwfs9xTyETrjcm33hVxV-Ks058XLB2U69B5srpyNnxY" alt="" />
 There are two <a href="http://aws.amazon.com/cloudformation/" title="AWS CloudFormation">CloudFormation</a>
stacks being used, the <a href="http://jenkins-ci.org/" title="Jenkins Continuous Integration">Jenkins</a> stack – or Jenkins environment – as shown on the left and the Manatee stack – or Target environment – as shown on the right.</p>

<p><strong>The Jenkins Stack</strong></p>

<ol>
<li><ul>
<li>Creates the jenkins.example.com  <a href="http://aws.amazon.com/route53/" title="Route53">Route53</a> Hosted Zone</li>
</ul>
</li>
<li><ul>
<li>Creates an EC2 instance with Tomcat and Jenkins installed and configured on it.</li>
</ul>
</li>
<li><ul>
<li>Runs the CD Pipeline</li>
</ul>
</li>
</ol>


<p>The Manatee stack is slightly different, it utilizes the configuration provided by <a href="http://aws.amazon.com/simpledb/" title="SimpleDB NoSQL">SimpleDB</a> to create itself. This stack defines the target environment for which the application software is deployed.</p>

<p><strong>The Manatee Stack</strong></p>

<ol>
<li><ul>
<li>Creates the manatee.example.com Route53 Hosted Zone</li>
</ul>
</li>
<li><ul>
<li>Creates an EC2 instance with Tomcat, Apache, PostgreSQL installed on it.</li>
</ul>
</li>
<li><ul>
<li>Runs the Manatee application.</li>
</ul>
</li>
</ol>


<p>The Manatee stack is configured with CPU alarms that send an email notification to the developers/administrators when it becomes over-utilized. We’re in the process of scaling to additional instances when these types of alarms are triggered.</p>

<p>Both instances are encapsulated behind a security group so that they can talk between each other using the internal AWS network.</p>

<p><strong>Fast Facts</strong>
 <strong>Industry</strong>: Non-Profit
 <strong>Profile</strong>: Customer tracks and monitors endangered species such as manatees.
 <strong>Key Business Issues</strong>: The customer’s development team needed to have unencumbered access to resources along with automated environment creation and deployment.
 <strong>Stakeholders</strong>: Development team and scientists and others from the Sea to Shore Alliance
 <strong>Solution</strong>: Continuous Delivery in the Cloud (<a href="../solutions/elastic-operations/index.html" title="Elastic Operations">Elastic Operations</a>)
 <strong>Key Tools/Technologies</strong>: <a href="http://aws.amazon.com/" title="Amazon Web Services">AWS – Amazon Web Services</a> (CloudFormation, EC2, S3, SimpleDB, <a href="http://aws.amazon.com/iam/" title="AWS Identity and Access Management">IAM</a>, <a href="http://aws.amazon.com/cloudwatch/" title="CloudWatch">CloudWatch</a>, SNS), Jenkins, Capistrano, <a href="http://puppetlabs.com/" title="Puppet">Puppet</a>, Subversion, <a href="http://cukes.info/" title="Cucumber Acceptance-Test Driven Development">Cucumber</a>, <a href="http://www.liquibase.org/" title="Liquibase">Liquibase</a></p>

<p><strong>The Business Problem</strong>
 The customer needed an operations team that could be scaled up or down depending on the application need. The customer’s main requirements were to have unencumbered access to resources such as virtual hardware. Specifically, they wanted to have the ability to create a target environment and run an automated deployment to it without going to a separate team and submitting tickets, emails, etc. In addition to being able to create environments, the customer wanted to have more control over the resources being used; they wanted to have the ability to terminate resources if they were unused. To address these requirements we introduced an entirely automated solution which utilizes the AWS cloud for providing resources on-demand, along with other solutions for providing testing, environment provisioning and deployment.</p>

<p>On the Manatee project, we have five key objectives for the delivery infrastructure. The development team should be able to:</p>

<ol>
<li><ul>
<li>Deliver new software or updates to users on demand</li>
</ul>
</li>
<li><ul>
<li>Reprovision target environment configuration on demand</li>
</ul>
</li>
<li><ul>
<li>Provision environments on demand</li>
</ul>
</li>
<li><ul>
<li>Remove configuration bottlenecks</li>
</ul>
</li>
<li><ul>
<li>Ability for users to terminate instances</li>
</ul>
</li>
</ol>


<p><strong>Our Team</strong>
 <a href="http://stelligent.com" title="Stelligent's">Stelligent</a>’s team consisted of an account manager and one polyskilled <a href="http://www.informit.com/store/product.aspx?isbn=0321793269" title="DevOps">DevOps</a> Engineer that built, managed, and supported the Continuous Delivery pipeline.</p>

<p><strong>Our Solution</strong>
 Our solution, a single delivery pipeline that gives our customer (developers, testers, etc.) unencumbered access to resources and a single click automated deployment to production. To enable this, the pipeline needed to include:</p>

<ol>
<li><ul>
<li>The ability for any authorized team member to create a new target  environment using a single click</li>
</ul>
</li>
<li><ul>
<li>Automated deployment to the target environment</li>
</ul>
</li>
<li><ul>
<li>End-to-end testing</li>
</ul>
</li>
<li><ul>
<li>The ability to terminate unnecessary environments</li>
</ul>
</li>
<li><ul>
<li>Automated deployment into production with a single click</li>
</ul>
</li>
</ol>


<p>The delivery pipeline improves efficiency and reduces costs by not limiting the development team. The solution includes:</p>

<p><strong>On-Demand Provisioning</strong> – All hardware is provided via EC2’s virtual instances in the cloud, on demand. As part of the CD pipeline, any authorized team member can use the Jenkins CreateTargetEnvironment job to order target environments for development work.</p>

<p><strong>Continuous Delivery Solution so that the team can deliver software to users on demand</strong>:</p>

<ul>
<li>Dependency Management using <a href="http://ant.apache.org/ivy/" title="Ivy">Ivy</a> (through <a href="http://grails.org/" title="Grails">Grails</a>).</li>
<li>Database Integration/Change using  <a href="http://www.liquibase.org" title="Liquibase">Liquibase</a></li>
<li>Testing using <a href="http://cukes.info/" title="Cucumber">Cucumber</a></li>
<li>Custom <a href="http://capistranorb.com/" title="Capistrano">Capistrano</a> scripts     for remote deployment.</li>
<li><a href="http://amzn.to/cibook" title="Continuous Integration">Continuous     Integration</a> server     using <a href="http://jenkins-ci.org/" title="Jenkins">Jenkins</a></li>
<li>Continuous Delivery pipeline system – we customized Jenkins to build     a delivery pipeline</li>
</ul>


<p><strong>Development Infrastructure</strong> – Consists of:</p>

<ul>
<li><a href="http://tomcat.apache.org/" title="Tomcat">Tomcat</a>: used for hosting the     Manatee Application</li>
<li><a href="http://httpd.apache.org/" title="Apache">Apache</a>: Hosted the front-end     website and used virtual hosts for proxying and redirection.</li>
<li><a href="http://www.postgresql.org/" title="PostgreSQL">PostgreSQL</a>: Database for     the Manatee application</li>
<li><a href="http://groovy.codehaus.org/" title="Groovy">Groovy</a>: the application is     written in Grails which uses Groovy.</li>
</ul>


<p><strong>Instance Management</strong> – Any authorized team member is able to monitor virtual instance usage by viewing Jenkins. There is a policy that test instances are automatically terminated every two days. This promotes ephemeral environments and test automation.</p>

<p><strong>Deployment to Production</strong> – There’s a boolean value (i.e. a checkbox the user selects) in the delivery pipeline used for deciding whether to deploy to production.</p>

<p><strong>System Monitoring and Disaster Recovery</strong> – Using the AWS CloudWatch service, AWS provides us with detailed monitoring to notify us of instance errors or anomalies through statistics such as CPU utilization, Network IO, Disk utilization, etc. Using these solutions we’ve implemented an automated disaster recovery solution.</p>

<p>A list of the AWS tools we utilized are enumerated below.</p>

<p><strong>Tool</strong>: <a href="http://aws.amazon.com/ec2/" title="AWS EC2">AWS EC2</a>
 <strong>What is it?</strong> Cloud-based virtual hardware instances
 <strong>Our Use</strong>: We use EC2 for all of our virtual hardware needs. All instances, from development to production are run on EC2</p>

<p><strong><strong> </strong>Tool</strong>: <a href="http://aws.amazon.com/s3/" title="AWS S3">AWS S3</a>
 <strong>What is it?</strong> Cloud-based storage
 <strong>Our Use</strong>: We use S3 as both a binary repository and a place to store successful build artifacts.</p>

<p><strong>Tool</strong>:  <a href="http://aws.amazon.com/iam/" title="AWS IAM">AWS IAM</a>
 <strong>What is it?</strong> User-based access to AWS resources
 <strong>Our Use</strong>: We create users dynamically and use their AWS access and secret access keys so we don’t have to store credentials as properties</p>

<p><strong>Tool</strong>: <a href="http://aws.amazon.com/cloudwatch/" title="AWS CloudWatch">AWS
CloudWatch</a>
 <strong>What is it?</strong> System monitoring
 <strong>Our Use</strong>: Monitors all instances in production. If an instance takes an abnormal amount of strain or shuts down unexpectedly, SNS sends an email to designated parties</p>

<p><strong>Tool</strong>: <a href="http://aws.amazon.com/sns/" title="AWS SNS">AWS SNS</a>
 <strong>What is it?</strong> Email notifications
 <strong>Our Use</strong>: When an environment is created or a deployment is run, SNS is used to send notifications to affected parties.</p>

<p><strong>Tool</strong>: <a href="http://cukes.info/" title="Cucumber">Cucumber</a>
 <strong>What is it?</strong> Acceptance testing
 <strong>Our Use</strong>: Cucumber is used for testing at almost every step of the way. We use Cucumber to test infrastructure, deployments and application code to ensure correct functionality. Cucumber’s unique english-ess  verbiage allows both technical personnel and customers to communicate using an executable test.</p>

<p><strong>Tool</strong>: <a href="http://www.liquibase.org" title="Liquibase">Liquibase</a>
 <strong>What is it?</strong> Automated database change management
 <strong>Our Use</strong>: Liquibase is used for all database changesets. When a change is necessary within the database, it is made to a liquibase changelog.xml</p>

<p><strong>Tool</strong>: <a href="http://aws.amazon.com/cloudformation/" title="AWS CloudFormation">AWS
CloudFormation</a>
 <strong>What is it?</strong> Templating language for orchestrating all AWS resources
 <strong>Our Use</strong>: CloudFormation is used for creating a fully working Jenkins environment and Target environment. For instance for the Jenkins environment it creates the EC2 instance with CloudWatch monitoring alarms, associated IAM user, SNS notification topic, everything required for Jenkins to build. This along with Jenkins are the major pieces of the infrastructure.</p>

<p><strong>Tool</strong>: <a href="http://aws.amazon.com/simpledb/" title="AWS Simple DB">AWS
SimpleDB</a>
 <strong>What is it?</strong> Cloud-based NoSQL database
 <strong>Our Use</strong>: SimpleDB is used for storing dynamic property configuration and passing properties through the CD Pipeline. As part of the environment creation process, we store multiple values such as IP addresses that we need when deploying the application to the created environment.</p>

<p><strong>Tool</strong>: <a href="http://jenkins-ci.org/" title="Jenkins">Jenkins</a>
 <strong>What is it?</strong> We’re using Jenkins to implement a CD pipeline using the Build Pipeline plugin.
 <strong>Our Use</strong>: Jenkins runs the CD pipeline which does the building, testing, environment creation and deploying. Since the CD pipeline is also code (i.e. configuration code), we version our Jenkins configuration.</p>

<p><strong>Tool</strong>: <a href="http://capistranorb.com/" title="Capistrano">Capistrano</a>
 <strong>What is it?</strong> Deployment automation
 <strong>Our Use</strong>: Capistrano orchestrates and automates deployments.
Capistrano is a Ruby-based deployment DSL that can be used to deploy to multiple platforms including Java, Ruby and PHP. It is called as part of the CD pipeline and deploys to the target environment.</p>

<p><strong>Tool</strong>: <a href="http://puppetlabs.com/" title="Puppet">Puppet</a>
 <strong>What is it?</strong> Infrastructure automation
 <strong>Our Use</strong>: Puppet takes care of the environment provisioning.
CloudFormation requests the environment and then calls Puppet to do the dynamic configuration. We configured Puppet to install, configure, and manage the packages, files and services.</p>

<p><strong>Tool</strong>: <a href="http://subversion.tigris.org/" title="Subversion">Subversion</a>
 <strong>What is it?</strong> Version control system
 <strong>Our Use</strong>: Subversion is the version control repository where every piece of the Manatee infrastructure is stored. This includes the environment scripts such as the Puppet modules, the CloudFormation templates, Capistrano deployment scripts, etc.</p>

<p>We applied the on-demand usability of the cloud with a proven continuous delivery approach to build an automated one click method for building and deploying software into scripted production environments.</p>

<p>In the blog series, I will describe the technical implementation of how we went about building this infrastructure into a complete solution for continuously delivering software. This series will consist of the following:</p>

<p><strong>Part 2 of 6 – CD Pipeline</strong>: I will go through the technical implementation of the CD pipeline using Jenkins. I will also cover Jenkins versioning, pulling and pushing artifacts from S3, and Continuous Integration.</p>

<p><strong>Part 3 of 6 – CloudFormation</strong>: I will go through a CloudFormation template we’re using to orchestrate the creation of AWS resources and to build the Jenkins and target infrastructure.</p>

<p><strong>Part 4 of 6 – Dynamic Configuration</strong>: Will cover dynamic property configuration using SimpleDB</p>

<p><strong>Part 5 of 6 – Deployment Automation</strong>: I will explain Capistrano in detail along how we used Capistrano to deploy build artifacts and run Liquibase database changesets against target environments</p>

<p><strong>Part 6 of 6 – Infrastructure Automation</strong>: I will describe the features of Puppet in detail along with how we’re using Puppet to build and configure target environments – for which the software is deployed.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
  
    
      <h1 class="entry-title"><a href="/blog/2014/03/25/continuous-delivery-implementation-laying-the-foundations-of-a-continuous-delivery-pipeline/">Continuous Delivery Implementation : Laying the Foundations of a Continuous Delivery Pipeline</a></h1>
      
      
    
      <p class="meta">
        








  


<time datetime="2014-03-25T15:02:54-04:00" pubdate data-updated="true">Mar 25<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>This article is part of the Continuous Delivery Blueprints series. It
discusses how to go from no cloud infrastructure and no continuous
integration set up to having a functioning Continuous Delivery Pipeline
in Amazon Web Services. It discusses high level topics while also
providing a reference implementation so it’s easy to follow along with.
You can read part one
<a href="../getting-started-with-aws-the-right-way/index.html" title="here">here</a>.</p>

<p>What we’re going to do today:</p>

<ul>
<li>• Set up Version Control System</li>
<li>• Migrate code into Version Control System</li>
<li>• Launch Jenkins Server</li>
<li>• Explore Jenkins Server</li>
</ul>


<p>With your AWS account set up and ready to go, it’s time to start setting
up your pipeline. At the end of this article, you’ll have a functioning
Continuous Integration server, and can start building out your
pipeline.\</p>

<hr />

<p><strong>Set up a Version Control System</strong></p>

<p>****To do any kind of continuous integration, delivery, or deployment,
you need your source code in source control. It’s the foundation upon
which everything else is built. If your source is already under a
version control system, you can just skip this step.</p>

<p>Otherwise, it’s time to set up a source control system there are two
options when it comes to source control: either you can build and run
the server which your source control service lives on, or you can use a
hosted source control provider.</p>

<p>Choosing a hosted provider gives you a lot of things — you can instantly
start using it without having to configure any sort of server; you don’t
have to worry about backups and disaster recovery; you’ll always be able
to take advantage of the latest features. On the downside, you are
giving your source code to another entity, which may not be an
acceptable trade off at your organization. You’ll need to figure out
which solution works best for you. If you’re not using source control
already, this is probably the easiest option.</p>

<p>For the purposes of these blueprints, we’ll be using Github for our
source hosting. If you’d like to set up your own git server, <a href="http://git-scm.com/book/en/Git-on-the-Server-Setting-Up-the-Server" title="there are directions for that online">there are
directions for that
online</a>.</p>

<p>There are other version control options (like Mercurial) and other
hosted source options (like bitbucket). All major version control
solutions will work with the Continuous Delivery Pipeline. That said,
we’d advise against using Subversion. Subversion is easy to pick up, but
once you really get going with it you can lose a lot of time dealing
with merge headaches. Distributed version control systems like Git and
Mercurial and better choices in the long run. (If you already have your
source code in Subversion, don’t worry — you’ll still be able to do
everything we talk about.)</p>

<p>Throughout the blueprints, we’ll be referring to our reference
implementation project, CanaryBoard. It’s an open source project
Stelligent built. It is currently hosted in Github, and if you’re just
getting started, we recommend you use Github as well. Setting up an
account with Github is pretty easy, here’s the account sign up form if
you don’t already have an account. Note that if you use the free github
account, you do not get any private repositories, and your code is open
up to the world. If you need a private repository, Github offers paid
plans with private repositories.</p>

<p>With an account set up, it’s time to import your code. If your
organization doesn’t use source control, it’s a snap to get it added,
just follow these instructions to set up a repo, copy your code in, and
then commit the code and push it to github. Boom. Done.</p>

<p>If you’re not ready to import your code, you can fork the CanaryBoard
repository and follow along using that as a reference implementation. To
do that, just go to the CanaryBoard repo page, and look for the “Fork”
button at the top right.</p>

<p><strong>Set up your AWS Access Credentials</strong></p>

<p>****To interact with AWS programmatically, you need to provide it with
access credentials. These are created via the AWS console and stored in
environment variables for the scripts to use. Since we’re going to be
running scripts to set up the Jenkins server, we need to create those
keys now. To do this, log into the AWS Console:</p>

<ol>
<li>Navigate to the IAM panel</li>
<li>Select “Users” from the left side</li>
<li>Select the user you want to create credentials for</li>
<li>In the lower pane, click the “Security Credentials tab”</li>
<li>Click “Manage Access Keys”</li>
<li>Click “Create Access Key”</li>
<li>Click “Download Credentials”</li>
</ol>


<p>Now we have the credentials created, but we need to store them in
environment variables. On Linux or OSX, use these commands (replacing
the values with your actual key values)</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>export AWS_ACCESS_KEY_ID=ASDF1234567890ASDF
</span><span class='line'>export AWS_SECRET_ACCESS_KEY=qwerty1234567890qwerty1234567890qwerty</span></code></pre></td></tr></table></div></figure>


<p>On Windows:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>set AWS_ACCESS_KEY_ID=ASDF1234567890ASDF
</span><span class='line'>set AWS_SECRET_ACCESS_KEY=qwerty1234567890qwerty1234567890qwerty</span></code></pre></td></tr></table></div></figure>


<p>Boom. Now we’re ready to programmatically create some computing
instances.</p>

<p><strong>Set up a Continuous Integration Server</strong></p>

<p>So, with your source in source control, we’re ready to set up your
Continuous Integration server. For the purpose of these blueprints,
we’ll be using Jenkins. Jenkins is a free, open source Continuous
Integration server, and it’s widely used. In fact, you might already be
using Jenkins somewhere in your organization.\
 Jenkins is pretty easy to set up, but during these lessons we’ll be
taking advantage of several Jenkins plugins and using a bunch of job
configuration that is pretty static. Because of that, we’re able to
provide you with a script to launch a Jenkins server. It creates an
Opsworks stack, and then pulls in some Chef cookbooks we collected to
set up a Jenkins server that’s ready for you to work on.</p>

<p>The first thing you’ll want to do is clone the Stelligent CDRI repo and
run the Jenkins server script:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone https://github.com/stelligent/cdri.git
</span><span class='line'>cd cdri
</span><span class='line'>bundle install
</span><span class='line'>ruby bin/create_jenkins_server_stack.rb</span></code></pre></td></tr></table></div></figure>


<p>(Don’t have Git and/or Ruby installed? Well then, you’ll probably want
to follow these directions for <a href="http://git-scm.com/book/en/Getting-Started-Installing-Git" title="installing Git">installing
Git</a>
or <a href="https://www.ruby-lang.org/en/downloads/" title="installing Ruby">installing
Ruby</a>.) The
script will take a couple of minutes to lay down everything it needs to
set up a Jenkins server. After the script completes, though, it’ll still
take a bit of time for the Jenkins server to build itself and be ready
to go. The script actually has a couple options you may want to take
advantage of:</p>

<pre><code>$ ruby bin/create_jenkins_server_stack.rb --help
Options:
 --region, -r &lt;s&gt;: The AWS region to use (default: us-west-2)
 --zone, -z &lt;s&gt;: The AWS availability zone to use (default: us-west-2a)
 --source, -s &lt;s&gt;: The github repo where the source to build resides (will not work with anything but github!)
 (default: https://github.com/stelligent/canaryboard.git)
 --size, -i &lt;s&gt;: The instance size to use (default: m1.large)
 --help, -h: Show this message
</code></pre>

<p>The default region is us-west-2. If you’re in North America, this is
probably fine; otherwise you may want to switch it to a region closer to
you. (A list of AWS regions is <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html" title="available here">available
here</a>.)
The default zone us us-west-2a, so if you change the region, you will
need to change this as well.</p>

<p>The source repo is configurable, with a couple of caveats. The
repository must be a github repository, and it must be a public repo. It
is possible to have Jenkins connect to really any other repository type,
and it is possible to set up username / password information or SSH keys
to authenticate against a private repo. Both increase complexity, so to
keep things simple, we’ve restricted the script to only run against
public Github repositories.</p>

<p>Finally, you can configure the size of the EC2 instance that the Jenkins
server will run on. A list of instance sizes and prices is available
here. Note that anything smaller that a c3.large instance will take
considerably longer to start up, but shouldn’t impact your ability to
run builds at all. (However, Jenkins is a bit too heavy to run on a
t1.micro instance, so don’t try going that low; the Chef scripts won’t
even successfully run.)</p>

<p><strong>How the Jenkins Server is Set Up</strong></p>

<p>To set up the Jenkins server, we take advantage of two AWS services:
CloudFormation and OpsWorks. These services handle a lot of the tedious
bits about setting up AWS resources, and handle coordinating all the
Chef calls necessary. AWS has a bunch of CloudFormation and OpsWorks
documentation you can refer to, and any questions you have about it
should be in there. We’ll just give you the highlights in the blueprints
to get around the tools we provide; if you need more information, please
refer to the documentation.</p>

<p>The first thing the script does is create a CloudFormation stack to
create everything that the subsequent OpsWorks stack will need (security
groups, roles, and policies). Once those are in place, it then sets up a
new OpsWorks stack with a single custom layer and instance for the
Jenkins server. If you go to the OpsWorks console, you’ll see a Jenkins
stack with an instance starting. Once that instance turns green, your
Jenkins server will be up and running. You can access it by clicking on
the IP address in the instance details.</p>

<p>Since you’re just getting started, it’s probably a good idea to note
that the server you just launched will cost you money for each hour it’s
up. If you’re not going to be doing anything with it right away, you may
want to stop it when you’re not using it.</p>

<p>Note: when you stop the instance through OpsWorks you’ll lose any
configuration changes you’ve made to the server!</p>

<p><strong>Exploring the Pipeline</strong></p>

<p>The Jenkins server comes prepopulated with the beginnings of a
continuous delivery pipeline. If you go to the “Continuous Delivery
Pipeline” view, you’ll see all the different stages laid out. As you
work through this series, you’ll build out each of these stages for your
application. For now, let’s take a look at the first two stages, the
trigger stage and the commit stage.</p>

<p>The trigger stage is a simple monitoring job. Its purpose is to look for
changes in the repositories of your project, and if it detects a change,
it kicks off a new run of the pipeline.</p>

<p>The commit stage handles building, packaging, and unit testing the
application. It is supposed to run quickly (around five minutes) and
give fast feedback to the developers. We will cover the commit stage in
depth in the next part of this series.</p>

<p><strong>Wrapping Up</strong></p>

<p>If you didn’t already have source control setup, you do now. That’s
huge! Source control is probably the most important part of a continuous
delivery pipeline. We also set up a Jenkins server, to automate the
different parts of our pipeline. With your code in source control, and
your continuous integration server running, you’re ready to start
building out the different stages of the pipeline to work with your
application. In the next article, we’ll talk about how to set up your
commit stage to build and test your application.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
  
    
      <h1 class="entry-title"><a href="/blog/2014/03/25/continuous-delivery-implementation-getting-started-with-aws/">Continuous Delivery Implementation : Getting Started With AWS</a></h1>
      
      
    
      <p class="meta">
        








  


<time datetime="2014-03-25T14:57:15-04:00" pubdate data-updated="true">Mar 25<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><ul>
<li>Blog</li>
<li>This article is part of the Continuous Delivery Blueprints series.
It discusses how to go from no cloud infrastructure and no
continuous integration set up to having a functioning Continuous
Delivery Pipeline in Amazon Web Services. It discusses high level
topics while also providing a reference implementation so it’s easy
to follow along with.

<ul>
<li>Turn on CloudTrail</li>
<li>Turn on Programmatic Billing</li>
<li>If CloudTrail and Programmatic Billing are so important, why
aren’t they turned on by default?</li>
<li>Create IAM Users</li>
<li>Comments</li>
<li>Trackbacks</li>
<li>Post a comment</li>
<li>Categories</li>
</ul>
</li>
</ul>


<h1>This article is part of the Continuous Delivery Blueprints series. It discusses how to go from no cloud infrastructure and no continuous integration set up to having a functioning Continuous Delivery Pipeline in Amazon Web Services. It discusses high level topics while also providing a reference implementation so it’s easy to follow along with.</h1>

<p>Everyone is talking about migrating to the cloud these days, and getting
started with Amazon Web Services is super simple to do. However, most
people just rush in, creating headaches for themselves down the road.
There are some best practices you should take at the beginning of your
cloud migration that will make things easier, more secure, and allow you
to scale up and out better.</p>

<p>What we’re going to do today:</p>

<ul>
<li>• Create an AWS Account</li>
<li>• Turn On AWS CloudTrail</li>
<li>• Turn On Programmatic Billing</li>
<li>• Create IAM Users and Groups</li>
<li>• Add MFA for New Users</li>
</ul>


<p><strong>Create your AWS Account</strong></p>

<p>It all starts here: <a href="http://aws.amazon.com/">aws.amazon.com</a>. Find the
big sign up button and just follow the prompts. A couple of things to
note before getting started:</p>

<ol>
<li><ol>
<li>It’ll prompt you for your information (name, email, address, etc)
and credit card info, so you should get that figured out first.</li>
</ol>
</li>
<li><ol>
<li>You’ll need to verify your account via a phone call, so have your
phone handy.</li>
</ol>
</li>
<li><ol>
<li>You don’t need to sign up for support just yet.</li>
</ol>
</li>
</ol>


<p>Once you’re signed up, just login into the AWS console. The console
allows you to interact with most AWS services. Most people will start
building their servers in the sky right away, but there’s a bit of
information you should probably know up front, and some account set up
we recommend before getting started. Let’s go over that first.</p>

<p><strong>What You Need To Know About AWS Before Setting Stuff Up</strong></p>

<p>Amazon Web Services offers a lot of different services, from virtual
computing instances and storage to transcoding and streaming. Going over
each service would take a whole series of blog posts, but an
understanding of how AWS is laid out will be helpful when getting
started.</p>

<p>AWS has data centers all over the world, and has two ways of grouping
them. At global scale there are <strong>regions</strong>, representing parts of or
entire continents. Inside each region are <strong>availability zones</strong>.
Regions are completely distinct entities, and you can only work in one
at a time. Availability zones are designed to talk to each other, and
AWS will automatically spread your resources across availability zones.
Availability zones, however, can only speak to other zones within the
same region.</p>

<p>Choosing a region is important, though these directions are the same
more-or-less in every region. However, be aware that not all services
are available in all regions, and pricing does vary by region. In
addition to that, US-East-1 is the “default” zone when you start with
AWS, and has been around the longest. For that reason, it’s also the
most popular, and sometimes you won’t be able to allocate resources in
certain Availability Zones in the US-East-1 region due to those zones
being at capacity.</p>

<p>AWS provides <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html">lots of
documentation</a>
on how to choose a region, so definitely look through that to decide the
best place to host your infrastructure. If you’re just doing initial
investigation into AWS and aren’t sure what region to use, just pick one
close to you.</p>

<p><strong>Making a Name For Yourself</strong></p>

<p>We’ll be talking about several AWS services in this section, and many of
them make use of AWS Simple Storage Service, or <strong>S3</strong>. S3 allows you to
store objects in the cloud with a high degree of durability. Where S3
objects are stored are called “buckets”. S3 bucket names have to be
unique, not just across you account, but across the entire world. A
bucket name is globally unique. By the time we’re done, we’ll have
created a couple buckets, as well globally unique login URL. For that
reason, you should come up with a unique identifier now. For example,
when we tested this documentation, we used the identifier
“stelligent-cdblueprints.” Just note it down now and we’ll refer to it
as we go on.</p>

<h4>Turn on CloudTrail</h4>

<p>First thing is to turn on CloudTrail. CloudTrail is basically logging
for your AWS account. It will generate JSON files and store them in an
S3 bucket (Amazon’s cloud storage solution) every time an action is
performed on the account. While we won’t be doing a lot with CloudTrail
right away, we’re turning it on now because it’s not retroactive — you
can only see logs after you’ve turned it on. So let’s turn it on first.</p>

<p>(Quick note: CloudTrail is a relatively new service, and at the time of
this writing is only available in two regions: US-East-1 and US-West-2.
If you’re using a different region, you might not be able to turn
CloudTrail on. If that’s the case, just skip on to the next step.)</p>

<ol>
<li>Find CloudTrail panel from the main AWS Console,</li>
<li>Click Get Started and just punch in an S3 Bucket name. (As was
mentioned above, the S3 bucket name has to be globally unique. One
approach is to take the unique identifier you came up with before,
and just append -cloudtrail to it. We’ve named our bucket
“stelligent-cdblueprints-cloudtrail”.)</li>
<li>Click OK and you’re done.</li>
</ol>


<p>That was easy.</p>

<h4>Turn on Programmatic Billing</h4>

<p>Next, we’ll want to turn on Programmatic Billing. This will store your
AWS billing in JSON files in another S3 bucket, so that other services
can analyze your spending and plot trends over time. We’ll be visiting
those kind of tools later on, but we want to enable programmatic billing
now because (just like CloudTrail) it only generates data from the
present — there’s no way to go back and generate historical data. By
turning it on now, when we do start parsing that data for trends, you’ll
have a good amount of data to go back through.</p>

<p>Unlike CloudTrail, you’ll need to create and permission the bucket for
this yourself.</p>

<ol>
<li>Go to the S3 console so we can create a new bucket. (Taking your
previous unique identifier and just appending -billing to it isn’t a
bad idea. We’ve named ours “stelligent-cdblueprints-billing” to keep
with the theme.)</li>
<li>Click Create Bucket and punch that name in.</li>
<li>We’ll need to get a bucket permissions policy. Luckily, AWS will
generate that for us at this page (we’ll need to flip back to the S3
page in a second, so open this in a new
tab): <a href="https://portal.aws.amazon.com/gp/aws/developer/account?ie=UTF8&amp;action=billing-preferences">https://portal.aws.amazon.com/gp/aws/developer/account?ie=UTF8&amp;action=billing-preferences</a></li>
<li>Go down the list and turn everything on one and a time.</li>
<li>When you get to to Programmatic billing, punch in the name of
your bucket, and click “sample policy.” Just copy that policy, then
flip back to your S3 bucket.</li>
<li>Click on the bucket, then properties, then Permissions, and
you’ll see an option for setting an access policy.</li>
<li>Click into that, paste the policy you just copied, and save.</li>
<li>Now, flip back to the Billing Preferences page, click save there</li>
<li>Continue to enable everything else on this page.</li>
</ol>


<h4>If CloudTrail and Programmatic Billing are so important, why aren’t they turned on by default?</h4>

<p>One thing to be aware of with these two services is that they will put
data into your S3 buckets. S3 storage is very cheap, and while it is
pretty close, it is not free. You’ll be paying between nine and fifteen
cents a gig for storage, depending on region. For more details, <a href="https://aws.amazon.com/s3/pricing/">check
out the S3 pricing page</a>. The
services themselves don’t cost anything, though; you only pay for
storing the data they generate.</p>

<h4>Create IAM Users</h4>

<p>Now that the bookkeeping is taken care of, let’s set up some users. A
lot of new AWS users will start doing everything as the root account,
which besides being a bit of a security risk, also poses some issues
when you try to have multiple developers building solutions in your
cloud. That’s why we strongly recommend setting up IAM users and roles
from the beginning.</p>

<p>We’re going to use the AWS Identity and Access Management (IAM) console.
IAM allows you to create users, groups, and roles so that you can manage
users and access to your AWS account. For the first section, we’ll only
be creating one user (for you) and one group (admins) but as your usage
of the cloud increases and you need to add more users, you’ll be able to
control that from here.</p>

<p>To create a new admins group, head to the IAM console</p>

<ol>
<li>Click Create Group, and follow the prompts.</li>
<li>We’ll name the group “admins” and give it Administrator access.</li>
</ol>


<p>Now that we have an admins group, go to the Users panel and create a new
user for yourself to log in as. It’s pretty straightforward, and if you
hit any bumps in the road, <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/Using_SettingUpUser.html">AWS has some pretty good documentation about
it</a>.</p>

<p>After you create the user, add it to the admins group. Then, for each
user we want to set up two types of authentication. The first is a
simple password. Under each users’ Security Credentials tab, click the
“Manage Passwords” button and you’ll be able to assign a password.</p>

<p>After each user logs in, you’ll want to require them to add a
multi-factor authentication (MFA) device to their account. To add an MFA
device</p>

<ol>
<li>the user will need to login and go to the IAM console</li>
<li>find their username</li>
<li>under the security credentials tab, select “Manage MFA device.”</li>
<li>Then follow the steps to add your virtual MFA device to the account.</li>
</ol>


<p>Having MFAs set up for all accounts helps ensure that AWS accounts won’t
be compromised, keeping your data safe. Also, it helps ensure that your
account won’t be used for malicious purposes (DDOS attacks, spam emails,
etc) which would at best would increase your AWS bill and worst case
have your entire account disabled. We strongly recommend enabling MFAs
for all user accounts.</p>

<p>Now that users are able to log in, we’ll need to give them a URL to do
so. If you go to the main IAM console, you’ll find a IAM User Sign-In
URL section. Remember the unique identifier you came up with your
CloudTrail and Programatic Billing buckets? That’s probably a good
option for your sign in URL. Changing it is optional, though highly
recommended.</p>

<p><strong>Wrapping Up</strong></p>

<p>Using AWS is easy; using it well takes some thought. By setting up
logging of your usage and billing information, you’ll be able to
identify trends as time goes on. By setting up groups and users, your
account is prepared to scale as you bring on more developers. And by
giving those users multi-factor authentication, you’ve helped ensure the
security of the account. You’re in a great place to start using the
cloud. In our next post, we’ll lay the foundations for building a
continuous delivery pipeline.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
  
    
      <h1 class="entry-title"><a href="/blog/2014/03/25/autoscaling-for-lamp-on-aws-creating-a-lamp-stack-ami-part-4/">Autoscaling for LAMP on AWS |Creating a LAMP Stack AMI : Part 4</a></h1>
      
      
    
      <p class="meta">
        








  


<time datetime="2014-03-25T11:23:17-04:00" pubdate data-updated="true">Mar 25<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h3>Autoscaling for LAMP on AWS | Choosing an instance type: Part 4</h3>

<p>As mentioned in <a href="../autoscaling-for-lamp-on-aws-creating-a-lamp-stack-ami-part-1/index.html" title="Autoscaling for LAMP on AWS |Creating a LAMP Stack AMI : Part 1">part 1 of this
series</a> (Creating
a LAMP Stack AMI), a common concern among most customers is to choose
the right instance type.</p>

<p>It is important to do the capacity planning. Before you choose instance
type ask yourself the following three questions:</p>

<ol>
<li><p>Is the application Memory intensive CPU intensive or Network
intensive? For this question to be meaningful put a monitoring
system in place and collect the data for a few weeks of real usage.</p></li>
<li><p>What is the expected request count at peak hours?</p></li>
<li><p>What is the minimum number of instances you want to run in
non-business hours?</p></li>
</ol>


<p><a href="https://docs.google.com/a/flux7.com/spreadsheet/ccc?key=0AkmUqlScRGp8dGJTNndjY0VjTURid3FTV2dNMEljOUE#gid=0">https://docs.google.com/a/flux7.com/spreadsheet/ccc?key=0AkmUqlScRGp8dGJTNndjY0VjTURid3FTV2dNMEljOUE#gid=0</a></p>

<p>Make sure to run at least 2 servers for high availability.  During times
of fewer loads, choose two m1.small instances for non-business hours
like weekends. This would optimize cost instead of using 2 large
instances for the same request.</p>

<p>Different instance types have different capacity levels. If the
application is memory intensive choose and use m1. class. If the
application is CPU intensive then choose and use c1. class.</p>

<p>Network bandwidth varies between different instance types. If the
application requires more bandwidth (ex: video streaming applications)
choose higher instance types irrespective of Memory or CPU to get better
bandwidth.</p>

<p>To know more about each instance types visit the following link.</p>

<p><a href="http://aws.amazon.com/ec2/instance-types/">http://aws.amazon.com/ec2/instance-types/</a></p>

<p>Start with micro/small instance for any workload. Do the Load run
starting with the minimum number of users and increase the load
gradually. Also scale the servers vertically or horizontally gradually
until it reaches the maximum capacity. This would give a clearer picture
of the number of instances required to serve the maximum or minimum
load. Closely watch the CloudWatch graphs to understand usage statistics
better.</p>

<p>An interesting question at this juncture could be as follows: Can 4
m1.medium instances be preferred to 2 large instances? Yes of course.
However, network bandwidth varies from one instance type to other. Given
that, it is wise to choose 2 large instances instead of 4 m1.medium
instances as it is easier to handle lesser number of instances.</p>

<p>(Note: DB server health needs to be checked when a load test is run.
Increasing the app servers count may not improve the performance all the
time. If DB queries are the bottleneck, chances are high for a bad
performance. Consider scaling up the DB server capacity as well.)</p>

<p>Based on the instance type identified from the load run, tune the PHP
memory settings and Apache prefork MPM client connections.</p>

<p>Check out the following links to know more about fine tuning Apache and
PHP</p>

<p><a href="http://www.hosting.com/support/linux/tuning-the-apache-prefork-mpm/">http://www.hosting.com/support/linux/tuning-the-apache-prefork-mpm/</a></p>

<p><a href="http://icreatestuff.co.uk/blog/article/apache-performance-tuning">http://icreatestuff.co.uk/blog/article/apache-performance-tuning</a></p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>About Me</h1>
  <p>A little something about me.</p>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/04/04/a-case-study-on-using-100-percent-cloud-based-resources-with-automated-software-delivery/">A case study on using 100% cloud based Resources with Automated Software Delivery</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/04/04/tutotial-continuous-delivery-in-the-cloud-part-6-of-6/">Tutotial : Continuous Delivery in the Cloud Part 6 of 6</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/04/04/tutorial-continuous-delivery-in-the-cloud-part-5-of-6/">Tutorial : Continuous Delivery in the Cloud Part 5 of 6</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/04/04/tutorial-continuous-delivery-in-the-cloud-part-4-of-6/">Tutotial : Continuous Delivery in the Cloud Part 4 of 6</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/04/04/tutorial-continuous-delivery-in-the-cloud-part-3-of-6/">Tutorial : Continuous Delivery in the Cloud Part 3 of 6</a>
      </li>
    
  </ul>
</section>



<section class="googleplus">
  <h1>
    <a href="https://plus.google.com/bvajjala@gmail.com?rel=author">
      <img src="http://www.google.com/images/icons/ui/gprofile_button-32.png" width="32" height="32">
      Google+
    </a>
  </h1>
</section>



  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 -  Balaji Vajjala <br/>
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a> + <a href="https://github.com/ioveracker/mnml">mnml</a>.
	  
  </span>
</p>

</footer>
  



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
